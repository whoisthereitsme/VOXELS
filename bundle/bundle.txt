#Time when generated: 2026-01-29T12:27:26

### PROJECT BUNDLE ###
Root: C:\VOXELS
Files included: 21


################################################################################
# FILE 1/21: __init__.py (START)
################################################################################

import utils
import world
import bundle

__all__ = world.__all__ + utils.__all__ + bundle.__all__


################################################################################
# FILE 1/21: __init__.py (END)
################################################################################


################################################################################
# FILE 2/21: __main__.py (START)
################################################################################

from main import main

if __name__ == "__main__":
    main()

################################################################################
# FILE 2/21: __main__.py (END)
################################################################################


################################################################################
# FILE 3/21: bundle/__init__.py (START)
################################################################################

from .bundle import *
from .github import *

__all__ = [
    "Bundle",
    "GitHub",
]

################################################################################
# FILE 3/21: bundle/__init__.py (END)
################################################################################


################################################################################
# FILE 4/21: bundle/bundle.py (START)
################################################################################

from __future__ import annotations
import atexit
import sys
import threading
import time
from pathlib import Path
from typing import Iterable, Optional, Set, TextIO, Callable


from .github import GitHub


# ============================================================
# Bundle builder with integrated output capture (no output.txt, no HTML)
# ============================================================

class Bundle:
    class _Tee(TextIO):
        def __init__(self, original: TextIO, buffer: list[str], lock: threading.Lock) -> None:
            self._original = original
            self._buffer = buffer
            self._lock = lock

            

        def write(self, s: str) -> int:
            n = self._original.write(s)
            with self._lock:
                self._buffer.append(s)
            return n

        def flush(self) -> None:
            self._original.flush()

        def isatty(self) -> bool:
            return getattr(self._original, "isatty", lambda: False)()

        @property
        def encoding(self):
            return getattr(self._original, "encoding", "utf-8")

    def __init__(
        self,
        *,
        root: Path | None = None,
        out: Path | None = None,
        exts: Set[str] | None = None,
        dirs: Set[str] | None = None,
        skip: Set[str] | None = None,
        max_bytes: int = 2_000_000,
        overwrite: bool = True,
        include_stderr: bool = True,
        marker_prefix: str = "### CAPTURE START ###",
        auto_end_on_exit: bool = True,
        auto_end_on_exception: bool = True,
    ) -> None:
        self.root = (root if root is not None else Path.cwd()).resolve()
        self.out = (out if out is not None else (self.root / "bundle" / "bundle.txt")).resolve()

        self.exts = exts if exts is not None else {
            ".py", ".pyi", ".txt", ".md", ".json", ".toml", ".yaml", ".yml", ".ini", ".cfg", ".bat", ".ps1", ".sh",
        }
        self.dirs = dirs if dirs is not None else {
            ".git", ".hg", ".svn", ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            "atlas", "_old", "__OLD",
        }
        self.skip = skip if skip is not None else {".DS_Store", "Thumbs.db"}
        self.max_bytes = int(max_bytes)
        self.overwrite = bool(overwrite)

        self.include_stderr = bool(include_stderr)
        self.marker_prefix = str(marker_prefix)

        self._lock = threading.Lock()
        self._buf_out: list[str] = []
        self._buf_err: list[str] = []

        self._orig_stdout: Optional[TextIO] = None
        self._orig_stderr: Optional[TextIO] = None
        self._orig_excepthook: Optional[Callable] = None
        self._ended = False

        self.start_capture()

        if auto_end_on_exit:
            atexit.register(self.stop_capture_and_write_bundle)

        if auto_end_on_exception:
            self._install_excepthook()

        self.github = GitHub

    def __enter__(self) -> "Bundle":
        return self

    def __exit__(self, exc_type, exc, tb) -> bool:
        self.stop_capture_and_write_bundle()
        self.github()
        return False

    def _install_excepthook(self) -> None:
        self._orig_excepthook = sys.excepthook

        def hooked(exctype, value, tb) -> None:
            if self._orig_excepthook is not None:
                self._orig_excepthook(exctype, value, tb)
            self.stop_capture_and_write_bundle()

        sys.excepthook = hooked  # type: ignore[assignment]

    def start_capture(self) -> None:
        self._orig_stdout = sys.stdout
        self._orig_stderr = sys.stderr

        sys.stdout = self._Tee(self._orig_stdout, self._buf_out, self._lock)  # type: ignore[assignment]
        if self.include_stderr:
            sys.stderr = self._Tee(self._orig_stderr, self._buf_err, self._lock)  # type: ignore[assignment]

        print(f"{self.marker_prefix} root={self.root.as_posix()}")

    def stop_capture_and_write_bundle(self) -> Path:
        captured = self._end_capture_get_text()
        return self.write_bundle_txt(captured_output=captured)

    def _end_capture_get_text(self) -> str:
        if self._ended:
            with self._lock:
                out_text = "".join(self._buf_out)
                err_text = "".join(self._buf_err)
            return self._combine_streams(out_text, err_text)

        self._ended = True

        if self._orig_stdout is not None:
            sys.stdout = self._orig_stdout  # type: ignore[assignment]
        if self.include_stderr and self._orig_stderr is not None:
            sys.stderr = self._orig_stderr  # type: ignore[assignment]

        if self._orig_excepthook is not None:
            sys.excepthook = self._orig_excepthook  # type: ignore[assignment]

        with self._lock:
            out_text = "".join(self._buf_out)
            err_text = "".join(self._buf_err)

        combined = self._combine_streams(out_text, err_text)

        marker_line = f"{self.marker_prefix} root={self.root.as_posix()}"
        combined = self._keep_after_marker(combined, marker_line)
        return combined

    def _combine_streams(self, out_text: str, err_text: str) -> str:
        combined = out_text
        if self.include_stderr and err_text:
            if combined and not combined.endswith("\n"):
                combined += "\n"
            combined += err_text
        return combined

    @staticmethod
    def _keep_after_marker(text: str, marker_line: str) -> str:
        idx = text.rfind(marker_line)
        if idx == -1:
            return text
        nl = text.find("\n", idx)
        if nl == -1:
            return ""
        return text[nl + 1 :]

    def write_bundle_txt(self, *, captured_output: str) -> Path:
        self.out.parent.mkdir(parents=True, exist_ok=True)
        if self.overwrite and self.out.exists():
            self.out.unlink()

        generated_at = time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())
        files = sorted(self._iter_files(self.root), key=lambda p: str(p.relative_to(self.root)).lower())

        lines: list[str] = []
        lines.append(f"#Time when generated: {generated_at}\n\n")
        lines.append("### PROJECT BUNDLE ###\n")
        lines.append(f"Root: {self.root}\n")
        lines.append(f"Files included: {len(files)}\n\n")

        for i, p in enumerate(files, start=1):
            rel = p.relative_to(self.root).as_posix()

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (START)\n")
            lines.append("#" * 80 + "\n\n")

            content = self._safe_read_text_lossy(p)
            if content and not content.endswith("\n"):
                content += "\n"
            lines.append(content)

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (END)\n")
            lines.append("#" * 80 + "\n\n")

        if captured_output.strip():
            lines.append("\n" + "################################################################################\n")
            lines.append("### CAPTURED OUTPUT (STDOUT/STDERR) ###\n")
            lines.append("################################################################################\n\n")
            lines.append(captured_output if captured_output.endswith("\n") else captured_output + "\n")
            lines.append("\n################################################################################\n")
            lines.append("### END OF CAPTURED OUTPUT ###\n")
            lines.append("################################################################################\n")

        final_text = "".join(lines)
        if not final_text.endswith("\n"):
            final_text += "\n"

        total_lines = final_text.count("\n")
        final_text += f"# Total lines in bundle: {total_lines}\n"
        final_text += f"# Total files in bundle: {len(files)}\n"
        final_text += f"# Generated at the time: {time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime())}\n"
        final_text += "--- END OF FILE ---\n"

        self.out.write_text(final_text, encoding="utf-8")
        return self.out

    def _iter_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.skip:
                continue
            if p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.max_bytes:
                    continue
            except OSError:
                continue

            yield p

    @staticmethod
    def _safe_read_text_lossy(path: Path) -> str:
        try:
            return path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            return path.read_text(encoding="utf-8", errors="replace")
        except OSError as e:
            return f"<<ERROR READING FILE: {e}>>\n"






################################################################################
# FILE 4/21: bundle/bundle.py (END)
################################################################################


################################################################################
# FILE 5/21: bundle/github.py (START)
################################################################################

import base64
import json
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional, Set

from credentials import *
from utils import Request




@dataclass(frozen=True)
class FileJob:
    local_path: Path
    repo_path: str


class GitHub:
    def __init__(
        self,
        root: Path = Path.cwd(),
        verbose: bool = True,
        workers: int = 12,
        message: str = "Publish project snapshot",
        exts: Optional[Set[str]] = None,
        dirs: Optional[Set[str]] = None,
        files: Optional[Set[str]] = None,
        bytes: int = 2_000_000,
        binary: bool = True,
    ) -> None:
        self.owner = Environ.githublogin
        self.token = Environ.githubtoken
        self.repo = "VOXELS"
        self.branch = "main"
        self.root = root.resolve()
        
        self.verbose = verbose
        self.workers = workers
        self.message = message

        self.exts = exts
        self.dirs = dirs or {
            ".git", ".hg", ".svn",
            ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            ".gradle", ".terraform",
            "atlas", "_old", "__OLD",
        }
        self.files = files or {".DS_Store", "Thumbs.db"}
        self.bytes = bytes
        self.binary = binary

        self.lock = threading.Lock()

        self.publish()

    def publish(self) -> None:
        t0 = time.perf_counter()
        if not self.token:
            raise SystemExit(f"Missing environment variable GITHUB_TOKEN.\n", f"Create a fine-grained PAT (Contents: read+write) for repo {self.owner}/{self.repo}.")

        if not self.root.exists() or not self.root.is_dir():
            raise SystemExit(f"root does not exist or is not a directory: {self.root}")

        jobs = self._build_jobs()
        self._log(f"[GITHUB] single-commit publish: {len(jobs)} files from {self.root} -> {self.owner}/{self.repo}@{self.branch}")

        head_commit_sha = self._get_branch_head_commit_sha(self.token)
        base_tree_sha = self._get_commit_tree_sha(self.token, head_commit_sha)

        path_to_blob_sha = self._create_blobs_parallel(self.token, jobs)
        new_tree_sha = self._create_tree(self.token, base_tree_sha, path_to_blob_sha)
        new_commit_sha = self._create_commit(self.token, new_tree_sha, head_commit_sha)
        self._update_branch_ref(self.token, new_commit_sha)

        dt = time.perf_counter() - t0
        self._log(f"[GITHUB] done: 1 commit, {len(jobs)} files, elapsed {dt:.2f}s. files/sec: {len(jobs)/dt:.1f}")

    def _build_jobs(self) -> list[FileJob]:
        files = sorted(self._iter_project_files(self.root), key=lambda p: str(p).lower())
        return [FileJob(p, p.relative_to(self.root).as_posix()) for p in files]

    def _iter_project_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.files:
                continue
            if self.exts is not None and p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.bytes:
                    continue
            except OSError:
                continue

            if self.binary:
                try:
                    data = p.read_bytes()
                except OSError:
                    continue
                if self._looks_binary(data):
                    continue

            yield p

    @staticmethod
    def _looks_binary(data: bytes) -> bool:
        if b"\x00" in data:
            return True
        sample = data[:8192]
        if not sample:
            return False
        bad = 0
        for b in sample:
            if b in (9, 10, 13) or 32 <= b <= 126:
                continue
            bad += 1
        return (bad / len(sample)) > 0.20

    # -----------------------------
    # GitHub API core
    # -----------------------------
    def _api_request(self, method: str, url: str, token: str, body: Optional[dict] = None) -> dict:
        data = None
        if body is not None:
            data = json.dumps(body).encode("utf-8")

        req = Request(url=url, data=data, method=method, timeout=600, retries=3)
        req.header("Authorization", f"Bearer {token}")
        req.header("Accept", "application/vnd.github+json")
        req.header("X-GitHub-Api-Version", "2022-11-28")
        if data is not None:
            req.header("Content-Type", "application/json; charset=utf-8")

        return req.open()

    def _get_branch_head_commit_sha(self, token: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/ref/heads/{self.branch}"
        j = self._api_request("GET", url, token)
        return j["object"]["sha"]

    def _get_commit_tree_sha(self, token: str, commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits/{commit_sha}"
        j = self._api_request("GET", url, token)
        return j["tree"]["sha"]

    def _create_blob(self, token: str, content_bytes: bytes) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/blobs"
        body = {"content": base64.b64encode(content_bytes).decode("ascii"), "encoding": "base64"}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_blobs_parallel(self, token: str, jobs: list[FileJob]) -> dict[str, str]:
        out: dict[str, str] = {}
        lock = threading.Lock()

        def worker(job: FileJob) -> None:
            data = job.local_path.read_bytes()
            sha = self._create_blob(token, data)
            with lock:
                out[job.repo_path] = sha
            if self.verbose:
                self._log(f"    [blob] {job.repo_path}")

        with ThreadPoolExecutor(max_workers=self.workers) as ex:
            futures = [ex.submit(worker, j) for j in jobs]
            for fut in as_completed(futures):
                fut.result()

        return out

    def _create_tree(self, token: str, base_tree_sha: str, path_to_blob_sha: dict[str, str]) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/trees"
        tree_entries = [
            {"path": path, "mode": "100644", "type": "blob", "sha": blob_sha}
            for path, blob_sha in path_to_blob_sha.items()
        ]
        body = {"base_tree": base_tree_sha, "tree": tree_entries}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_commit(self, token: str, tree_sha: str, parent_commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits"
        body = {"message": self.message, "tree": tree_sha, "parents": [parent_commit_sha]}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _update_branch_ref(self, token: str, new_commit_sha: str) -> None:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/refs/heads/{self.branch}"
        body = {"sha": new_commit_sha, "force": False}
        self._api_request("PATCH", url, token, body=body)

    def _log(self, msg: str) -> None:
        with self.lock:
            print(msg)


################################################################################
# FILE 5/21: bundle/github.py (END)
################################################################################


################################################################################
# FILE 6/21: credentials/__init__.py (START)
################################################################################

from .environ import Environ

__all__ = [
    "Environ"
]   

################################################################################
# FILE 6/21: credentials/__init__.py (END)
################################################################################


################################################################################
# FILE 7/21: credentials/environ.py (START)
################################################################################




import os



class Environ:
    githublogin = os.getenv("GITHUB_LOGIN")
    githubtoken = os.getenv("GITHUB_TOKEN")
    mailadress  = os.getenv("MAIL_ADRESS")
    phonenumber = os.getenv("PHONE_NUMBER")
    ippublic    = os.getenv("IP_PUBLIC")
    ipprivate   = os.getenv("IP_PRIVATE")
    sshkey      = os.getenv("SSH_KEY")


################################################################################
# FILE 7/21: credentials/environ.py (END)
################################################################################


################################################################################
# FILE 8/21: main.py (START)
################################################################################


from utils import *
from world import *
from bundle import *





def main() -> None:
    rows = ROWS()
    row = rows.array[ MATERIALS.IDX["STONE"] ][0]
    rows.delete(row=row)

    cell = 20          # cube edge length
    nx = 40            # number of cells in X  -> world X size = nx*cell
    ny = 40            # number of cells in Y
    nz = 40            # number of cells in Z
    n = nx * ny * nz  # total number of cells

    timer.lap()
    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.append(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg="STEP 1 :  3D grid partition built")

    max_x = nx * cell - 1
    max_y = ny * cell - 1
    max_z = nz * cell - 1

    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (
                random.randint(0, max_x),
                random.randint(0, max_y),
                random.randint(0, max_z),
            )
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Random CONTAINS checks completed in")

    print(" - Now deleting all rows...")
    for i in range(10000):
        row = rows.array[ MATERIALS.IDX["STONE"] ][n-1-i]
        rows.delete(row=row)
    timer.print(msg=" - All 10000 rows deleted in")
    # and now test wiht a new set adn see if it still works
    print("STEP 2 : Rebuilding rows after deletion...")
    cell = 40          # double size
    nx = 20            # half number of cells in X  -> world X size = nx*cell
    ny = 20            # half number of cells in Y
    nz = 20            # half number of cells in Z
    n = nx * ny * nz   # total number of cells (1/8th number of previous)

    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.append(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg=" - second time 3D grid partition built")
    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (
                random.randint(0, max_x),
                random.randint(0, max_y),
                random.randint(0, max_z),
            )
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Second random CONTAINS checks completed in")

    if succes == 1000 and fails == 0:
        print("FINALLY: TESTS PASSED SUCCESSFULLY!")

    print("STEP 3 : Now testing SPLIT functionality...")
    rows = ROWS() # it has by default a large enough array to hold 10000 rows per material
    print("WORLD VOLUME BEFORE: ", rows.volume())
    print(rows.size)
    # 1 row exists normally at tis point -> its created at init with STONE material
    for i in range(10):
        x = random.randint(1000, b=999000)
        y = random.randint(a=1000, b=999000)
        z = random.randint(a=1000, b=64000)
        rows.split(pos=(x, y, z), mat="AIR")  # should raise error since no rows exist yet
        print(f" - SPLIT test {i+1}/10 passed.")

    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SPLIT tests.")
    
    print("WORLD VOLUME AFTER: ", rows.volume())







if __name__ == "__main__":
    timer.lap()
    with Bundle():
        try:
            main()
            timer.print(msg="main.py: executed in")
        except Exception:
            traceback.print_exc()
        finally:    
            pass



################################################################################
# FILE 8/21: main.py (END)
################################################################################


################################################################################
# FILE 9/21: TODO.md (START)
################################################################################




# ! ROWS
# TODO: ROWS.SPLIT(pos:POS=None)
# TODO: ROWS.MERGE(row0:NDARRAY=None, row1:NDARRAY=None)
# TODO: 

# ! UTILS
# TODO: 

# ! BUNDLE
# TODO: CLEANUP!!!

################################################################################
# FILE 9/21: TODO.md (END)
################################################################################


################################################################################
# FILE 10/21: utils/__init__.py (START)
################################################################################

from .request import Request
from .includes import *
from .includes import __all__ as inc
__all__ = [
    "Request",
] + inc

################################################################################
# FILE 10/21: utils/__init__.py (END)
################################################################################


################################################################################
# FILE 11/21: utils/bvh.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from numpy.typing import NDArray
    from world.rows import ROWS
    from utils.types import POS

from world.row import ROW





class BVH:
    __slots__ = (
        "rows",
        "root",
        "left",
        "right",
        "parent",
        # AABB as 6 parallel lists (SoA)
        "xmin",
        "ymin",
        "zmin",
        "xmax",
        "ymax",
        "zmax",
        # leaf as 2 parallel lists
        "leaf_mid",
        "leaf_rid",
        # fast delete index
        "leaf_index",
    )

    def __init__(self, rows: ROWS) -> None:
        self.rows = rows
        self.root: int = -1

        self.left: list[int] = []
        self.right: list[int] = []
        self.parent: list[int] = []

        self.xmin: list[int] = []
        self.ymin: list[int] = []
        self.zmin: list[int] = []
        self.xmax: list[int] = []
        self.ymax: list[int] = []
        self.zmax: list[int] = []

        self.leaf_mid: list[int] = []
        self.leaf_rid: list[int] = []

        # (mid, rid) -> node index
        self.leaf_index: dict[tuple[int, int], int] = {}

    # ------------------------------------------------------------------
    # node alloc
    # ------------------------------------------------------------------

    def _new_node(
        self,
        xmin: int,
        ymin: int,
        zmin: int,
        xmax: int,
        ymax: int,
        zmax: int,
        leaf_mid: int = -1,
        leaf_rid: int = -1,
        left: int = -1,
        right: int = -1,
        parent: int = -1,
    ) -> int:
        i = len(self.left)

        self.left.append(left)
        self.right.append(right)
        self.parent.append(parent)

        self.xmin.append(xmin)
        self.ymin.append(ymin)
        self.zmin.append(zmin)
        self.xmax.append(xmax)
        self.ymax.append(ymax)
        self.zmax.append(zmax)

        self.leaf_mid.append(leaf_mid)
        self.leaf_rid.append(leaf_rid)
        return i

    # ------------------------------------------------------------------
    # helpers
    # ------------------------------------------------------------------

    @staticmethod
    def _volume(xmin: int, ymin: int, zmin: int, xmax: int, ymax: int, zmax: int) -> int:
        return (xmax - xmin) * (ymax - ymin) * (zmax - zmin)

    def _merged_volume_with_node(
        self,
        node: int,
        bxmin: int,
        bymin: int,
        bzmin: int,
        bxmax: int,
        bymax: int,
        bzmax: int,
    ) -> int:
        axmin = self.xmin[node]
        aymin = self.ymin[node]
        azmin = self.zmin[node]
        axmax = self.xmax[node]
        aymax = self.ymax[node]
        azmax = self.zmax[node]

        mxmin = axmin if axmin < bxmin else bxmin
        mymin = aymin if aymin < bymin else bymin
        mzmin = azmin if azmin < bzmin else bzmin
        mxmax = axmax if axmax > bxmax else bxmax
        mymax = aymax if aymax > bymax else bymax
        mzmax = azmax if azmax > bzmax else bzmax

        return self._volume(mxmin, mymin, mzmin, mxmax, mymax, mzmax)

    def _fix_upwards(self, node:int=None) -> None:
        while node != -1:
            l = self.left[node]
            r = self.right[node]

            self.xmin[node] = self.xmin[l] if self.xmin[l] < self.xmin[r] else self.xmin[r]
            self.ymin[node] = self.ymin[l] if self.ymin[l] < self.ymin[r] else self.ymin[r]
            self.zmin[node] = self.zmin[l] if self.zmin[l] < self.zmin[r] else self.zmin[r]
            self.xmax[node] = self.xmax[l] if self.xmax[l] > self.xmax[r] else self.xmax[r]
            self.ymax[node] = self.ymax[l] if self.ymax[l] > self.ymax[r] else self.ymax[r]
            self.zmax[node] = self.zmax[l] if self.zmax[l] > self.zmax[r] else self.zmax[r]

            node = self.parent[node]

    # ------------------------------------------------------------------
    # insertion
    # ------------------------------------------------------------------

    def insert(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is None:
            mid = self.rows.mats.name2idx[mat]
            row = self.rows.array[mid][rid]
        else:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])

        xmin, ymin, zmin = ROW.P0(row)
        xmax, ymax, zmax = ROW.P1(row)

        leaf_node = self._new_node(
            xmin, ymin, zmin,
            xmax, ymax, zmax,
            leaf_mid=mid,
            leaf_rid=rid,
        )

        self.leaf_index[(mid, rid)] = leaf_node

        if self.root == -1:
            self.root = leaf_node
            return

        self.root = self._insert_node(self.root, leaf_node)

    def _insert_node(self, root: int, leaf_node: int) -> int:
        bxmin = self.xmin[leaf_node]; bymin = self.ymin[leaf_node]; bzmin = self.zmin[leaf_node]
        bxmax = self.xmax[leaf_node]; bymax = self.ymax[leaf_node]; bzmax = self.zmax[leaf_node]

        node = root
        while self.leaf_mid[node] == -1:
            l = self.left[node]
            r = self.right[node]
            node = (
                l if self._merged_volume_with_node(l, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                < self._merged_volume_with_node(r, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                else r
            )

        old_leaf = node
        parent = self.parent[old_leaf]

        axmin = self.xmin[old_leaf]; aymin = self.ymin[old_leaf]; azmin = self.zmin[old_leaf]
        axmax = self.xmax[old_leaf]; aymax = self.ymax[old_leaf]; azmax = self.zmax[old_leaf]

        new_parent = self._new_node(
            axmin if axmin < bxmin else bxmin,
            aymin if aymin < bymin else bymin,
            azmin if azmin < bzmin else bzmin,
            axmax if axmax > bxmax else bxmax,
            aymax if aymax > bymax else bymax,
            azmax if azmax > bzmax else bzmax,
        )

        self.left[new_parent] = old_leaf
        self.right[new_parent] = leaf_node
        self.parent[old_leaf] = new_parent
        self.parent[leaf_node] = new_parent

        if parent == -1:
            return new_parent

        if self.left[parent] == old_leaf:
            self.left[parent] = new_parent
        else:
            self.right[parent] = new_parent

        self.parent[new_parent] = parent
        self._fix_upwards(parent)
        return root

    # ------------------------------------------------------------------
    # removal (FAST)
    # ------------------------------------------------------------------

    def remove(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is not None:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])
        else:
            mid = self.rows.mats.name2idx[mat]

        try:
            found = self.leaf_index.pop((mid, rid))
        except KeyError:
            raise KeyError("[ERROR] BVH.remove() failed: row not found in BVH")

        parent = self.parent[found]
        if parent == -1:
            self.root = -1
            return

        sibling = self.right[parent] if self.left[parent] == found else self.left[parent]
        grand = self.parent[parent]

        if grand == -1:
            self.root = sibling
            self.parent[sibling] = -1
        else:
            if self.left[grand] == parent:
                self.left[grand] = sibling
            else:
                self.right[grand] = sibling
            self.parent[sibling] = grand
            self._fix_upwards(grand)

    # ------------------------------------------------------------------
    # find
    # ------------------------------------------------------------------

    def find(self, pos:POS=None) -> tuple[str, int, "NDArray[ROW.DTYPE]"]:
        if self.root == -1:
            raise LookupError("[ERROR] BVH.find() failed: empty BVH")

        x, y, z = pos
        stack = [self.root]

        xminL = self.xmin; yminL = self.ymin; zminL = self.zmin
        xmaxL = self.xmax; ymaxL = self.ymax; zmaxL = self.zmax
        leftL = self.left; rightL = self.right
        leaf_midL = self.leaf_mid; leaf_ridL = self.leaf_rid
        rows_arr = self.rows.array
        idx2name = self.rows.mats.idx2name

        while stack:
            n = stack.pop()
            if n == -1:
                continue

            if not (xminL[n] <= x < xmaxL[n] and yminL[n] <= y < ymaxL[n] and zminL[n] <= z < zmaxL[n]):
                continue

            mid = leaf_midL[n]
            if mid != -1:
                rid = leaf_ridL[n]
                row = rows_arr[mid][rid]
                if ROW.CONTAINS(row=row, pos=pos):
                    return idx2name[mid], rid, row
                continue

            l = leftL[n]
            r = rightL[n]

            if l != -1 and (xminL[l] <= x < xmaxL[l] and yminL[l] <= y < ymaxL[l] and zminL[l] <= z < zmaxL[l]):
                stack.append(l)
            if r != -1 and (xminL[r] <= x < xmaxL[r] and yminL[r] <= y < ymaxL[r] and zminL[r] <= z < zmaxL[r]):
                stack.append(r)

        raise LookupError("[ERROR] BVH.find() failed: point not found (partition invariant violated or BVH not updated)")
















################################################################################
# FILE 11/21: utils/bvh.py (END)
################################################################################


################################################################################
# FILE 12/21: utils/event.py (START)
################################################################################

from __future__ import annotations
from typing import Any, Callable
from dataclasses import dataclass, field
from .event import Event
from .schedule import Schedule



@dataclass(order=True)
class Event:
    due_ns: int
    seq: int
    callback: Callable[..., Any] = field(compare=False)
    args: tuple[Any, ...] = field(default_factory=tuple, compare=False)
    kwargs: dict[str, Any] = field(default_factory=dict, compare=False)
    cancelled: bool = field(default=False, compare=False)


class Handler:
    __slots__ = ("_scheduler", "_event")

    def __init__(self, scheduler: "Schedule", event: Event) -> None:
        self._scheduler = scheduler
        self._event = event

    def cancel(self) -> bool:
        return self._scheduler.cancel(self)


################################################################################
# FILE 12/21: utils/event.py (END)
################################################################################


################################################################################
# FILE 13/21: utils/includes.py (START)
################################################################################

from __future__ import annotations  # MUST BE FIRST

# EXCEPTION IMPORTS
from .timer import Timer, time      # NON SORTED -> HERE BECAUSE Timer IS USED IMMEDIATELY
timer = Timer()

# IMPORTS FROM STANDARD LIBRARY AND THIRD-PARTY LIBRARIES
from typing import TYPE_CHECKING, Any, Iterator, TypeVar, Generic, Union, Tuple, List, Dict, Callable, Optional
from pathlib import Path
from numpy.typing import NDArray
from PIL import Image, ImageDraw, ImageFont


# SIMPLE IMPORTS
import math
import numpy as np
import torch 
import heapq
import threading
import json
import time
import pathlib
import sys
import os
import random
import shutil
import datetime
import bisect
import pygame
import moderngl
import traceback
import stat



# my own modules (utils)
from .types import POS, SIZE


# Exports
__all__ = [
    "math",
    "time",
    "np",
    "NDArray",
    "torch",
    "TYPE_CHECKING",
    "annotations",
    "Any",
    "Iterator",
    "TypeVar",
    "Generic",
    "Union",
    "Tuple",
    "List",
    "Dict",
    "Callable",
    "Optional",
    "Image",
    "ImageDraw",
    "ImageFont",
    "Timer",
    "heapq",
    "threading",
    "json",
    "Path",
    "POS",
    "SIZE",
    "pathlib",
    "sys",
    "os",
    "random",
    "shutil",
    "datetime",
    "bisect",
    "pygame",
    "moderngl",
    "timer", # include the instance timer -> can be used as utils.timer
    "traceback",
    "stat",
]


timer.print(msg=f"utils/includes.py: {len(__all__)} modules loaded in")
timer.reset()

################################################################################
# FILE 13/21: utils/includes.py (END)
################################################################################


################################################################################
# FILE 14/21: utils/request.py (START)
################################################################################

import time
import urllib.request
import urllib.error
import json


class Request:
    def __init__(self, url: str = None, timeout: int = 600, retries: int = 3, data=None, method: str = None) -> None:
        self.timeout = timeout
        self.retries = retries
        self._retries = retries
        self.url = url
        self.data = data
        self.method = method

        self.init()

    def init(self) -> None:
        self.request = urllib.request.Request(url=self.url, data=self.data, method=self.method)

    def header(self, key: str = None, value: str = None) -> None:
        self.request.add_header(key, value)

    def open(self) -> dict:
        try:
            with urllib.request.urlopen(self.request, timeout=self.timeout) as response:
                raw = response.read().decode("utf-8", errors="replace")
                try:
                    return json.loads(raw) if raw else {}
                
                except json.JSONDecodeError as e:
                    raise RuntimeError(f"[ERROR] invalid JSON response for {self.url}\n{e!r}\n---\n{raw[:200]}") from e

        except urllib.error.HTTPError as e:
            raw = e.read().decode("utf-8", errors="replace")
            retryable = (e.code == 429) or (500 <= e.code <= 599)

            if retryable and self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] {e.code} for {self.url}\n{raw}") from e

        except (urllib.error.URLError, TimeoutError, OSError) as e:
            if self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] request failed for {self.url}\n{e!r}") from e
        
        except Exception as e:
            raise RuntimeError(f"[ERROR] unexpected error for {self.url}\n{e!r}") from e

################################################################################
# FILE 14/21: utils/request.py (END)
################################################################################


################################################################################
# FILE 15/21: utils/schedule.py (START)
################################################################################

import threading
from typing import Any, Callable, Optional
import heapq
from .timer import Timer, now
from .event import Event, Handler



class Schedule:
    def __init__(self) -> None:
        self._timer = Timer()

        self._lock = threading.Lock()
        self._cv = threading.Condition(self._lock)
        self._pq: list[Event] = []
        self._seq = 0

        self._worker: Optional[threading.Thread] = None
        self._stop = False
        self._running = False

        self.start()

    def start(self) -> None:
        with self._lock:
            if self._running:
                return
            self._stop = False
            self._worker = threading.Thread(target=self._run, name="SchedulerWorker", daemon=True)
            self._running = True
            self._worker.start()

    def stop(self) -> None:
        with self._lock:
            if not self._running:
                return
            self._stop = True
            self._cv.notify_all()

        if self._worker:
            self._worker.join(timeout=2.0)

        with self._lock:
            self._running = False
            self._worker = None

    def schedule(self, ns: int=None, fn: Callable[..., Any]=None, *args: Any, **kwargs: Any) -> Handler:
        with self._lock:
            self._seq += 1
            ev = Event(due_ns=ns, seq=self._seq, callback=fn, args=args, kwargs=kwargs)
            heapq.heappush(self._pq, ev)
            self._cv.notify_all()
            return Handler(self, ev)

    def new(self, seconds:float=None, fn:Callable[..., Any]=None, delay=False, *args: Any, **kwargs: Any) -> Handler:
        if delay==True:
            ns = now() + int(seconds * 1e9)
        if delay==False:
            ns = int(seconds * 1e9)
        return self.schedule(ns=ns, fn=fn, *args, **kwargs)
    

    def cancel(self, handle: Handler) -> bool:
        with self._lock:
            if handle._event.cancelled:
                return False
            handle._event.cancelled = True
            self._cv.notify_all()
            return True

    def _run(self) -> None:
        while True:
            with self._lock:
                # Wait until there is work or stop requested
                while not self._pq and not self._stop:
                    self._cv.wait()

                if self._stop:
                    return

                # Drop cancelled events at head
                while self._pq and self._pq[0].cancelled:
                    heapq.heappop(self._pq)

                if not self._pq:
                    continue

                ev = self._pq[0]
                due = ev.due_ns

            # 2) Wait until deadline (no lock held)
            self._timer.waitns(due)

            # 3) Pop-and-execute if still valid
            with self._lock:
                if self._stop:
                    return

                if not self._pq:
                    continue
                if self._pq[0] is not ev:
                    continue

                heapq.heappop(self._pq)
                if ev.cancelled:
                    continue

            try:
                ev.callback(*ev.args, **ev.kwargs)
            except Exception as e:
                # Keep scheduler alive; replace with logging if desired
                print(f"[Schedule] callback error: {e!r}")






















# ============================================================
# Example usage
# ============================================================

if __name__ == "__main__":
    import time

    sched = Schedule()
    def hello(who:str=None, n:int=1) -> None:
        print(f"{time.perf_counter():.3f} hello {who} x{n}")
    def test(who:str=None,  n:int=1) -> None:
        print(who, n*n)

    h1 = sched.new(seconds=0.050, fn=test, who="A", n=2, delay=True)
    h2 = sched.new(seconds=0.120, fn=hello, who="B", n=3, delay=True)
    h3 = sched.new(seconds=0.080, fn=test, who="C", n=1, delay=True)
    h2.cancel()
    futuretime = time.perf_counter() + 0.100
    h4 = sched.new(seconds=futuretime, fn=hello, who="D", n=4, delay=False)
    h5 = sched.new(seconds=futuretime, fn=test, who="E", n=5, delay=False)
    h6 = sched.new(seconds=futuretime, fn=hello, who="F", n=6, delay=False)


    time.sleep(0.2)
    sched.stop()

################################################################################
# FILE 15/21: utils/schedule.py (END)
################################################################################


################################################################################
# FILE 16/21: utils/timer.py (START)
################################################################################

from __future__ import annotations
import time



class Timer:
    def __init__(self) -> None:
        self.coarse_ns = 2_000_000
        self.spin_ns = 1_000_000

        self.start()

    def nowns(self) -> int:  # can be used as Timer().nowns()
        return time.perf_counter_ns()
    
    @staticmethod   # can be used as Timer.now()
    def now() -> float:
        return time.perf_counter_ns()

    def start(self) -> int:
        self.started = self.nowns()
        self.t0 = self.started
        self.delta = []
        self.times = []
        return self.t0
    
    def lap(self) -> int:
        t1 = self.nowns()
        t0 = self.t0
        self.t0 = t1
        dt = round((t1 - t0) / 1e9, 6) # seconds
        self.delta.append(dt)
        self.times.append(t1)
        return dt       # time since last lap in seconds
    
    def stop(self) -> int:
        self.lap()
        first = self.started
        last = self.times[-1]
        t = round((last - first) / 1e9, 6) # seconds with 6 decimal places (microseconds) 
        return t        # total since started
    
    def print(self, msg:str=None) -> None:
        self.lap()
        txt = f"lap {len(self.delta)}: {self.delta[-1]} seconds, total {round((self.times[-1] - self.started) / 1e9, 6)} seconds"
        if msg is not None:
            txt = f"{msg}: {txt}"
        print(txt)

    def waitns(self, deadline_ns: int) -> None:
        coarse_ns = self.coarse_ns
        spin_ns = self.spin_ns

        while True:
            n = self.nowns()
            remaining = deadline_ns - n
            if remaining <= 0:
                return

            # FAR: sleep until within coarse_ns
            if remaining > coarse_ns:
                time.sleep((remaining - coarse_ns) / 1e9)
                continue

            # NEAR: yield until within spin_ns
            if remaining > spin_ns:
                time.sleep(0)
                continue

            # FINAL: busy-spin
            while self.nowns() < deadline_ns:
                pass
            return

    def wait(self, seconds: float) -> None:
        if seconds <= 0:
            return
        self.waitns(self.nowns() + int(seconds * 1e9))

    def reset(self) -> int:
        t = self.stop()
        self.start()
        return t  # total since started before reset


now = Timer.now # now: now() returns the current time in nanoseconds

################################################################################
# FILE 16/21: utils/timer.py (END)
################################################################################


################################################################################
# FILE 17/21: utils/types.py (START)
################################################################################

from typing import TypeAlias
POS: TypeAlias = tuple[int, int, int]
SIZE: TypeAlias = tuple[int, int, int]

__all__ = [
    "POS",
    "SIZE",
]

################################################################################
# FILE 17/21: utils/types.py (END)
################################################################################


################################################################################
# FILE 18/21: world/__init__.py (START)
################################################################################

from .rows import ROWS, rows
from .row import ROW
from .materials import MATERIALS, Materials, Material

from utils import *
from world import *
from bundle import *

__all__ = [
    "MATERIALS",
    "Materials",
    "Material",
    "ROW",
    "ROWS",
    "rows",
]

################################################################################
# FILE 18/21: world/__init__.py (END)
################################################################################


################################################################################
# FILE 19/21: world/materials.py (START)
################################################################################
















class MATERIALS:
    TYPES = {
        "INVIS": 0,     # start at 16384                # invisible
        "TRANS": 1,     # start at 32768                # transparent
        "SOLID": 2,     # start at 65536                # solid
        "ROCKS": 3,     # start at 4294967296           # indestructible
    }

    DATA  = {
        "AIR":      (16384+0,     TYPES["INVIS"]),

        "WATER":    (32768+0,     TYPES["TRANS"]), 
        "LAVA":     (32768+1,     TYPES["TRANS"]),
        "GLASS":    (32768+2,     TYPES["TRANS"]),

        "STONE":    (65536+0,     TYPES["SOLID"]),
        "OBSIDIAN": (65536+1,     TYPES["SOLID"]),

        "BEDROCK":  (4294967296+0,TYPES["ROCKS"]),
    }

    IDX = {name: i for i, name in enumerate(DATA.keys())}

    NUM = len(DATA)

class Material:
    def __init__(self, name:str=None) -> None:
        self.id, self.type = MATERIALS.DATA.get(name, (None, None)) 
        self.idx = MATERIALS.IDX.get(name, None) 
        if self.id is None or self.type is None or self.idx is None:
            raise ValueError(f"Invalid material name: {name}")

    def isrocks(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

    def issolid(self) -> bool:
        return self.type == MATERIALS.TYPES["SOLID"]
    
    def istrans(self) -> bool:
        return self.type == MATERIALS.TYPES["TRANS"]
    
    def isinvisible(self) -> bool:
        return self.type == MATERIALS.TYPES["INVIS"]
    
    def isindestructible(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

class Materials:
    idx2name = {idx: name for name, idx in MATERIALS.IDX.items()}
    name2idx = MATERIALS.IDX

    name2id  = {name: pair[0] for name, pair in MATERIALS.DATA.items()}
    id2name  = {pair[0]: name for name, pair in MATERIALS.DATA.items()}

    # the one you actually need:
    id2idx   = {pair[0]: MATERIALS.IDX[name] for name, pair in MATERIALS.DATA.items()}
    idx2id   = {MATERIALS.IDX[name]: pair[0] for name, pair in MATERIALS.DATA.items()}


    def __init__(self) -> None:
        for name in MATERIALS.DATA.keys():
            setattr(self, name.lower(), Material(name=name))

    def idx(self, name: str = None, id: int = None) -> int:
        if (name is None) == (id is None):
            raise ValueError("Provide exactly one of name or id")
        return self.name2idx[name] if name is not None else self.id2idx[id]

    def id(self, name: str = None, idx: int = None) -> int:
        if (name is None) == (idx is None):
            raise ValueError("Provide exactly one of name or idx")
        return self.name2id[name] if name is not None else self.idx2id[idx]

    def name(self, id: int = None, idx: int = None) -> str:
        if (id is None) == (idx is None):
            raise ValueError("Provide exactly one of id or idx")
        return self.id2name[id] if id is not None else self.idx2name[idx]


################################################################################
# FILE 19/21: world/materials.py (END)
################################################################################


################################################################################
# FILE 20/21: world/row.py (START)
################################################################################

from __future__ import annotations
import stat
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass



import numpy as np
from numpy.typing import NDArray


from utils.types import SIZE, POS
from world.materials import Material, Materials





class ROW:
    DTYPE = np.uint64
    SHAPE = (4, 4)
    NBITS = DTYPE(0).nbytes * 8                      # -> 64 bits

    XBITS = 20
    YBITS = 20
    ZBITS = 16
    if XBITS + YBITS + ZBITS + 1 > NBITS:
        raise ValueError("bit allocation error")

    XMIN = 0
    YMIN = 0
    ZMIN = 0
    XMAX = 2**XBITS
    YMAX = 2**YBITS
    ZMAX = 2**ZBITS
    NMAX = XMAX * YMAX * ZMAX
    

    # POSITIONS (MIN)  stored in row 0
    IDS_X0 = (0, 0)
    IDS_Y0 = (0, 1)
    IDS_Z0 = (0, 2)

    # POSITIONS (MAX)  stored in row 1
    IDS_X1 = (1, 0)
    IDS_Y1 = (1, 1)
    IDS_Z1 = (1, 2)

    # DIMENSIONS  stored in row 2
    IDS_DX = (2, 0)
    IDS_DY = (2, 1)
    IDS_DZ = (2, 2)

    # METADATA  stored in row 3
    IDS_ID    = (3, 0)
    IDS_MAT   = (3, 1)
    IDS_FLAGS = (3, 2)

    ENCODE_DIRTY        = DTYPE(1 << 0)
    ENCODE_ALIVE        = DTYPE(1 << 1)
    ENCODE_SOLID        = DTYPE(1 << 2)
    ENCODE_DESTRUCTABLE = DTYPE(1 << 3)
    ENCODE_VISIBLE      = DTYPE(1 << 4)

    SENTINEL = np.iinfo(DTYPE).max
    ARRAY: NDArray[DTYPE] = np.zeros(SHAPE, dtype=DTYPE)
    for i in range(4):
        for j in range(4):
            ARRAY[i, j] = SENTINEL  # initialize all to -1 -> invalid
    _ID = 0
    
    @staticmethod # get min position (x0, y0, z0)   
    def P0(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X0]), int(row[*ROW.IDS_Y0]), int(row[*ROW.IDS_Z0]))
    
    @staticmethod # get max position (x1, y1, z1)
    def P1(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X1]), int(row[*ROW.IDS_Y1]), int(row[*ROW.IDS_Z1]))
    
    @staticmethod # get size (dx, dy, dz)
    def SIZE(row:NDArray[DTYPE]=None) -> SIZE:
        return (int(row[*ROW.IDS_DX]), int(row[*ROW.IDS_DY]), int(row[*ROW.IDS_DZ]))
    
    @staticmethod # get material id
    def MID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_MAT])
    
    @staticmethod # get meterial string name
    def MAT(row:NDArray[DTYPE]=None) -> str:
        return Materials.id2name[ROW.MID(row=row)]
    
    @staticmethod # get row id
    def RID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_ID])
    
    @staticmethod # get flags
    def FLAGS(row:NDArray[DTYPE]=None) -> tuple[bool, bool, bool, bool, bool]:
        flags: int = int(row[*ROW.IDS_FLAGS])
        dirty, alive, solid, destr, visib = ROW.DECODE(flags=flags)
        return (dirty, alive, solid, destr, visib)
    
    @staticmethod # get volume (dx * dy * dz)
    def VOLUME(row:NDArray[DTYPE]=None) -> int:
        dx, dy, dz = ROW.SIZE(row=row)
        return dx * dy * dz

    @staticmethod # make a copy of the template array
    def COPY() -> NDArray[DTYPE]:
        return np.copy(ROW.ARRAY)
    
    @staticmethod
    def CLIP(pos:POS=None) -> POS:
        x, y, z = pos
        cx = min(max(x, ROW.XMIN), ROW.XMAX - 1)
        cy = min(max(y, ROW.YMIN), ROW.YMAX - 1)
        cz = min(max(z, ROW.ZMIN), ROW.ZMAX - 1)
        pos: POS = (cx, cy, cz)
        return pos
    
    @staticmethod
    def SORT(p0:POS=None, p1:POS=None) -> tuple[POS, POS]:
        x0, y0, z0 = p0
        x1, y1, z1 = p1
        sx0, sx1 = (min(x0, x1), max(x0, x1))
        sy0, sy1 = (min(y0, y1), max(y0, y1))
        sz0, sz1 = (min(z0, z1), max(z0, z1))
        p0: POS = (sx0, sy0, sz0)
        p1: POS = (sx1, sy1, sz1)
        return (p0, p1)
    
    @staticmethod
    def CONTAINS(row: NDArray[DTYPE], pos: POS) -> bool:
        x, y, z = pos
        x0, y0, z0 = ROW.P0(row=row)
        x1, y1, z1 = ROW.P1(row=row)
        return (
            (x0 <= x < x1) and
            (y0 <= y < y1) and
            (z0 <= z < z1)
        )
    
    @staticmethod
    def MERGE(row0: NDArray[DTYPE]=None, row1: NDArray[DTYPE]=None) -> tuple[bool, bool, bool]:
        if row0[*ROW.IDS_MAT] != row1[*ROW.IDS_MAT]:
            return (False, False, False)

        x0a, y0a, z0a = ROW.P0(row=row0)
        x1a, y1a, z1a = ROW.P1(row=row0)
        x0b, y0b, z0b = ROW.P0(row=row1)
        x1b, y1b, z1b = ROW.P1(row=row1)
        p00 = (x0a, y0a, z0a)
        p01 = (x1a, y1a, z1a)
        p10 = (x0b, y0b, z0b)
        p11 = (x1b, y1b, z1b)

        def overlap(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a0 < b1 and b0 < a1
        def touches(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a1 == b0 or b1 == a0

        touching = [False, False, False]
        overlaps = [False, False, False]

        for i in range(3):
            if overlap(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                overlaps[i] = True
            elif touches(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                touching[i] = True
            else:
                return (False, False, False)  # separated on this axis
            
        if sum(touching) == 1 and sum(overlaps) == 2:
            return tuple(touching)  # (x_touch, y_touch, z_touch)

        return (False, False, False)
    

    @staticmethod
    def ENCODE(dirty:bool=None, alive:bool=None, solid:bool=None, destructable:bool=None, visible:bool=None) -> int:
        f: int = 0
        if dirty:
            f |= int(ROW.ENCODE_DIRTY)
        if alive:
            f |= int(ROW.ENCODE_ALIVE)
        if solid:
            f |= int(ROW.ENCODE_SOLID)
        if destructable:
            f |= int(ROW.ENCODE_DESTRUCTABLE)
        if visible:
            f |= int(ROW.ENCODE_VISIBLE)
        return f
    
    @staticmethod
    def DECODE(flags) -> tuple[bool, bool, bool, bool, bool]:
        f: int = int(flags)

        dirty = (f & int(ROW.ENCODE_DIRTY)) != 0
        alive = (f & int(ROW.ENCODE_ALIVE)) != 0
        solid = (f & int(ROW.ENCODE_SOLID)) != 0
        destr = (f & int(ROW.ENCODE_DESTRUCTABLE)) != 0
        visib = (f & int(ROW.ENCODE_VISIBLE)) != 0
        return dirty, alive, solid, destr, visib








                

    @staticmethod
    def new(p0:POS=None, p1:POS=None, mat:str=None, rid:int=None, dirty:bool=True, alive:bool=True) -> NDArray[DTYPE]:
        p0, p1 = ROW.SORT(p0=ROW.CLIP(pos=p0), p1=ROW.CLIP(pos=p1))
        mat: Material = Material(name=mat)
        flags: int = ROW.ENCODE(dirty=dirty, alive=alive, solid=mat.issolid(), destructable=not mat.isindestructible(), visible=not mat.isinvisible())
        
        copy: NDArray[ROW.DTYPE] = ROW.COPY()

        # POS0
        copy[*ROW.IDS_X0]    = np.uint64(p0[0])
        copy[*ROW.IDS_Y0]    = np.uint64(p0[1])
        copy[*ROW.IDS_Z0]    = np.uint64(p0[2])
        # POS1
        copy[*ROW.IDS_X1]    = np.uint64(p1[0])
        copy[*ROW.IDS_Y1]    = np.uint64(p1[1])
        copy[*ROW.IDS_Z1]    = np.uint64(p1[2])
        # SIZE
        copy[*ROW.IDS_DX]    = np.uint64(p1[0] - p0[0])
        copy[*ROW.IDS_DY]    = np.uint64(p1[1] - p0[1])
        copy[*ROW.IDS_DZ]    = np.uint64(p1[2] - p0[2])
        # METADATA
        copy[*ROW.IDS_ID]    = np.uint64(rid)       # stores now the row index within material array instead of global unique id
        copy[*ROW.IDS_MAT]   = np.uint64(mat.id)
        copy[*ROW.IDS_FLAGS] = np.uint64(flags)

        if any(v < 0 for v in (copy[*ROW.IDS_DX], copy[*ROW.IDS_DY], copy[*ROW.IDS_DZ])):
            raise ValueError("p1 must be greater than or equal to p0 on all axes")
        if any(v < 0 for v in (copy[*ROW.IDS_X0], copy[*ROW.IDS_Y0], copy[*ROW.IDS_Z0])):
            raise ValueError("positions must be non-negative")
        return copy
    
    

################################################################################
# FILE 20/21: world/row.py (END)
################################################################################


################################################################################
# FILE 21/21: world/rows.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass


import numpy as np
from numpy.typing import NDArray

from world.row import ROW
from utils.bvh import BVH
from world.materials import Materials, MATERIALS
from utils.types import POS, SIZE





class ROWS:
    SIZE = 65536
    def __init__(self) -> None:
        self.mats = Materials()
        self.bvh = BVH(rows=self)
        self.n:dict[int, int] = {mid: 0 for mid in range(MATERIALS.NUM)}  # number of valid rows per material
        self.m = 0  # for the total number of rows used

        self.array: NDArray[ROW.DTYPE] = np.full((MATERIALS.NUM, ROWS.SIZE, *ROW.SHAPE), fill_value=ROW.SENTINEL, dtype=ROW.DTYPE)
        self.shape = self.array.shape
        self.nbytes = self.array.nbytes
        self.gbytes = self.nbytes / (1024**3)

        mat = "STONE"
        self.append(p0=(ROW.XMIN, ROW.YMIN, ROW.ZMIN), p1=(ROW.XMAX, ROW.YMAX, ROW.ZMAX), mat=mat)  # alive and dirty by default are true so no need to specify : easier to use now!!!
        self.size = ROW.XMAX - ROW.XMIN, ROW.YMAX - ROW.YMIN, ROW.ZMAX - ROW.ZMIN

    def newn(self, mat:str=None) -> int:
        mid: int = Materials.name2idx[mat]
        n: int = self.n[mid]
        self.n[mid] += 1
        self.m += 1
        return n
    
    def deln(self, mat: str=None) -> int:
        if mat is None:
            raise ValueError("material must be specified")
        mid = Materials.name2idx[mat]
        if self.n[mid] <= 0:
            raise ValueError("no rows to free")
        self.n[mid] -= 1
        self.m -= 1
        return self.n[mid]
            

    def append(self, p0:POS=None, p1:POS=None, mat:str=None, dirty:bool=True, alive:bool=True) -> ROWS:
        mid: int = Materials.name2idx[mat]
        rid: int = self.newn(mat=mat)
        row = ROW.new(p0=p0, p1=p1, mat=mat, rid=rid, dirty=dirty, alive=alive)
        self.array[mid][rid] = row  # added rid=n so that bvh can use it when i provide a row as argument
        self.bvh.insert(row=row)  # insert into bvh index
        return self
    
    def delete(self, index:int=None, mat:str=None, row:NDArray[ROW.DTYPE]=None) -> ROWS:
        if row is not None and index is None and mat is None:
            mat = ROW.MAT(row=row)
            index = ROW.RID(row=row)
        mid = Materials.name2idx[mat]
        n = self.n[mid]
        if index < 0 or index >= n:
            raise IndexError("index out of range")
        last = n - 1
        self.bvh.remove(mat=mat, rid=index)

        if index != last:
            self.bvh.remove(mat=mat, rid=last)
            self.array[mid][index] = self.array[mid][last]
            self.array[mid][index][*ROW.IDS_ID] = np.uint64(index)
            self.bvh.insert(mat=mat, rid=index)

        self.array[mid][last] = ROW.ARRAY
        self.deln(mat=mat)
        return self
    
    def volume(self) -> int:
        total = 0
        for mid in range(MATERIALS.NUM):
            n = self.n[mid]
            for rid in range(n):
                row = self.array[mid][rid]
                total += ROW.VOLUME(row=row)
        return total

    def find(self, pos:POS=None) -> tuple[str, int, NDArray[ROW.DTYPE]]:
        mat, rid, row = self.bvh.find(pos=pos)
        return (mat, rid, row)
    
    def get(self, mat:str=None, rid:int=None) -> NDArray[ROW.DTYPE]:
        return self.array[Materials.name2idx[mat]][rid]

    def nrows(self, mat:str=None) -> int:
        return self.n[Materials.name2idx[mat]]
    
    def split(self, pos:POS=None, mat:str=None) -> tuple[int, int]:
        mat0, rid, row = self.find(pos=pos)
        p0 = ROW.P0(row=row)
        p1 = ROW.P1(row=row)
        self.delete(row=row)  # delete the original row
        x0, y0, z0 = p0
        x1, y1, z1 = pos
        x2, y2, z2 =x1+1, y1+1, z1+1
        x3, y3, z3 = p1

        xs = [[x0, x1], [x1, x2], [x2, x3]]
        ys = [[y0, y1], [y1, y2], [y2, y3]]
        zs = [[z0, z1], [z1, z2], [z2, z3]]

        print(f" - Splitting row id={rid} mat={mat0} at pos={pos} into 27 sub-rows...")
        print(f"   Original row p0={p0} p1={p1}")
        print(xs, ys, zs)
        succes = 0
        fails = 0
        for i, (X0, X1) in enumerate(xs):
            for j, (Y0, Y1) in enumerate(ys):
                for k, (Z0, Z1) in enumerate(zs):
                    size = (X1 - X0) * (Y1 - Y0) * (Z1 - Z0)
                    if size > 0:
                        if i == 1 and j == 1 and k == 1:    # the center cube should get the new material (its the one containing pos)
                            self.append(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat) # use new the material given for the new row
                            succes += 1
                        else:
                            self.append(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat0) # use the old material for the other rows
                            succes += 1
                    else:
                        print(f" - WARNING: zero size cube skipped during split at {(X0, Y0, Z0)} -> {(X1, Y1, Z1)}")
                        fails += 1


        print(f"   Split completed with {succes} new rows created, {fails} zero-size cubes skipped.")
        
        



    

    def __repr__(self) -> str:
        return self.__str__()

    def __str__(self) -> str:
        n = self.nrows(mat="STONE")
        return f"ROWS(shape={self.shape}, nbytes={self.nbytes}, gbytes={self.gbytes:.3f} with {n} valid rows)"





rows = ROWS()

################################################################################
# FILE 21/21: world/rows.py (END)
################################################################################


################################################################################
### CAPTURED OUTPUT (STDOUT/STDERR) ###
################################################################################

STEP 1 :  3D grid partition built: lap 3: 5.131036 seconds, total 5.164627 seconds
 - All random CONTAINS checks passed. Successes: 1000, Fails: 0 is a succes percentage of 100.00% adn per lookup 194.89 lookups/second
 - Random CONTAINS checks completed in: lap 4: 0.433203 seconds, total 5.597829 seconds
 - Now deleting all rows...
 - All 10000 rows deleted in: lap 5: 0.348127 seconds, total 5.945957 seconds
STEP 2 : Rebuilding rows after deletion...
 - second time 3D grid partition built: lap 6: 0.533564 seconds, total 6.479521 seconds
 - All random CONTAINS checks passed. Successes: 1000, Fails: 0 is a succes percentage of 100.00% adn per lookup 1874.19 lookups/second
 - Second random CONTAINS checks completed in: lap 7: 0.172533 seconds, total 6.652054 seconds
FINALLY: TESTS PASSED SUCCESSFULLY!
STEP 3 : Now testing SPLIT functionality...
WORLD VOLUME BEFORE:  72056357089509375
(1048576, 1048576, 65536)
 - Splitting row id=0 mat=STONE at pos=(43127, 24842, 14652) into 27 sub-rows...
   Original row p0=(0, 0, 0) p1=(1048575, 1048575, 65535)
[[0, 43127], [43127, 43128], [43128, 1048575]] [[0, 24842], [24842, 24843], [24843, 1048575]] [[0, 14652], [14652, 14653], [14653, 65535]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 1/10 passed.
 - Splitting row id=25 mat=STONE at pos=(550745, 704552, 45483) into 27 sub-rows...
   Original row p0=(43128, 24843, 14653) p1=(1048575, 1048575, 65535)
[[43128, 550745], [550745, 550746], [550746, 1048575]] [[24843, 704552], [704552, 704553], [704553, 1048575]] [[14653, 45483], [45483, 45484], [45484, 65535]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 2/10 passed.
 - Splitting row id=48 mat=STONE at pos=(832067, 939394, 23645) into 27 sub-rows...
   Original row p0=(550746, 704553, 14653) p1=(1048575, 1048575, 45483)
[[550746, 832067], [832067, 832068], [832068, 1048575]] [[704553, 939394], [939394, 939395], [939395, 1048575]] [[14653, 23645], [23645, 23646], [23646, 45483]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 3/10 passed.
 - Splitting row id=44 mat=STONE at pos=(842102, 87622, 57242) into 27 sub-rows...
   Original row p0=(550746, 24843, 45484) p1=(1048575, 704552, 65535)
[[550746, 842102], [842102, 842103], [842103, 1048575]] [[24843, 87622], [87622, 87623], [87623, 704552]] [[45484, 57242], [57242, 57243], [57243, 65535]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 4/10 passed.
 - Splitting row id=25 mat=STONE at pos=(483372, 234656, 33910) into 27 sub-rows...
   Original row p0=(43128, 24843, 14653) p1=(550745, 704552, 45483)
[[43128, 483372], [483372, 483373], [483373, 550745]] [[24843, 234656], [234656, 234657], [234657, 704552]] [[14653, 33910], [33910, 33911], [33911, 45483]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 5/10 passed.
 - Splitting row id=81 mat=STONE at pos=(759813, 389999, 50050) into 27 sub-rows...
   Original row p0=(550746, 87623, 45484) p1=(842102, 704552, 57242)
[[550746, 759813], [759813, 759814], [759814, 842102]] [[87623, 389999], [389999, 390000], [390000, 704552]] [[45484, 50050], [50050, 50051], [50051, 57242]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 6/10 passed.
 - Splitting row id=31 mat=STONE at pos=(218448, 742835, 21056) into 27 sub-rows...
   Original row p0=(43128, 704553, 14653) p1=(550745, 1048575, 45483)
[[43128, 218448], [218448, 218449], [218449, 550745]] [[704553, 742835], [742835, 742836], [742836, 1048575]] [[14653, 21056], [21056, 21057], [21057, 45483]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 7/10 passed.
 - Splitting row id=67 mat=STONE at pos=(936105, 892651, 15828) into 27 sub-rows...
   Original row p0=(832068, 704553, 14653) p1=(1048575, 939394, 23645)
[[832068, 936105], [936105, 936106], [936106, 1048575]] [[704553, 892651], [892651, 892652], [892652, 939394]] [[14653, 15828], [15828, 15829], [15829, 23645]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 8/10 passed.
 - Splitting row id=108 mat=STONE at pos=(177961, 404013, 40722) into 27 sub-rows...
   Original row p0=(43128, 234657, 33911) p1=(483372, 704552, 45483)
[[43128, 177961], [177961, 177962], [177962, 483372]] [[234657, 404013], [404013, 404014], [404014, 704552]] [[33911, 40722], [40722, 40723], [40723, 45483]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 9/10 passed.
 - Splitting row id=48 mat=STONE at pos=(959398, 825585, 52257) into 27 sub-rows...
   Original row p0=(550746, 704553, 45484) p1=(1048575, 1048575, 65535)
[[550746, 959398], [959398, 959399], [959399, 1048575]] [[704553, 825585], [825585, 825586], [825586, 1048575]] [[45484, 52257], [52257, 52258], [52258, 65535]]
   Split completed with 27 new rows created, 0 zero-size cubes skipped.
 - SPLIT test 10/10 passed.
Material AIR has 10 rows after SPLIT tests.
Material WATER has 0 rows after SPLIT tests.
Material LAVA has 0 rows after SPLIT tests.
Material GLASS has 0 rows after SPLIT tests.
Material STONE has 251 rows after SPLIT tests.
Material OBSIDIAN has 0 rows after SPLIT tests.
Material BEDROCK has 0 rows after SPLIT tests.
WORLD VOLUME AFTER:  72056357089509375
main.py: executed in: lap 8: 0.024446 seconds, total 6.6765 seconds

################################################################################
### END OF CAPTURED OUTPUT ###
################################################################################
# Total lines in bundle: 2198
# Total files in bundle: 21
# Generated at the time: 2026-01-29T12:27:26
--- END OF FILE ---
