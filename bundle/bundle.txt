#Time when generated: 2026-01-30T16:26:51

### PROJECT BUNDLE ###
Root: C:\VOXELS
Files included: 22


################################################################################
# FILE 1/22: __init__.py (START)
################################################################################

import utils
import world
import bundle

__all__ = world.__all__ + utils.__all__ + bundle.__all__


################################################################################
# FILE 1/22: __init__.py (END)
################################################################################


################################################################################
# FILE 2/22: __main__.py (START)
################################################################################

from main import main

if __name__ == "__main__":
    main()

################################################################################
# FILE 2/22: __main__.py (END)
################################################################################


################################################################################
# FILE 3/22: bundle/__init__.py (START)
################################################################################

from .bundle import *
from .github import *

__all__ = [
    "Bundle",
    "GitHub",
]

################################################################################
# FILE 3/22: bundle/__init__.py (END)
################################################################################


################################################################################
# FILE 4/22: bundle/bundle.py (START)
################################################################################

from __future__ import annotations
import atexit
import sys
import threading
import time
from pathlib import Path
from typing import Iterable, Optional, Set, TextIO, Callable


from .github import GitHub


# ============================================================
# Bundle builder with integrated output capture (no output.txt, no HTML)
# ============================================================

class Bundle:
    class _Tee(TextIO):
        def __init__(self, original: TextIO, buffer: list[str], lock: threading.Lock) -> None:
            self._original = original
            self._buffer = buffer
            self._lock = lock

            

        def write(self, s: str) -> int:
            n = self._original.write(s)
            with self._lock:
                self._buffer.append(s)
            return n

        def flush(self) -> None:
            self._original.flush()

        def isatty(self) -> bool:
            return getattr(self._original, "isatty", lambda: False)()

        @property
        def encoding(self):
            return getattr(self._original, "encoding", "utf-8")

    def __init__(
        self,
        *,
        root: Path | None = None,
        out: Path | None = None,
        exts: Set[str] | None = None,
        dirs: Set[str] | None = None,
        skip: Set[str] | None = None,
        max_bytes: int = 2_000_000,
        overwrite: bool = True,
        include_stderr: bool = True,
        marker_prefix: str = "### CAPTURE START ###",
        auto_end_on_exit: bool = True,
        auto_end_on_exception: bool = True,
    ) -> None:
        self.root = (root if root is not None else Path.cwd()).resolve()
        self.out = (out if out is not None else (self.root / "bundle" / "bundle.txt")).resolve()

        self.exts = exts if exts is not None else {
            ".py", ".pyi", ".txt", ".md", ".json", ".toml", ".yaml", ".yml", ".ini", ".cfg", ".bat", ".ps1", ".sh",
        }
        self.dirs = dirs if dirs is not None else {
            ".git", ".hg", ".svn", ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            "atlas", "_old", "__OLD",
        }
        self.skip = skip if skip is not None else {".DS_Store", "Thumbs.db"}
        self.max_bytes = int(max_bytes)
        self.overwrite = bool(overwrite)

        self.include_stderr = bool(include_stderr)
        self.marker_prefix = str(marker_prefix)

        self._lock = threading.Lock()
        self._buf_out: list[str] = []
        self._buf_err: list[str] = []

        self._orig_stdout: Optional[TextIO] = None
        self._orig_stderr: Optional[TextIO] = None
        self._orig_excepthook: Optional[Callable] = None
        self._ended = False

        self.start_capture()

        if auto_end_on_exit:
            atexit.register(self.stop_capture_and_write_bundle)

        if auto_end_on_exception:
            self._install_excepthook()

        self.github = GitHub

    def __enter__(self) -> "Bundle":
        return self

    def __exit__(self, exc_type, exc, tb) -> bool:
        self.stop_capture_and_write_bundle()
        self.github()
        return False

    def _install_excepthook(self) -> None:
        self._orig_excepthook = sys.excepthook

        def hooked(exctype, value, tb) -> None:
            if self._orig_excepthook is not None:
                self._orig_excepthook(exctype, value, tb)
            self.stop_capture_and_write_bundle()

        sys.excepthook = hooked  # type: ignore[assignment]

    def start_capture(self) -> None:
        self._orig_stdout = sys.stdout
        self._orig_stderr = sys.stderr

        sys.stdout = self._Tee(self._orig_stdout, self._buf_out, self._lock)  # type: ignore[assignment]
        if self.include_stderr:
            sys.stderr = self._Tee(self._orig_stderr, self._buf_err, self._lock)  # type: ignore[assignment]

        print(f"{self.marker_prefix} root={self.root.as_posix()}")

    def stop_capture_and_write_bundle(self) -> Path:
        captured = self._end_capture_get_text()
        return self.write_bundle_txt(captured_output=captured)

    def _end_capture_get_text(self) -> str:
        if self._ended:
            with self._lock:
                out_text = "".join(self._buf_out)
                err_text = "".join(self._buf_err)
            return self._combine_streams(out_text, err_text)

        self._ended = True

        if self._orig_stdout is not None:
            sys.stdout = self._orig_stdout  # type: ignore[assignment]
        if self.include_stderr and self._orig_stderr is not None:
            sys.stderr = self._orig_stderr  # type: ignore[assignment]

        if self._orig_excepthook is not None:
            sys.excepthook = self._orig_excepthook  # type: ignore[assignment]

        with self._lock:
            out_text = "".join(self._buf_out)
            err_text = "".join(self._buf_err)

        combined = self._combine_streams(out_text, err_text)

        marker_line = f"{self.marker_prefix} root={self.root.as_posix()}"
        combined = self._keep_after_marker(combined, marker_line)
        return combined

    def _combine_streams(self, out_text: str, err_text: str) -> str:
        combined = out_text
        if self.include_stderr and err_text:
            if combined and not combined.endswith("\n"):
                combined += "\n"
            combined += err_text
        return combined

    @staticmethod
    def _keep_after_marker(text: str, marker_line: str) -> str:
        idx = text.rfind(marker_line)
        if idx == -1:
            return text
        nl = text.find("\n", idx)
        if nl == -1:
            return ""
        return text[nl + 1 :]

    def write_bundle_txt(self, *, captured_output: str) -> Path:
        self.out.parent.mkdir(parents=True, exist_ok=True)
        if self.overwrite and self.out.exists():
            self.out.unlink()

        generated_at = time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())
        files = sorted(self._iter_files(self.root), key=lambda p: str(p.relative_to(self.root)).lower())

        lines: list[str] = []
        lines.append(f"#Time when generated: {generated_at}\n\n")
        lines.append("### PROJECT BUNDLE ###\n")
        lines.append(f"Root: {self.root}\n")
        lines.append(f"Files included: {len(files)}\n\n")

        for i, p in enumerate(files, start=1):
            rel = p.relative_to(self.root).as_posix()

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (START)\n")
            lines.append("#" * 80 + "\n\n")

            content = self._safe_read_text_lossy(p)
            if content and not content.endswith("\n"):
                content += "\n"
            lines.append(content)

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (END)\n")
            lines.append("#" * 80 + "\n\n")

        if captured_output.strip():
            lines.append("\n" + "################################################################################\n")
            lines.append("### CAPTURED OUTPUT (STDOUT/STDERR) ###\n")
            lines.append("################################################################################\n\n")
            lines.append(captured_output if captured_output.endswith("\n") else captured_output + "\n")
            lines.append("\n################################################################################\n")
            lines.append("### END OF CAPTURED OUTPUT ###\n")
            lines.append("################################################################################\n")

        final_text = "".join(lines)
        if not final_text.endswith("\n"):
            final_text += "\n"

        total_lines = final_text.count("\n")
        final_text += f"# Total lines in bundle: {total_lines}\n"
        final_text += f"# Total files in bundle: {len(files)}\n"
        final_text += f"# Generated at the time: {time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime())}\n"
        final_text += "--- END OF FILE ---\n"

        self.out.write_text(final_text, encoding="utf-8")
        return self.out

    def _iter_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.skip:
                continue
            if p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.max_bytes:
                    continue
            except OSError:
                continue

            yield p

    @staticmethod
    def _safe_read_text_lossy(path: Path) -> str:
        try:
            return path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            return path.read_text(encoding="utf-8", errors="replace")
        except OSError as e:
            return f"<<ERROR READING FILE: {e}>>\n"






################################################################################
# FILE 4/22: bundle/bundle.py (END)
################################################################################


################################################################################
# FILE 5/22: bundle/github.py (START)
################################################################################

import base64
import json
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional, Set

from credentials import *
from utils import Request




@dataclass(frozen=True)
class FileJob:
    local_path: Path
    repo_path: str


class GitHub:
    def __init__(
        self,
        root: Path = Path.cwd(),
        verbose: bool = True,
        workers: int = 12,
        message: str = "Publish project snapshot",
        exts: Optional[Set[str]] = None,
        dirs: Optional[Set[str]] = None,
        files: Optional[Set[str]] = None,
        bytes: int = 2_000_000,
        binary: bool = True,
    ) -> None:
        self.owner = Environ.githublogin
        self.token = Environ.githubtoken
        self.repo = "VOXELS"
        self.branch = "main"
        self.root = root.resolve()
        
        self.verbose = verbose
        self.workers = workers
        self.message = message

        self.exts = exts
        self.dirs = dirs or {
            ".git", ".hg", ".svn",
            ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            ".gradle", ".terraform",
            "atlas", "_old", "__OLD",
        }
        self.files = files or {".DS_Store", "Thumbs.db"}
        self.bytes = bytes
        self.binary = binary

        self.lock = threading.Lock()

        self.publish()

    def publish(self) -> None:
        t0 = time.perf_counter()
        if not self.token:
            raise SystemExit(f"Missing environment variable GITHUB_TOKEN.\n", f"Create a fine-grained PAT (Contents: read+write) for repo {self.owner}/{self.repo}.")

        if not self.root.exists() or not self.root.is_dir():
            raise SystemExit(f"root does not exist or is not a directory: {self.root}")

        jobs = self._build_jobs()
        self._log(f"[GITHUB] single-commit publish: {len(jobs)} files from {self.root} -> {self.owner}/{self.repo}@{self.branch}")

        head_commit_sha = self._get_branch_head_commit_sha(self.token)
        base_tree_sha = self._get_commit_tree_sha(self.token, head_commit_sha)

        path_to_blob_sha = self._create_blobs_parallel(self.token, jobs)
        new_tree_sha = self._create_tree(self.token, base_tree_sha, path_to_blob_sha)
        new_commit_sha = self._create_commit(self.token, new_tree_sha, head_commit_sha)
        self._update_branch_ref(self.token, new_commit_sha)

        dt = time.perf_counter() - t0
        self._log(f"[GITHUB] done: 1 commit, {len(jobs)} files, elapsed {dt:.2f}s. files/sec: {len(jobs)/dt:.1f}")

    def _build_jobs(self) -> list[FileJob]:
        files = sorted(self._iter_project_files(self.root), key=lambda p: str(p).lower())
        return [FileJob(p, p.relative_to(self.root).as_posix()) for p in files]

    def _iter_project_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.files:
                continue
            if self.exts is not None and p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.bytes:
                    continue
            except OSError:
                continue

            if self.binary:
                try:
                    data = p.read_bytes()
                except OSError:
                    continue
                if self._looks_binary(data):
                    continue

            yield p

    @staticmethod
    def _looks_binary(data: bytes) -> bool:
        if b"\x00" in data:
            return True
        sample = data[:8192]
        if not sample:
            return False
        bad = 0
        for b in sample:
            if b in (9, 10, 13) or 32 <= b <= 126:
                continue
            bad += 1
        return (bad / len(sample)) > 0.20

    # -----------------------------
    # GitHub API core
    # -----------------------------
    def _api_request(self, method: str, url: str, token: str, body: Optional[dict] = None) -> dict:
        data = None
        if body is not None:
            data = json.dumps(body).encode("utf-8")

        req = Request(url=url, data=data, method=method, timeout=600, retries=3)
        req.header("Authorization", f"Bearer {token}")
        req.header("Accept", "application/vnd.github+json")
        req.header("X-GitHub-Api-Version", "2022-11-28")
        if data is not None:
            req.header("Content-Type", "application/json; charset=utf-8")

        return req.open()

    def _get_branch_head_commit_sha(self, token: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/ref/heads/{self.branch}"
        j = self._api_request("GET", url, token)
        return j["object"]["sha"]

    def _get_commit_tree_sha(self, token: str, commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits/{commit_sha}"
        j = self._api_request("GET", url, token)
        return j["tree"]["sha"]

    def _create_blob(self, token: str, content_bytes: bytes) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/blobs"
        body = {"content": base64.b64encode(content_bytes).decode("ascii"), "encoding": "base64"}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_blobs_parallel(self, token: str, jobs: list[FileJob]) -> dict[str, str]:
        out: dict[str, str] = {}
        lock = threading.Lock()

        def worker(job: FileJob) -> None:
            data = job.local_path.read_bytes()
            sha = self._create_blob(token, data)
            with lock:
                out[job.repo_path] = sha
            if self.verbose:
                self._log(f"    [blob] {job.repo_path}")

        with ThreadPoolExecutor(max_workers=self.workers) as ex:
            futures = [ex.submit(worker, j) for j in jobs]
            for fut in as_completed(futures):
                fut.result()

        return out

    def _create_tree(self, token: str, base_tree_sha: str, path_to_blob_sha: dict[str, str]) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/trees"
        tree_entries = [
            {"path": path, "mode": "100644", "type": "blob", "sha": blob_sha}
            for path, blob_sha in path_to_blob_sha.items()
        ]
        body = {"base_tree": base_tree_sha, "tree": tree_entries}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_commit(self, token: str, tree_sha: str, parent_commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits"
        body = {"message": self.message, "tree": tree_sha, "parents": [parent_commit_sha]}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _update_branch_ref(self, token: str, new_commit_sha: str) -> None:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/refs/heads/{self.branch}"
        body = {"sha": new_commit_sha, "force": False}
        self._api_request("PATCH", url, token, body=body)

    def _log(self, msg: str) -> None:
        with self.lock:
            print(msg)


################################################################################
# FILE 5/22: bundle/github.py (END)
################################################################################


################################################################################
# FILE 6/22: credentials/__init__.py (START)
################################################################################

from .environ import Environ

__all__ = [
    "Environ"
]   

################################################################################
# FILE 6/22: credentials/__init__.py (END)
################################################################################


################################################################################
# FILE 7/22: credentials/environ.py (START)
################################################################################




import os



class Environ:
    githublogin = os.getenv("GITHUB_LOGIN")
    githubtoken = os.getenv("GITHUB_TOKEN")
    mailadress  = os.getenv("MAIL_ADRESS")
    phonenumber = os.getenv("PHONE_NUMBER")
    ippublic    = os.getenv("IP_PUBLIC")
    ipprivate   = os.getenv("IP_PRIVATE")
    sshkey      = os.getenv("SSH_KEY")


################################################################################
# FILE 7/22: credentials/environ.py (END)
################################################################################


################################################################################
# FILE 8/22: main.py (START)
################################################################################


from utils import *
from world import *
from bundle import *





def test1() -> None:
    rows = ROWS()
    row = rows.array[ MATERIALS.IDX["STONE"] ][0]
    rows.remove(row=row)

    cell = 20          # cube edge length
    nx = 40            # number of cells in X  -> world X size = nx*cell
    ny = 40            # number of cells in Y
    nz = 40            # number of cells in Z
    n = nx * ny * nz  # total number of cells

    timer.lap()
    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.insert(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg="STEP 1 :  3D grid partition built")

    max_x = nx * cell - 1
    max_y = ny * cell - 1
    max_z = nz * cell - 1

    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (
                random.randint(0, max_x),
                random.randint(0, max_y),
                random.randint(0, max_z),
            )
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Random CONTAINS checks completed in")

    print(" - Now deleting all rows...")
    for i in range(10000):
        row = rows.array[ MATERIALS.IDX["STONE"] ][n-1-i]
        rows.remove(row=row)
    timer.print(msg=" - All 10000 rows deleted in")
    # and now test wiht a new set adn see if it still works
    print("STEP 2 : Rebuilding rows after deletion...")
    cell = 40          # double size
    nx = 20            # half number of cells in X  -> world X size = nx*cell
    ny = 20            # half number of cells in Y
    nz = 20            # half number of cells in Z
    n = nx * ny * nz   # total number of cells (1/8th number of previous)

    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.insert(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg=" - second time 3D grid partition built")
    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (random.randint(0, max_x), random.randint(0, max_y), random.randint(0, max_z))
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Second random CONTAINS checks completed in")

def test2() -> None:
    rows = ROWS() # it has by default a large enough array to hold 10000 rows per material
    print("WORLD VOLUME BEFORE: ", rows.volume())

    # 1 row exists normally at tis point -> its created at init with STONE material
    for i in range(10):
        x = random.randint(a=1000, b=999000)
        y = random.randint(a=1000, b=999000)
        z = random.randint(a=1000, b=64000)
        rows.split(pos=(x, y, z), mat="AIR")  # should raise error since no rows exist yet
        print(f" - SPLIT test {i+1}/10 passed.")

    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SPLIT tests.")
    
    print("WORLD VOLUME AFTER: ", rows.volume())
    timer.print(msg="STARTING STEP 4 : Now testing SWEEP functionality...")
    rows.sweep()
    timer.print(msg=" - SWEEP completed in")
    print("WORLD VOLUME AFTER SWEEP: ", rows.volume())

    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SWEEP tests.")


def test3() -> None:
    rows = ROWS()
    mines = []
    for i in range(10):
        x = random.randint(a=1000, b=999000)
        y = random.randint(a=1000, b=999000)
        z = random.randint(a=1000, b=64000)
        mines.append( (x,y,z) )
    print(len(mines), "mines to be created at random positions.")

    for mine in mines:
        for dx in range(5):
            for dy in range(5):
                for dz in range(5):
                    x = mine[0] + dx
                    y = mine[1] + dy
                    z = mine[2] + dz
                    pos = (x, y, z)
                    rows.split(pos=pos, mat="AIR")

    rowsbefore = rows.nrows(mat="AIR")
    for i in range(10):
        print("Performing SWEEP to consolidate AIR rows... AIR rows before:", rows.nrows(mat="AIR"), "in sweep iteration:", i+1)
        rows.merge()
        rowsafter = rows.nrows(mat="AIR")
        if rowsafter == rowsbefore:
            print(" No more AIR rows could be consolidated. Stopping SWEEP.")
            break
        rowsbefore = rowsafter


    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SWEEP tests.")
        if "AIR"==Materials.idx2name[i]:
            for j in range(n):
                row = rows.array[i][j]
                p0 = ROW.P0(row=row)
                p1 = ROW.P1(row=row)
                print(f"  AIR row {j}: p0={p0}, p1={p1}")
                
    print(f"air rows= {rows.nrows(mat='AIR')}", f"stone rows= {rows.nrows(mat='STONE')}")


def main(test=[]) -> None:
    timer.lap()
    with Bundle():
        try:
            if 1 in test:
                test1()
            if 2 in test:
                test2()
            if 3 in test:
                test3()
            timer.print(msg="main.py: executed in")
        except Exception:
            traceback.print_exc()
        finally:    
            pass



if __name__ == "__main__":
    main(test=[3])
    

################################################################################
# FILE 8/22: main.py (END)
################################################################################


################################################################################
# FILE 9/22: TODO.md (START)
################################################################################




# ! ROWS
# TODO: ROWS.SPLIT(pos:POS=None)
# TODO: ROWS.MERGE(row0:NDARRAY=None, row1:NDARRAY=None)
# TODO: 

# ! UTILS
# TODO: 

# ! BUNDLE
# TODO: CLEANUP!!!

################################################################################
# FILE 9/22: TODO.md (END)
################################################################################


################################################################################
# FILE 10/22: utils/__init__.py (START)
################################################################################

from .request import Request
from .includes import *
from .includes import __all__ as inc
__all__ = [
    "Request",
] + inc

################################################################################
# FILE 10/22: utils/__init__.py (END)
################################################################################


################################################################################
# FILE 11/22: utils/bvh.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from numpy.typing import NDArray
    from world.rows import ROWS
    from utils.types import POS

from world.row import ROW





class BVH:
    __slots__ = (
        "rows",
        "root",
        "left",
        "right",
        "parent",
        # AABB as 6 parallel lists (SoA)
        "xmin",
        "ymin",
        "zmin",
        "xmax",
        "ymax",
        "zmax",
        # leaf as 2 parallel lists
        "leaf_mid",
        "leaf_rid",
        # fast delete index
        "leaf_index",
    )

    def __init__(self, rows: ROWS) -> None:
        self.rows = rows
        self.root: int = -1

        self.left: list[int] = []
        self.right: list[int] = []
        self.parent: list[int] = []

        self.xmin: list[int] = []
        self.ymin: list[int] = []
        self.zmin: list[int] = []
        self.xmax: list[int] = []
        self.ymax: list[int] = []
        self.zmax: list[int] = []

        self.leaf_mid: list[int] = []
        self.leaf_rid: list[int] = []

        # (mid, rid) -> node index
        self.leaf_index: dict[tuple[int, int], int] = {}

    # ------------------------------------------------------------------
    # node alloc
    # ------------------------------------------------------------------

    def _new_node(
        self,
        xmin: int,
        ymin: int,
        zmin: int,
        xmax: int,
        ymax: int,
        zmax: int,
        leaf_mid: int = -1,
        leaf_rid: int = -1,
        left: int = -1,
        right: int = -1,
        parent: int = -1,
    ) -> int:
        i = len(self.left)

        self.left.append(left)
        self.right.append(right)
        self.parent.append(parent)

        self.xmin.append(xmin)
        self.ymin.append(ymin)
        self.zmin.append(zmin)
        self.xmax.append(xmax)
        self.ymax.append(ymax)
        self.zmax.append(zmax)

        self.leaf_mid.append(leaf_mid)
        self.leaf_rid.append(leaf_rid)
        return i

    # ------------------------------------------------------------------
    # helpers
    # ------------------------------------------------------------------

    @staticmethod
    def _volume(xmin: int, ymin: int, zmin: int, xmax: int, ymax: int, zmax: int) -> int:
        return (xmax - xmin) * (ymax - ymin) * (zmax - zmin)

    def _merged_volume_with_node(
        self,
        node: int,
        bxmin: int,
        bymin: int,
        bzmin: int,
        bxmax: int,
        bymax: int,
        bzmax: int,
    ) -> int:
        axmin = self.xmin[node]
        aymin = self.ymin[node]
        azmin = self.zmin[node]
        axmax = self.xmax[node]
        aymax = self.ymax[node]
        azmax = self.zmax[node]

        mxmin = axmin if axmin < bxmin else bxmin
        mymin = aymin if aymin < bymin else bymin
        mzmin = azmin if azmin < bzmin else bzmin
        mxmax = axmax if axmax > bxmax else bxmax
        mymax = aymax if aymax > bymax else bymax
        mzmax = azmax if azmax > bzmax else bzmax

        return self._volume(mxmin, mymin, mzmin, mxmax, mymax, mzmax)

    def _fix_upwards(self, node:int=None) -> None:
        while node != -1:
            l = self.left[node]
            r = self.right[node]

            self.xmin[node] = self.xmin[l] if self.xmin[l] < self.xmin[r] else self.xmin[r]
            self.ymin[node] = self.ymin[l] if self.ymin[l] < self.ymin[r] else self.ymin[r]
            self.zmin[node] = self.zmin[l] if self.zmin[l] < self.zmin[r] else self.zmin[r]
            self.xmax[node] = self.xmax[l] if self.xmax[l] > self.xmax[r] else self.xmax[r]
            self.ymax[node] = self.ymax[l] if self.ymax[l] > self.ymax[r] else self.ymax[r]
            self.zmax[node] = self.zmax[l] if self.zmax[l] > self.zmax[r] else self.zmax[r]

            node = self.parent[node]

    # ------------------------------------------------------------------
    # insertion
    # ------------------------------------------------------------------

    def insert(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is None:
            mid = self.rows.mats.name2idx[mat]
            row = self.rows.array[mid][rid]
        else:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])

        xmin, ymin, zmin = ROW.P0(row)
        xmax, ymax, zmax = ROW.P1(row)

        leaf_node = self._new_node(
            xmin, ymin, zmin,
            xmax, ymax, zmax,
            leaf_mid=mid,
            leaf_rid=rid,
        )

        self.leaf_index[(mid, rid)] = leaf_node

        if self.root == -1:
            self.root = leaf_node
            return

        self.root = self._insert_node(self.root, leaf_node)

    def _insert_node(self, root: int, leaf_node: int) -> int:
        bxmin = self.xmin[leaf_node]; bymin = self.ymin[leaf_node]; bzmin = self.zmin[leaf_node]
        bxmax = self.xmax[leaf_node]; bymax = self.ymax[leaf_node]; bzmax = self.zmax[leaf_node]

        node = root
        while self.leaf_mid[node] == -1:
            l = self.left[node]
            r = self.right[node]
            node = (
                l if self._merged_volume_with_node(l, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                < self._merged_volume_with_node(r, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                else r
            )

        old_leaf = node
        parent = self.parent[old_leaf]

        axmin = self.xmin[old_leaf]; aymin = self.ymin[old_leaf]; azmin = self.zmin[old_leaf]
        axmax = self.xmax[old_leaf]; aymax = self.ymax[old_leaf]; azmax = self.zmax[old_leaf]

        new_parent = self._new_node(
            axmin if axmin < bxmin else bxmin,
            aymin if aymin < bymin else bymin,
            azmin if azmin < bzmin else bzmin,
            axmax if axmax > bxmax else bxmax,
            aymax if aymax > bymax else bymax,
            azmax if azmax > bzmax else bzmax,
        )

        self.left[new_parent] = old_leaf
        self.right[new_parent] = leaf_node
        self.parent[old_leaf] = new_parent
        self.parent[leaf_node] = new_parent

        if parent == -1:
            return new_parent

        if self.left[parent] == old_leaf:
            self.left[parent] = new_parent
        else:
            self.right[parent] = new_parent

        self.parent[new_parent] = parent
        self._fix_upwards(parent)
        return root

    # ------------------------------------------------------------------
    # removal (FAST)
    # ------------------------------------------------------------------

    def remove(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is not None:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])
        else:
            mid = self.rows.mats.name2idx[mat]

        try:
            found = self.leaf_index.pop((mid, rid))
        except KeyError:
            raise KeyError("[ERROR] BVH.remove() failed: row not found in BVH")

        parent = self.parent[found]
        if parent == -1:
            self.root = -1
            return

        sibling = self.right[parent] if self.left[parent] == found else self.left[parent]
        grand = self.parent[parent]

        if grand == -1:
            self.root = sibling
            self.parent[sibling] = -1
        else:
            if self.left[grand] == parent:
                self.left[grand] = sibling
            else:
                self.right[grand] = sibling
            self.parent[sibling] = grand
            self._fix_upwards(grand)

    # ------------------------------------------------------------------
    # search
    # ------------------------------------------------------------------

    def search(self, pos:POS=None) -> tuple[str, int, "NDArray[ROW.DTYPE]"]:
        if self.root == -1:
            raise LookupError("[ERROR] BVH.search() failed: empty BVH")

        x, y, z = pos
        stack = [self.root]

        xminL = self.xmin; yminL = self.ymin; zminL = self.zmin
        xmaxL = self.xmax; ymaxL = self.ymax; zmaxL = self.zmax
        leftL = self.left; rightL = self.right
        leaf_midL = self.leaf_mid; leaf_ridL = self.leaf_rid
        rows_arr = self.rows.array
        idx2name = self.rows.mats.idx2name

        while stack:
            n = stack.pop()
            if n == -1:
                continue

            if not (xminL[n] <= x < xmaxL[n] and yminL[n] <= y < ymaxL[n] and zminL[n] <= z < zmaxL[n]):
                continue

            mid = leaf_midL[n]
            if mid != -1:
                rid = leaf_ridL[n]
                row = rows_arr[mid][rid]
                if ROW.CONTAINS(row=row, pos=pos):
                    return idx2name[mid], rid, row
                continue

            l = leftL[n]
            r = rightL[n]

            if l != -1 and (xminL[l] <= x < xmaxL[l] and yminL[l] <= y < ymaxL[l] and zminL[l] <= z < zmaxL[l]):
                stack.append(l)
            if r != -1 and (xminL[r] <= x < xmaxL[r] and yminL[r] <= y < ymaxL[r] and zminL[r] <= z < zmaxL[r]):
                stack.append(r)

        raise LookupError("[ERROR] BVH.search() failed: point not found (partition invariant violated or BVH not updated)")
















################################################################################
# FILE 11/22: utils/bvh.py (END)
################################################################################


################################################################################
# FILE 12/22: utils/event.py (START)
################################################################################

from __future__ import annotations
from typing import Any, Callable
from dataclasses import dataclass, field
from .event import Event
from .schedule import Schedule



@dataclass(order=True)
class Event:
    due_ns: int
    seq: int
    callback: Callable[..., Any] = field(compare=False)
    args: tuple[Any, ...] = field(default_factory=tuple, compare=False)
    kwargs: dict[str, Any] = field(default_factory=dict, compare=False)
    cancelled: bool = field(default=False, compare=False)


class Handler:
    __slots__ = ("_scheduler", "_event")

    def __init__(self, scheduler: "Schedule", event: Event) -> None:
        self._scheduler = scheduler
        self._event = event

    def cancel(self) -> bool:
        return self._scheduler.cancel(self)


################################################################################
# FILE 12/22: utils/event.py (END)
################################################################################


################################################################################
# FILE 13/22: utils/includes.py (START)
################################################################################

from __future__ import annotations  # MUST BE FIRST

# EXCEPTION IMPORTS
from .timer import Timer, time      # NON SORTED -> HERE BECAUSE Timer IS USED IMMEDIATELY
timer = Timer()

# IMPORTS FROM STANDARD LIBRARY AND THIRD-PARTY LIBRARIES
from typing import TYPE_CHECKING, Any, Iterator, TypeVar, Generic, Union, Tuple, List, Dict, Callable, Optional
from pathlib import Path
from numpy.typing import NDArray
from PIL import Image, ImageDraw, ImageFont


# SIMPLE IMPORTS
import math
import numpy as np
import torch 
import heapq
import threading
import json
import time
import pathlib
import sys
import os
import random
import shutil
import datetime
import bisect
import pygame
import moderngl
import traceback
import stat



# my own modules (utils)
from .types import POS, SIZE


# Exports
__all__ = [
    "math",
    "time",
    "np",
    "NDArray",
    "torch",
    "TYPE_CHECKING",
    "annotations",
    "Any",
    "Iterator",
    "TypeVar",
    "Generic",
    "Union",
    "Tuple",
    "List",
    "Dict",
    "Callable",
    "Optional",
    "Image",
    "ImageDraw",
    "ImageFont",
    "Timer",
    "heapq",
    "threading",
    "json",
    "Path",
    "POS",
    "SIZE",
    "pathlib",
    "sys",
    "os",
    "random",
    "shutil",
    "datetime",
    "bisect",
    "pygame",
    "moderngl",
    "timer", # include the instance timer -> can be used as utils.timer
    "traceback",
    "stat",
]


timer.print(msg=f"utils/includes.py: {len(__all__)} modules loaded in")
timer.reset()

################################################################################
# FILE 13/22: utils/includes.py (END)
################################################################################


################################################################################
# FILE 14/22: utils/mdx.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from world.rows import ROWS
    


from collections import defaultdict
from dataclasses import dataclass
from typing import DefaultDict, Dict, Optional, Set, Tuple

from world.row import ROW, NDArray

Loc = Tuple[int, int]  # (mid, rid)
FACE = Tuple[int, int, int, int, int, int]  # (mid, a0, a1, b0, b1, face_coord)
BUCK = DefaultDict[FACE, Set[Loc]]  # face_key -> set of (mid, rid)
FACES = Tuple[FACE, FACE]  # (max_face, min_face)  # our faces, in search order
BUCKS = Tuple[BUCK, BUCK]  # (neg_bucket, pos_bucket)

@dataclass
class ROWFACES:
    x0: FACE
    x1: FACE
    y0: FACE
    y1: FACE
    z0: FACE
    z1: FACE

    @property
    def xfaces(self) -> FACES:
        return (self.x1, self.x0)

    @property
    def yfaces(self) -> FACES:
        return (self.y1, self.y0)

    @property
    def zfaces(self) -> FACES:
        return (self.z1, self.z0)

    def faces(self, ax:int=None) -> FACES:
        if ax not in [0, 1, 2]:
            raise ValueError("[VALUE ERROR] ROWFACES.faces() ax must be 0,1,2. provided axis:", ax)
        return (self.xfaces, self.yfaces, self.zfaces)[ax]


class MDX:
    AX_X = 0
    AX_Y = 1
    AX_Z = 2
    ALLAXIS = (AX_X, AX_Y, AX_Z)

    def __init__(self, rows:ROWS=None) -> None:
        self.rows = rows
        self.init()

    def init(self) -> None:
        self.neg: Tuple[BUCK, ...] = (defaultdict(set), defaultdict(set), defaultdict(set))
        self.pos: Tuple[BUCK, ...] = (defaultdict(set), defaultdict(set), defaultdict(set))
        self._faces: Dict[Loc, ROWFACES] = {}


    def faces(self, mid:int=None, row:NDArray[ROW.DTYPE]=None) -> ROWFACES:
        x0, y0, z0 = ROW.P0(row=row)
        x1, y1, z1 = ROW.P1(row=row)
        # axis X: spans are (y0,y1,z0,z1), face coord is x0 or x1
        kx0: FACE = (mid, y0, y1, z0, z1, x0)
        kx1: FACE = (mid, y0, y1, z0, z1, x1)
        # axis Y: spans are (x0,x1,z0,z1), face coord is y0 or y1
        ky0: FACE = (mid, x0, x1, z0, z1, y0)
        ky1: FACE = (mid, x0, x1, z0, z1, y1)
        # axis Z: spans are (x0,x1,y0,y1), face coord is z0 or z1
        kz0: FACE = (mid, x0, x1, y0, y1, z0)
        kz1: FACE = (mid, x0, x1, y0, y1, z1)
        return ROWFACES(x0=kx0, x1=kx1, y0=ky0, y1=ky1, z0=kz0, z1=kz1)

    def insert(self, row:NDArray[ROW.DTYPE]=None) -> None:
        mid = self.rows.mats.name2idx[ROW.MAT(row=row)]
        rid = ROW.RID(row=row)
        loc = (mid, rid)
        faces = self.faces(mid, row)
        self._faces[loc] = faces

        self.neg[self.AX_X][faces.x0].add(loc)
        self.pos[self.AX_X][faces.x1].add(loc)

        self.neg[self.AX_Y][faces.y0].add(loc)
        self.pos[self.AX_Y][faces.y1].add(loc)

        self.neg[self.AX_Z][faces.z0].add(loc)
        self.pos[self.AX_Z][faces.z1].add(loc)

    def remove(self, mat:str=None, rid:int=None) -> None:
        mid = self.rows.mats.name2idx[mat]
        loc = (mid, rid)
        faces = self._faces.pop(loc, None)
        if faces is None:
            return

        self.discard(m=self.neg[self.AX_X], key=faces.x0, loc=loc)
        self.discard(m=self.pos[self.AX_X], key=faces.x1, loc=loc)
        self.discard(m=self.neg[self.AX_Y], key=faces.y0, loc=loc)
        self.discard(m=self.pos[self.AX_Y], key=faces.y1, loc=loc)
        self.discard(m=self.neg[self.AX_Z], key=faces.z0, loc=loc)
        self.discard(m=self.pos[self.AX_Z], key=faces.z1, loc=loc)

    def discard(self, m:BUCK=None, key:FACE=None, loc:Loc=None) -> None:
        s = m.get(key)
        if not s:
            return
        s.discard(loc)
        if not s:
            del m[key]

    def search(self, mid:int=None, rid:int=None, axis:int=None) -> Optional[Loc]:
        if mid is None or rid is None or axis is None:
            raise ValueError("mid, rid, and axis must be provided")
        loc = (mid, rid)
        rowfaces: ROWFACES = self._faces.get(loc)
        if rowfaces is None:
            return None

        def search(faces:FACES=None, bucks:BUCKS=None) -> Optional[Loc]:
            for face, buck in zip(faces, bucks):
                buck: BUCK = buck
                face: FACE = face
                candidates = buck.get(face)
                if not candidates:
                    continue
                for c in candidates:
                    if c != loc:
                        return c
            return None

        faces = rowfaces.faces(ax=axis) 
        bucks = (self.neg[axis], self.pos[axis])

        return search(faces=faces, bucks=bucks)

################################################################################
# FILE 14/22: utils/mdx.py (END)
################################################################################


################################################################################
# FILE 15/22: utils/request.py (START)
################################################################################

import time
import urllib.request
import urllib.error
import json


class Request:
    def __init__(self, url: str = None, timeout: int = 600, retries: int = 3, data=None, method: str = None) -> None:
        self.timeout = timeout
        self.retries = retries
        self._retries = retries
        self.url = url
        self.data = data
        self.method = method

        self.init()

    def init(self) -> None:
        self.request = urllib.request.Request(url=self.url, data=self.data, method=self.method)

    def header(self, key: str = None, value: str = None) -> None:
        self.request.add_header(key, value)

    def open(self) -> dict:
        try:
            with urllib.request.urlopen(self.request, timeout=self.timeout) as response:
                raw = response.read().decode("utf-8", errors="replace")
                try:
                    return json.loads(raw) if raw else {}
                
                except json.JSONDecodeError as e:
                    raise RuntimeError(f"[ERROR] invalid JSON response for {self.url}\n{e!r}\n---\n{raw[:200]}") from e

        except urllib.error.HTTPError as e:
            raw = e.read().decode("utf-8", errors="replace")
            retryable = (e.code == 429) or (500 <= e.code <= 599)

            if retryable and self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] {e.code} for {self.url}\n{raw}") from e

        except (urllib.error.URLError, TimeoutError, OSError) as e:
            if self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] request failed for {self.url}\n{e!r}") from e
        
        except Exception as e:
            raise RuntimeError(f"[ERROR] unexpected error for {self.url}\n{e!r}") from e

################################################################################
# FILE 15/22: utils/request.py (END)
################################################################################


################################################################################
# FILE 16/22: utils/schedule.py (START)
################################################################################

import threading
from typing import Any, Callable, Optional
import heapq
from .timer import Timer, now
from .event import Event, Handler



class Schedule:
    def __init__(self) -> None:
        self._timer = Timer()

        self._lock = threading.Lock()
        self._cv = threading.Condition(self._lock)
        self._pq: list[Event] = []
        self._seq = 0

        self._worker: Optional[threading.Thread] = None
        self._stop = False
        self._running = False

        self.start()

    def start(self) -> None:
        with self._lock:
            if self._running:
                return
            self._stop = False
            self._worker = threading.Thread(target=self._run, name="SchedulerWorker", daemon=True)
            self._running = True
            self._worker.start()

    def stop(self) -> None:
        with self._lock:
            if not self._running:
                return
            self._stop = True
            self._cv.notify_all()

        if self._worker:
            self._worker.join(timeout=2.0)

        with self._lock:
            self._running = False
            self._worker = None

    def schedule(self, ns: int=None, fn: Callable[..., Any]=None, *args: Any, **kwargs: Any) -> Handler:
        with self._lock:
            self._seq += 1
            ev = Event(due_ns=ns, seq=self._seq, callback=fn, args=args, kwargs=kwargs)
            heapq.heappush(self._pq, ev)
            self._cv.notify_all()
            return Handler(self, ev)

    def new(self, seconds:float=None, fn:Callable[..., Any]=None, delay=False, *args: Any, **kwargs: Any) -> Handler:
        if delay==True:
            ns = now() + int(seconds * 1e9)
        if delay==False:
            ns = int(seconds * 1e9)
        return self.schedule(ns=ns, fn=fn, *args, **kwargs)
    

    def cancel(self, handle: Handler) -> bool:
        with self._lock:
            if handle._event.cancelled:
                return False
            handle._event.cancelled = True
            self._cv.notify_all()
            return True

    def _run(self) -> None:
        while True:
            with self._lock:
                # Wait until there is work or stop requested
                while not self._pq and not self._stop:
                    self._cv.wait()

                if self._stop:
                    return

                # Drop cancelled events at head
                while self._pq and self._pq[0].cancelled:
                    heapq.heappop(self._pq)

                if not self._pq:
                    continue

                ev = self._pq[0]
                due = ev.due_ns

            # 2) Wait until deadline (no lock held)
            self._timer.waitns(due)

            # 3) Pop-and-execute if still valid
            with self._lock:
                if self._stop:
                    return

                if not self._pq:
                    continue
                if self._pq[0] is not ev:
                    continue

                heapq.heappop(self._pq)
                if ev.cancelled:
                    continue

            try:
                ev.callback(*ev.args, **ev.kwargs)
            except Exception as e:
                # Keep scheduler alive; replace with logging if desired
                print(f"[Schedule] callback error: {e!r}")






















# ============================================================
# Example usage
# ============================================================

if __name__ == "__main__":
    import time

    sched = Schedule()
    def hello(who:str=None, n:int=1) -> None:
        print(f"{time.perf_counter():.3f} hello {who} x{n}")
    def test(who:str=None,  n:int=1) -> None:
        print(who, n*n)

    h1 = sched.new(seconds=0.050, fn=test, who="A", n=2, delay=True)
    h2 = sched.new(seconds=0.120, fn=hello, who="B", n=3, delay=True)
    h3 = sched.new(seconds=0.080, fn=test, who="C", n=1, delay=True)
    h2.cancel()
    futuretime = time.perf_counter() + 0.100
    h4 = sched.new(seconds=futuretime, fn=hello, who="D", n=4, delay=False)
    h5 = sched.new(seconds=futuretime, fn=test, who="E", n=5, delay=False)
    h6 = sched.new(seconds=futuretime, fn=hello, who="F", n=6, delay=False)


    time.sleep(0.2)
    sched.stop()

################################################################################
# FILE 16/22: utils/schedule.py (END)
################################################################################


################################################################################
# FILE 17/22: utils/timer.py (START)
################################################################################

from __future__ import annotations
import time



class Timer:
    def __init__(self) -> None:
        self.coarse_ns = 2_000_000
        self.spin_ns = 1_000_000

        self.start()

    def nowns(self) -> int:  # can be used as Timer().nowns()
        return time.perf_counter_ns()
    
    @staticmethod   # can be used as Timer.now()
    def now() -> float:
        return time.perf_counter_ns()

    def start(self) -> int:
        self.started = self.nowns()
        self.t0 = self.started
        self.delta = []
        self.times = []
        return self.t0
    
    def lap(self) -> int:
        t1 = self.nowns()
        t0 = self.t0
        self.t0 = t1
        dt = round((t1 - t0) / 1e9, 6) # seconds
        self.delta.append(dt)
        self.times.append(t1)
        return dt       # time since last lap in seconds
    
    def stop(self) -> int:
        self.lap()
        first = self.started
        last = self.times[-1]
        t = round((last - first) / 1e9, 6) # seconds with 6 decimal places (microseconds) 
        return t        # total since started
    
    def print(self, msg:str=None) -> None:
        self.lap()
        txt = f"lap {len(self.delta)}: {self.delta[-1]} seconds, total {round((self.times[-1] - self.started) / 1e9, 6)} seconds"
        if msg is not None:
            txt = f"{msg}: {txt}"
        print(txt)

    def waitns(self, deadline_ns: int) -> None:
        coarse_ns = self.coarse_ns
        spin_ns = self.spin_ns

        while True:
            n = self.nowns()
            remaining = deadline_ns - n
            if remaining <= 0:
                return

            # FAR: sleep until within coarse_ns
            if remaining > coarse_ns:
                time.sleep((remaining - coarse_ns) / 1e9)
                continue

            # NEAR: yield until within spin_ns
            if remaining > spin_ns:
                time.sleep(0)
                continue

            # FINAL: busy-spin
            while self.nowns() < deadline_ns:
                pass
            return

    def wait(self, seconds: float) -> None:
        if seconds <= 0:
            return
        self.waitns(self.nowns() + int(seconds * 1e9))

    def reset(self) -> int:
        t = self.stop()
        self.start()
        return t  # total since started before reset


now = Timer.now # now: now() returns the current time in nanoseconds

################################################################################
# FILE 17/22: utils/timer.py (END)
################################################################################


################################################################################
# FILE 18/22: utils/types.py (START)
################################################################################

from typing import TypeAlias
POS: TypeAlias = tuple[int, int, int]
SIZE: TypeAlias = tuple[int, int, int]

__all__ = [
    "POS",
    "SIZE",
]

################################################################################
# FILE 18/22: utils/types.py (END)
################################################################################


################################################################################
# FILE 19/22: world/__init__.py (START)
################################################################################

from .rows import ROWS, rows
from .row import ROW
from .materials import MATERIALS, Materials, Material

from utils import *
from world import *
from bundle import *

__all__ = [
    "MATERIALS",
    "Materials",
    "Material",
    "ROW",
    "ROWS",
    "rows",
]

################################################################################
# FILE 19/22: world/__init__.py (END)
################################################################################


################################################################################
# FILE 20/22: world/materials.py (START)
################################################################################
















class MATERIALS:
    TYPES = {
        "INVIS": 0,     # start at 16384                # invisible
        "TRANS": 1,     # start at 32768                # transparent
        "SOLID": 2,     # start at 65536                # solid
        "ROCKS": 3,     # start at 4294967296           # indestructible
    }

    DATA  = {
        "AIR":      (16384+0,     TYPES["INVIS"]),

        "WATER":    (32768+0,     TYPES["TRANS"]), 
        "LAVA":     (32768+1,     TYPES["TRANS"]),
        "GLASS":    (32768+2,     TYPES["TRANS"]),

        "STONE":    (65536+0,     TYPES["SOLID"]),
        "OBSIDIAN": (65536+1,     TYPES["SOLID"]),

        "BEDROCK":  (4294967296+0,TYPES["ROCKS"]),
    }

    IDX = {name: i for i, name in enumerate(DATA.keys())}

    NUM = len(DATA)

class Material:
    def __init__(self, name:str=None) -> None:
        self.id, self.type = MATERIALS.DATA.get(name, (None, None)) 
        self.idx = MATERIALS.IDX.get(name, None) 
        if self.id is None or self.type is None or self.idx is None:
            raise ValueError(f"Invalid material name: {name}")

    def isrocks(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

    def issolid(self) -> bool:
        return self.type == MATERIALS.TYPES["SOLID"]
    
    def istrans(self) -> bool:
        return self.type == MATERIALS.TYPES["TRANS"]
    
    def isinvisible(self) -> bool:
        return self.type == MATERIALS.TYPES["INVIS"]
    
    def isindestructible(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

class Materials:
    idx2name = {idx: name for name, idx in MATERIALS.IDX.items()}
    name2idx = MATERIALS.IDX

    name2id  = {name: pair[0] for name, pair in MATERIALS.DATA.items()}
    id2name  = {pair[0]: name for name, pair in MATERIALS.DATA.items()}

    # the one you actually need:
    id2idx   = {pair[0]: MATERIALS.IDX[name] for name, pair in MATERIALS.DATA.items()}
    idx2id   = {MATERIALS.IDX[name]: pair[0] for name, pair in MATERIALS.DATA.items()}


    def __init__(self) -> None:
        for name in MATERIALS.DATA.keys():
            setattr(self, name.lower(), Material(name=name))

    def idx(self, name: str = None, id: int = None) -> int:
        if (name is None) == (id is None):
            raise ValueError("Provide exactly one of name or id")
        return self.name2idx[name] if name is not None else self.id2idx[id]

    def id(self, name: str = None, idx: int = None) -> int:
        if (name is None) == (idx is None):
            raise ValueError("Provide exactly one of name or idx")
        return self.name2id[name] if name is not None else self.idx2id[idx]

    def name(self, id: int = None, idx: int = None) -> str:
        if (id is None) == (idx is None):
            raise ValueError("Provide exactly one of id or idx")
        return self.id2name[id] if id is not None else self.idx2name[idx]


################################################################################
# FILE 20/22: world/materials.py (END)
################################################################################


################################################################################
# FILE 21/22: world/row.py (START)
################################################################################

from __future__ import annotations
import stat
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass



import numpy as np
from numpy.typing import NDArray


from utils.types import SIZE, POS
from world.materials import Material, Materials





class ROW:
    DTYPE = np.uint64
    SHAPE = (4, 4)
    NBITS = DTYPE(0).nbytes * 8                      # -> 64 bits

    XBITS = 20
    YBITS = 20
    ZBITS = 16
    if XBITS + YBITS + ZBITS + 1 > NBITS:
        raise ValueError("bit allocation error")

    XMIN = 0
    YMIN = 0
    ZMIN = 0
    XMAX = 2**XBITS
    YMAX = 2**YBITS
    ZMAX = 2**ZBITS
    NMAX = XMAX * YMAX * ZMAX
    

    # POSITIONS (MIN)  stored in row 0
    IDS_X0 = (0, 0)
    IDS_Y0 = (0, 1)
    IDS_Z0 = (0, 2)

    # POSITIONS (MAX)  stored in row 1
    IDS_X1 = (1, 0)
    IDS_Y1 = (1, 1)
    IDS_Z1 = (1, 2)

    # DIMENSIONS  stored in row 2
    IDS_DX = (2, 0)
    IDS_DY = (2, 1)
    IDS_DZ = (2, 2)

    # METADATA  stored in row 3
    IDS_ID    = (3, 0)
    IDS_MAT   = (3, 1)
    IDS_FLAGS = (3, 2)

    ENCODE_DIRTY        = DTYPE(1 << 0)
    ENCODE_ALIVE        = DTYPE(1 << 1)
    ENCODE_SOLID        = DTYPE(1 << 2)
    ENCODE_DESTRUCTABLE = DTYPE(1 << 3)
    ENCODE_VISIBLE      = DTYPE(1 << 4)

    SENTINEL = np.iinfo(DTYPE).max
    ARRAY: NDArray[DTYPE] = np.zeros(SHAPE, dtype=DTYPE)
    for i in range(4):
        for j in range(4):
            ARRAY[i, j] = SENTINEL  # initialize all to -1 -> invalid
    _ID = 0
    
    @staticmethod # get min position (x0, y0, z0)   
    def P0(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X0]), int(row[*ROW.IDS_Y0]), int(row[*ROW.IDS_Z0]))
    
    @staticmethod # get max position (x1, y1, z1)
    def P1(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X1]), int(row[*ROW.IDS_Y1]), int(row[*ROW.IDS_Z1]))
    
    @staticmethod # get size (dx, dy, dz)
    def SIZE(row:NDArray[DTYPE]=None) -> SIZE:
        return (int(row[*ROW.IDS_DX]), int(row[*ROW.IDS_DY]), int(row[*ROW.IDS_DZ]))
    
    @staticmethod # get material id
    def MID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_MAT])
    
    @staticmethod # get meterial string name
    def MAT(row:NDArray[DTYPE]=None) -> str:
        return Materials.id2name[ROW.MID(row=row)]
    
    @staticmethod # get row id
    def RID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_ID])
    
    @staticmethod # get flags
    def FLAGS(row:NDArray[DTYPE]=None) -> tuple[bool, bool, bool, bool, bool]:
        flags: int = int(row[*ROW.IDS_FLAGS])
        dirty, alive, solid, destr, visib = ROW.DECODE(flags=flags)
        return (dirty, alive, solid, destr, visib)
    
    @staticmethod # get volume (dx * dy * dz)
    def VOLUME(row:NDArray[DTYPE]=None) -> int:
        dx, dy, dz = ROW.SIZE(row=row)
        return dx * dy * dz

    @staticmethod # make a copy of the template array
    def COPY() -> NDArray[DTYPE]:
        return np.copy(ROW.ARRAY)
    
    @staticmethod
    def CLIP(pos:POS=None) -> POS:
        x, y, z = pos
        cx = min(max(x, ROW.XMIN), ROW.XMAX - 1)
        cy = min(max(y, ROW.YMIN), ROW.YMAX - 1)
        cz = min(max(z, ROW.ZMIN), ROW.ZMAX - 1)
        pos: POS = (cx, cy, cz)
        return pos
    
    @staticmethod
    def SORT(p0:POS=None, p1:POS=None) -> tuple[POS, POS]:
        x0, y0, z0 = p0
        x1, y1, z1 = p1
        sx0, sx1 = (min(x0, x1), max(x0, x1))
        sy0, sy1 = (min(y0, y1), max(y0, y1))
        sz0, sz1 = (min(z0, z1), max(z0, z1))
        p0: POS = (sx0, sy0, sz0)
        p1: POS = (sx1, sy1, sz1)
        return (p0, p1)
    
    @staticmethod
    def CONTAINS(row: NDArray[DTYPE], pos: POS) -> bool:
        x, y, z = pos
        x0, y0, z0 = ROW.P0(row=row)
        x1, y1, z1 = ROW.P1(row=row)
        return (
            (x0 <= x < x1) and
            (y0 <= y < y1) and
            (z0 <= z < z1)
        )
    
    @staticmethod
    def MERGE(row0: NDArray[DTYPE]=None, row1: NDArray[DTYPE]=None) -> tuple[bool, bool, bool]:
        if row0[*ROW.IDS_MAT] != row1[*ROW.IDS_MAT]:
            return (False, False, False)

        x0a, y0a, z0a = ROW.P0(row=row0)
        x1a, y1a, z1a = ROW.P1(row=row0)
        x0b, y0b, z0b = ROW.P0(row=row1)
        x1b, y1b, z1b = ROW.P1(row=row1)
        p00 = (x0a, y0a, z0a)
        p01 = (x1a, y1a, z1a)
        p10 = (x0b, y0b, z0b)
        p11 = (x1b, y1b, z1b)

        def overlap(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a0 < b1 and b0 < a1
        def touches(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a1 == b0 or b1 == a0

        touching = [False, False, False]
        overlaps = [False, False, False]

        for i in range(3):
            if overlap(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                overlaps[i] = True
            elif touches(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                touching[i] = True
            else:
                return (False, False, False)  # separated on this axis
            
        if sum(touching) == 1 and sum(overlaps) == 2:
            return tuple(touching)  # (x_touch, y_touch, z_touch)

        return (False, False, False)
    

    @staticmethod
    def ENCODE(dirty:bool=None, alive:bool=None, solid:bool=None, destructable:bool=None, visible:bool=None) -> int:
        f: int = 0
        if dirty:
            f |= int(ROW.ENCODE_DIRTY)
        if alive:
            f |= int(ROW.ENCODE_ALIVE)
        if solid:
            f |= int(ROW.ENCODE_SOLID)
        if destructable:
            f |= int(ROW.ENCODE_DESTRUCTABLE)
        if visible:
            f |= int(ROW.ENCODE_VISIBLE)
        return f
    
    @staticmethod
    def DECODE(flags) -> tuple[bool, bool, bool, bool, bool]:
        f: int = int(flags)

        dirty = (f & int(ROW.ENCODE_DIRTY)) != 0
        alive = (f & int(ROW.ENCODE_ALIVE)) != 0
        solid = (f & int(ROW.ENCODE_SOLID)) != 0
        destr = (f & int(ROW.ENCODE_DESTRUCTABLE)) != 0
        visib = (f & int(ROW.ENCODE_VISIBLE)) != 0
        return dirty, alive, solid, destr, visib








                

    @staticmethod
    def new(p0:POS=None, p1:POS=None, mat:str=None, rid:int=None, dirty:bool=True, alive:bool=True) -> NDArray[DTYPE]:
        p0, p1 = ROW.SORT(p0=ROW.CLIP(pos=p0), p1=ROW.CLIP(pos=p1))
        mat: Material = Material(name=mat)
        flags: int = ROW.ENCODE(dirty=dirty, alive=alive, solid=mat.issolid(), destructable=not mat.isindestructible(), visible=not mat.isinvisible())
        
        copy: NDArray[ROW.DTYPE] = ROW.COPY()

        # POS0
        copy[*ROW.IDS_X0]    = np.uint64(p0[0])
        copy[*ROW.IDS_Y0]    = np.uint64(p0[1])
        copy[*ROW.IDS_Z0]    = np.uint64(p0[2])
        # POS1
        copy[*ROW.IDS_X1]    = np.uint64(p1[0])
        copy[*ROW.IDS_Y1]    = np.uint64(p1[1])
        copy[*ROW.IDS_Z1]    = np.uint64(p1[2])
        # SIZE
        copy[*ROW.IDS_DX]    = np.uint64(p1[0] - p0[0])
        copy[*ROW.IDS_DY]    = np.uint64(p1[1] - p0[1])
        copy[*ROW.IDS_DZ]    = np.uint64(p1[2] - p0[2])
        # METADATA
        copy[*ROW.IDS_ID]    = np.uint64(rid)       # stores now the row index within material array instead of global unique id
        copy[*ROW.IDS_MAT]   = np.uint64(mat.id)
        copy[*ROW.IDS_FLAGS] = np.uint64(flags)

        if any(v < 0 for v in (copy[*ROW.IDS_DX], copy[*ROW.IDS_DY], copy[*ROW.IDS_DZ])):
            raise ValueError("p1 must be greater than or equal to p0 on all axes")
        if any(v < 0 for v in (copy[*ROW.IDS_X0], copy[*ROW.IDS_Y0], copy[*ROW.IDS_Z0])):
            raise ValueError("positions must be non-negative")
        return copy
    
    

################################################################################
# FILE 21/22: world/row.py (END)
################################################################################


################################################################################
# FILE 22/22: world/rows.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass


import numpy as np
from numpy.typing import NDArray

from world.row import ROW
from utils.bvh import BVH
from world.materials import Materials, MATERIALS
from utils.types import POS, SIZE
from utils.mdx import MDX




class ROWS:
    SIZE = 65536
    def __init__(self) -> None:
        self.mats = Materials()
        self.bvh = BVH(rows=self)
        self.mdx = MDX(rows=self)
        self.n:dict[int, int] = {mid: 0 for mid in range(MATERIALS.NUM)}  # number of valid rows per material
        self.m = 0  # for the total number of rows used

        
        self.array: NDArray[ROW.DTYPE] = np.full((MATERIALS.NUM, ROWS.SIZE, *ROW.SHAPE), fill_value=ROW.SENTINEL, dtype=ROW.DTYPE)
        self.shape = self.array.shape
        self.nbytes = self.array.nbytes
        self.gbytes = self.nbytes / (1024**3)

        mat = "STONE"
        self.insert(p0=(ROW.XMIN, ROW.YMIN, ROW.ZMIN), p1=(ROW.XMAX, ROW.YMAX, ROW.ZMAX), mat=mat)  # alive and dirty by default are true so no need to specify : easier to use now!!!
        self.size = ROW.XMAX - ROW.XMIN, ROW.YMAX - ROW.YMIN, ROW.ZMAX - ROW.ZMIN

        self._merge = 16
        self.__merge = 0

    def newn(self, mat:str=None) -> int:
        mid: int = Materials.name2idx[mat]
        n: int = self.n[mid]
        self.n[mid] += 1
        self.m += 1
        return n
    
    def deln(self, mat: str=None) -> int:
        if mat is None:
            raise ValueError("material must be specified")
        mid = Materials.name2idx[mat]
        if self.n[mid] <= 0:
            raise ValueError("no rows to free")
        self.n[mid] -= 1
        self.m -= 1
        return self.n[mid]
            
    def insert(self, p0:POS=None, p1:POS=None, mat:str=None, dirty:bool=True, alive:bool=True) -> NDArray[ROW.DTYPE]:
        mid: int = Materials.name2idx[mat]
        rid: int = self.newn(mat=mat)
        row = ROW.new(p0=p0, p1=p1, mat=mat, rid=rid, dirty=dirty, alive=alive)
        self.array[mid][rid] = row
        self.bvh.insert(row=row)
        self.mdx.insert(row=row)
        return row
    
    def remove(self, index:int=None, mat:str=None, row:NDArray[ROW.DTYPE]=None) -> NDArray[ROW.DTYPE]:
        if row is not None and index is None and mat is None:
            mat = ROW.MAT(row=row)
            index = ROW.RID(row=row)
        mid = Materials.name2idx[mat]
        n = self.n[mid]
        if index < 0 or index >= n:
            raise IndexError("index out of range")
        last = n - 1
        self.bvh.remove(mat=mat, rid=index)
        self.mdx.remove(mat=mat, rid=index)

        if index != last:
            self.bvh.remove(mat=mat, rid=last)
            self.mdx.remove(mat=mat, rid=last)
            self.array[mid][index] = self.array[mid][last]
            self.array[mid][index][*ROW.IDS_ID] = np.uint64(index)
            self.bvh.insert(row=self.array[mid][index])
            self.mdx.insert(row=self.array[mid][index])

        self.array[mid][last] = ROW.ARRAY
        self.deln(mat=mat)
        return self
    
    def volume(self) -> int:
        total = 0
        for mid in range(MATERIALS.NUM):
            n = self.n[mid]
            for rid in range(n):
                row = self.array[mid][rid]
                total += ROW.VOLUME(row=row)
        return total

    def search(self, pos:POS=None) -> tuple[str, int, NDArray[ROW.DTYPE]]:
        mat, rid, row = self.bvh.search(pos=pos)
        return (mat, rid, row)
    
    def get(self, mat:str=None, rid:int=None) -> NDArray[ROW.DTYPE]:
        return self.array[Materials.name2idx[mat]][rid]

    def nrows(self, mat:str=None) -> int:
        return self.n[Materials.name2idx[mat]]
    
    def split(self, pos:POS=None, mat:str=None) -> tuple[NDArray[ROW.DTYPE], dict[int, int]]:
        mat0, rid, row = self.search(pos=pos)
        p0 = ROW.P0(row=row)
        p1 = ROW.P1(row=row)
        
        x0, y0, z0 = p0
        x1, y1, z1 = pos
        x2, y2, z2 = x1+1, y1+1, z1+1
        x3, y3, z3 = p1

        xs = [[x0, x1], [x1, x2], [x2, x3]]
        ys = [[y0, y1], [y1, y2], [y2, y3]]
        zs = [[z0, z1], [z1, z2], [z2, z3]]

        arids = {mid: 0 for mid in range(MATERIALS.NUM)}
        array: NDArray[ROW.DTYPE] = np.full((MATERIALS.NUM, 27, *ROW.SHAPE), fill_value=ROW.SENTINEL, dtype=ROW.DTYPE)
        for i, (X0, X1) in enumerate(xs):
            for j, (Y0, Y1) in enumerate(ys):
                for k, (Z0, Z1) in enumerate(zs):
                    size = (X1 - X0) * (Y1 - Y0) * (Z1 - Z0)
                    if size > 0:
                        if i == 1 and j == 1 and k == 1:    # the center cube should get the new material (its the one containing pos)
                            row0 = self.insert(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat) # use new the material given for the new row
                            mid0 = self.mats.id2idx[ROW.MID(row=row0)]
                            array[mid0][arids[mid0]] = row0
                            arids[mid0] += 1
                        else:
                            row0 = self.insert(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat0) # use the old material for the other rows
                            mid0 = self.mats.id2idx[ROW.MID(row=row0)]
                            array[mid0][arids[mid0]] = row0
                            arids[mid0] += 1

        self.remove(row=row) 
        self.merge(rows=array)  # this gives rows so calls  self.mergerows() and not self.mergemat() so only the new rows created here are considered for merging



    def merge2(self, mat:str=None, rid0:int=None, rid1:int=None) -> bool:
        mid = Materials.name2idx[mat]
        n = self.n[mid]
        if rid0 < 0 or rid0 >= n or rid1 < 0 or rid1 >= n or rid0 == rid1:
            return False

        row0 = self.array[mid][rid0]
        row1 = self.array[mid][rid1]

        touch = ROW.MERGE(row0=row0, row1=row1)
        if touch == (False, False, False):
            return False

        p0 = ROW.SORT(p0=ROW.P0(row=row0), p1=ROW.P0(row=row1))[0]
        p1 = ROW.SORT(p0=ROW.P1(row=row0), p1=ROW.P1(row=row1))[1]

        hi = rid0 if rid0 > rid1 else rid1
        lo = rid1 if hi == rid0 else rid0
        self.remove(mat=mat, index=hi)
        self.remove(mat=mat, index=lo)
        self.insert(p0=p0, p1=p1, mat=mat)
        return True

    def mergeax(self, mat:str=None, axis:int=None) -> int:
        mid = Materials.name2idx[mat]
        merges = 0
        extra: list[int] = list(range(self.n[mid] - 1, -1, -1))
        seen: set[int] = set()

        while extra:
            rid = extra.pop()

            if rid < 0 or rid >= self.n[mid]:
                continue

            if rid in seen:
                continue
            seen.add(rid)

            partner = self.mdx.search(mid=mid, rid=rid, axis=axis)
            if partner is None:
                continue

            pmid, prid = partner
            if pmid != mid or prid < 0 or prid >= self.n[mid]:
                continue

            if self.merge2(mat=mat, rid0=rid, rid1=prid):
                merges += 1
                new_rid = self.n[mid] - 1
                extra.append(new_rid)

                if hasattr(self.mdx, "neighbors_of"):
                    neigh = self.mdx.neighbors_of(mid=mid, rid=new_rid)
                    for nm, nr in neigh:
                        if nm != mid:
                            continue

                        if nr in seen:
                            seen.remove(nr)
                        extra.append(nr)

                if rid < self.n[mid]:
                    if rid in seen:
                        seen.remove(rid)
                    extra.append(rid)

        return merges
        
    def mergemat(self, mat:str=None) -> int:
        for ax in range(3):
            merged = self.mergeax(mat=mat, axis=ax) > 0
            while merged == True:
                merged = self.mergeax(mat=mat, axis=ax) > 0
             
    def mergerows(self, rows:NDArray[ROW.DTYPE]=None) -> int:
        if rows is None:
            return 0

        mids_present: set[int] = set()
        for mid in range(rows.shape[0]):
            for i in range(rows.shape[1]):
                if rows[mid][i][*ROW.IDS_ID] != ROW.SENTINEL:
                    mids_present.add(mid)
                    break

        total_merges = 0

        while True:
            merged_this_round = 0

            for ax in (self.mdx.AX_X, self.mdx.AX_Y, self.mdx.AX_Z):
                extra: list[tuple[int, int]] = []
                for mid in mids_present:
                    for rid in range(self.n[mid] - 1, -1, -1):
                        extra.append((mid, rid))

                seen: set[tuple[int, int]] = set()

                while extra:
                    mid, rid = extra.pop()
                    if rid < 0 or rid >= self.n[mid]:
                        continue

                    key = (mid, rid)
                    if key in seen:
                        continue
                    seen.add(key)

                    partner = self.mdx.search(mid=mid, rid=rid, axis=ax)
                    if partner is None:
                        continue

                    pmid, prid = partner
                    if pmid != mid or prid < 0 or prid >= self.n[mid]:
                        continue

                    mat = self.mats.idx2name[mid]

                    if self.merge2(mat=mat, rid0=rid, rid1=prid):
                        merged_this_round += 1
                        total_merges += 1

                        new_rid = self.n[mid] - 1
                        extra.append((mid, new_rid))

                        # recheck the slot that got swapped-in
                        if rid < self.n[mid]:
                            seen.discard((mid, rid))
                            extra.append((mid, rid))

            if merged_this_round == 0:
                break

        return total_merges

    
    def mergeall(self) -> None:
        for mat in self.mats.name2idx.keys():
            self.mergemat(mat=mat)
        
    def merge(self, rows:NDArray[ROW.DTYPE]=None) -> int:
        if rows is None:
            self.mergeall()
        if rows is not None:
            self.mergerows(rows=rows)


    def __repr__(self) -> str:
        return self.__str__()

    def __str__(self) -> str:
        n = self.nrows(mat="STONE")
        return f"ROWS(shape={self.shape}, nbytes={self.nbytes}, gbytes={self.gbytes:.3f} with {n} valid rows)"





rows = ROWS()

################################################################################
# FILE 22/22: world/rows.py (END)
################################################################################


################################################################################
### CAPTURED OUTPUT (STDOUT/STDERR) ###
################################################################################

10 mines to be created at random positions.
Performing SWEEP to consolidate AIR rows... AIR rows before: 10 in sweep iteration: 1
 No more AIR rows could be consolidated. Stopping SWEEP.
Material AIR has 10 rows after SWEEP tests.
  AIR row 0: p0=(871886, 241595, 12515), p1=(871891, 241600, 12520)
  AIR row 1: p0=(260086, 72057, 45224), p1=(260091, 72062, 45229)
  AIR row 2: p0=(747213, 126834, 42851), p1=(747218, 126839, 42856)
  AIR row 3: p0=(312488, 904048, 1453), p1=(312493, 904053, 1458)
  AIR row 4: p0=(925280, 195230, 61011), p1=(925285, 195235, 61016)
  AIR row 5: p0=(179151, 168810, 41569), p1=(179156, 168815, 41574)
  AIR row 6: p0=(628157, 145796, 9533), p1=(628162, 145801, 9538)
  AIR row 7: p0=(851630, 385390, 61539), p1=(851635, 385395, 61544)
  AIR row 8: p0=(289660, 376279, 28825), p1=(289665, 376284, 28830)
  AIR row 9: p0=(646452, 752789, 31232), p1=(646457, 752794, 31237)
Material WATER has 0 rows after SWEEP tests.
Material LAVA has 0 rows after SWEEP tests.
Material GLASS has 0 rows after SWEEP tests.
Material STONE has 51 rows after SWEEP tests.
Material OBSIDIAN has 0 rows after SWEEP tests.
Material BEDROCK has 0 rows after SWEEP tests.
air rows= 10 stone rows= 51
main.py: executed in: lap 2: 2.305605 seconds, total 2.335538 seconds

################################################################################
### END OF CAPTURED OUTPUT ###
################################################################################
# Total lines in bundle: 2495
# Total files in bundle: 22
# Generated at the time: 2026-01-30T16:26:51
--- END OF FILE ---
