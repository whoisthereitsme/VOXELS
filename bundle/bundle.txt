#Time when generated: 2026-01-29T15:17:06

### PROJECT BUNDLE ###
Root: C:\VOXELS
Files included: 22


################################################################################
# FILE 1/22: __init__.py (START)
################################################################################

import utils
import world
import bundle

__all__ = world.__all__ + utils.__all__ + bundle.__all__


################################################################################
# FILE 1/22: __init__.py (END)
################################################################################


################################################################################
# FILE 2/22: __main__.py (START)
################################################################################

from main import main

if __name__ == "__main__":
    main()

################################################################################
# FILE 2/22: __main__.py (END)
################################################################################


################################################################################
# FILE 3/22: bundle/__init__.py (START)
################################################################################

from .bundle import *
from .github import *

__all__ = [
    "Bundle",
    "GitHub",
]

################################################################################
# FILE 3/22: bundle/__init__.py (END)
################################################################################


################################################################################
# FILE 4/22: bundle/bundle.py (START)
################################################################################

from __future__ import annotations
import atexit
import sys
import threading
import time
from pathlib import Path
from typing import Iterable, Optional, Set, TextIO, Callable


from .github import GitHub


# ============================================================
# Bundle builder with integrated output capture (no output.txt, no HTML)
# ============================================================

class Bundle:
    class _Tee(TextIO):
        def __init__(self, original: TextIO, buffer: list[str], lock: threading.Lock) -> None:
            self._original = original
            self._buffer = buffer
            self._lock = lock

            

        def write(self, s: str) -> int:
            n = self._original.write(s)
            with self._lock:
                self._buffer.append(s)
            return n

        def flush(self) -> None:
            self._original.flush()

        def isatty(self) -> bool:
            return getattr(self._original, "isatty", lambda: False)()

        @property
        def encoding(self):
            return getattr(self._original, "encoding", "utf-8")

    def __init__(
        self,
        *,
        root: Path | None = None,
        out: Path | None = None,
        exts: Set[str] | None = None,
        dirs: Set[str] | None = None,
        skip: Set[str] | None = None,
        max_bytes: int = 2_000_000,
        overwrite: bool = True,
        include_stderr: bool = True,
        marker_prefix: str = "### CAPTURE START ###",
        auto_end_on_exit: bool = True,
        auto_end_on_exception: bool = True,
    ) -> None:
        self.root = (root if root is not None else Path.cwd()).resolve()
        self.out = (out if out is not None else (self.root / "bundle" / "bundle.txt")).resolve()

        self.exts = exts if exts is not None else {
            ".py", ".pyi", ".txt", ".md", ".json", ".toml", ".yaml", ".yml", ".ini", ".cfg", ".bat", ".ps1", ".sh",
        }
        self.dirs = dirs if dirs is not None else {
            ".git", ".hg", ".svn", ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            "atlas", "_old", "__OLD",
        }
        self.skip = skip if skip is not None else {".DS_Store", "Thumbs.db"}
        self.max_bytes = int(max_bytes)
        self.overwrite = bool(overwrite)

        self.include_stderr = bool(include_stderr)
        self.marker_prefix = str(marker_prefix)

        self._lock = threading.Lock()
        self._buf_out: list[str] = []
        self._buf_err: list[str] = []

        self._orig_stdout: Optional[TextIO] = None
        self._orig_stderr: Optional[TextIO] = None
        self._orig_excepthook: Optional[Callable] = None
        self._ended = False

        self.start_capture()

        if auto_end_on_exit:
            atexit.register(self.stop_capture_and_write_bundle)

        if auto_end_on_exception:
            self._install_excepthook()

        self.github = GitHub

    def __enter__(self) -> "Bundle":
        return self

    def __exit__(self, exc_type, exc, tb) -> bool:
        self.stop_capture_and_write_bundle()
        self.github()
        return False

    def _install_excepthook(self) -> None:
        self._orig_excepthook = sys.excepthook

        def hooked(exctype, value, tb) -> None:
            if self._orig_excepthook is not None:
                self._orig_excepthook(exctype, value, tb)
            self.stop_capture_and_write_bundle()

        sys.excepthook = hooked  # type: ignore[assignment]

    def start_capture(self) -> None:
        self._orig_stdout = sys.stdout
        self._orig_stderr = sys.stderr

        sys.stdout = self._Tee(self._orig_stdout, self._buf_out, self._lock)  # type: ignore[assignment]
        if self.include_stderr:
            sys.stderr = self._Tee(self._orig_stderr, self._buf_err, self._lock)  # type: ignore[assignment]

        print(f"{self.marker_prefix} root={self.root.as_posix()}")

    def stop_capture_and_write_bundle(self) -> Path:
        captured = self._end_capture_get_text()
        return self.write_bundle_txt(captured_output=captured)

    def _end_capture_get_text(self) -> str:
        if self._ended:
            with self._lock:
                out_text = "".join(self._buf_out)
                err_text = "".join(self._buf_err)
            return self._combine_streams(out_text, err_text)

        self._ended = True

        if self._orig_stdout is not None:
            sys.stdout = self._orig_stdout  # type: ignore[assignment]
        if self.include_stderr and self._orig_stderr is not None:
            sys.stderr = self._orig_stderr  # type: ignore[assignment]

        if self._orig_excepthook is not None:
            sys.excepthook = self._orig_excepthook  # type: ignore[assignment]

        with self._lock:
            out_text = "".join(self._buf_out)
            err_text = "".join(self._buf_err)

        combined = self._combine_streams(out_text, err_text)

        marker_line = f"{self.marker_prefix} root={self.root.as_posix()}"
        combined = self._keep_after_marker(combined, marker_line)
        return combined

    def _combine_streams(self, out_text: str, err_text: str) -> str:
        combined = out_text
        if self.include_stderr and err_text:
            if combined and not combined.endswith("\n"):
                combined += "\n"
            combined += err_text
        return combined

    @staticmethod
    def _keep_after_marker(text: str, marker_line: str) -> str:
        idx = text.rfind(marker_line)
        if idx == -1:
            return text
        nl = text.find("\n", idx)
        if nl == -1:
            return ""
        return text[nl + 1 :]

    def write_bundle_txt(self, *, captured_output: str) -> Path:
        self.out.parent.mkdir(parents=True, exist_ok=True)
        if self.overwrite and self.out.exists():
            self.out.unlink()

        generated_at = time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())
        files = sorted(self._iter_files(self.root), key=lambda p: str(p.relative_to(self.root)).lower())

        lines: list[str] = []
        lines.append(f"#Time when generated: {generated_at}\n\n")
        lines.append("### PROJECT BUNDLE ###\n")
        lines.append(f"Root: {self.root}\n")
        lines.append(f"Files included: {len(files)}\n\n")

        for i, p in enumerate(files, start=1):
            rel = p.relative_to(self.root).as_posix()

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (START)\n")
            lines.append("#" * 80 + "\n\n")

            content = self._safe_read_text_lossy(p)
            if content and not content.endswith("\n"):
                content += "\n"
            lines.append(content)

            lines.append("\n" + "#" * 80 + "\n")
            lines.append(f"# FILE {i}/{len(files)}: {rel} (END)\n")
            lines.append("#" * 80 + "\n\n")

        if captured_output.strip():
            lines.append("\n" + "################################################################################\n")
            lines.append("### CAPTURED OUTPUT (STDOUT/STDERR) ###\n")
            lines.append("################################################################################\n\n")
            lines.append(captured_output if captured_output.endswith("\n") else captured_output + "\n")
            lines.append("\n################################################################################\n")
            lines.append("### END OF CAPTURED OUTPUT ###\n")
            lines.append("################################################################################\n")

        final_text = "".join(lines)
        if not final_text.endswith("\n"):
            final_text += "\n"

        total_lines = final_text.count("\n")
        final_text += f"# Total lines in bundle: {total_lines}\n"
        final_text += f"# Total files in bundle: {len(files)}\n"
        final_text += f"# Generated at the time: {time.strftime('%Y-%m-%dT%H:%M:%S', time.localtime())}\n"
        final_text += "--- END OF FILE ---\n"

        self.out.write_text(final_text, encoding="utf-8")
        return self.out

    def _iter_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.skip:
                continue
            if p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.max_bytes:
                    continue
            except OSError:
                continue

            yield p

    @staticmethod
    def _safe_read_text_lossy(path: Path) -> str:
        try:
            return path.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            return path.read_text(encoding="utf-8", errors="replace")
        except OSError as e:
            return f"<<ERROR READING FILE: {e}>>\n"






################################################################################
# FILE 4/22: bundle/bundle.py (END)
################################################################################


################################################################################
# FILE 5/22: bundle/github.py (START)
################################################################################

import base64
import json
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional, Set

from credentials import *
from utils import Request




@dataclass(frozen=True)
class FileJob:
    local_path: Path
    repo_path: str


class GitHub:
    def __init__(
        self,
        root: Path = Path.cwd(),
        verbose: bool = True,
        workers: int = 12,
        message: str = "Publish project snapshot",
        exts: Optional[Set[str]] = None,
        dirs: Optional[Set[str]] = None,
        files: Optional[Set[str]] = None,
        bytes: int = 2_000_000,
        binary: bool = True,
    ) -> None:
        self.owner = Environ.githublogin
        self.token = Environ.githubtoken
        self.repo = "VOXELS"
        self.branch = "main"
        self.root = root.resolve()
        
        self.verbose = verbose
        self.workers = workers
        self.message = message

        self.exts = exts
        self.dirs = dirs or {
            ".git", ".hg", ".svn",
            ".idea", ".vscode",
            "__pycache__", ".pytest_cache", ".mypy_cache", ".ruff_cache", ".tox",
            ".venv", "venv", "env",
            "node_modules", "dist", "build",
            ".gradle", ".terraform",
            "atlas", "_old", "__OLD",
        }
        self.files = files or {".DS_Store", "Thumbs.db"}
        self.bytes = bytes
        self.binary = binary

        self.lock = threading.Lock()

        self.publish()

    def publish(self) -> None:
        t0 = time.perf_counter()
        if not self.token:
            raise SystemExit(f"Missing environment variable GITHUB_TOKEN.\n", f"Create a fine-grained PAT (Contents: read+write) for repo {self.owner}/{self.repo}.")

        if not self.root.exists() or not self.root.is_dir():
            raise SystemExit(f"root does not exist or is not a directory: {self.root}")

        jobs = self._build_jobs()
        self._log(f"[GITHUB] single-commit publish: {len(jobs)} files from {self.root} -> {self.owner}/{self.repo}@{self.branch}")

        head_commit_sha = self._get_branch_head_commit_sha(self.token)
        base_tree_sha = self._get_commit_tree_sha(self.token, head_commit_sha)

        path_to_blob_sha = self._create_blobs_parallel(self.token, jobs)
        new_tree_sha = self._create_tree(self.token, base_tree_sha, path_to_blob_sha)
        new_commit_sha = self._create_commit(self.token, new_tree_sha, head_commit_sha)
        self._update_branch_ref(self.token, new_commit_sha)

        dt = time.perf_counter() - t0
        self._log(f"[GITHUB] done: 1 commit, {len(jobs)} files, elapsed {dt:.2f}s. files/sec: {len(jobs)/dt:.1f}")

    def _build_jobs(self) -> list[FileJob]:
        files = sorted(self._iter_project_files(self.root), key=lambda p: str(p).lower())
        return [FileJob(p, p.relative_to(self.root).as_posix()) for p in files]

    def _iter_project_files(self, root: Path) -> Iterable[Path]:
        for p in root.rglob("*"):
            if p.is_dir():
                continue

            parts = set(p.parts)
            if any(d in parts for d in self.dirs):
                continue
            if p.name in self.files:
                continue
            if self.exts is not None and p.suffix.lower() not in self.exts:
                continue

            try:
                if p.stat().st_size > self.bytes:
                    continue
            except OSError:
                continue

            if self.binary:
                try:
                    data = p.read_bytes()
                except OSError:
                    continue
                if self._looks_binary(data):
                    continue

            yield p

    @staticmethod
    def _looks_binary(data: bytes) -> bool:
        if b"\x00" in data:
            return True
        sample = data[:8192]
        if not sample:
            return False
        bad = 0
        for b in sample:
            if b in (9, 10, 13) or 32 <= b <= 126:
                continue
            bad += 1
        return (bad / len(sample)) > 0.20

    # -----------------------------
    # GitHub API core
    # -----------------------------
    def _api_request(self, method: str, url: str, token: str, body: Optional[dict] = None) -> dict:
        data = None
        if body is not None:
            data = json.dumps(body).encode("utf-8")

        req = Request(url=url, data=data, method=method, timeout=600, retries=3)
        req.header("Authorization", f"Bearer {token}")
        req.header("Accept", "application/vnd.github+json")
        req.header("X-GitHub-Api-Version", "2022-11-28")
        if data is not None:
            req.header("Content-Type", "application/json; charset=utf-8")

        return req.open()

    def _get_branch_head_commit_sha(self, token: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/ref/heads/{self.branch}"
        j = self._api_request("GET", url, token)
        return j["object"]["sha"]

    def _get_commit_tree_sha(self, token: str, commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits/{commit_sha}"
        j = self._api_request("GET", url, token)
        return j["tree"]["sha"]

    def _create_blob(self, token: str, content_bytes: bytes) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/blobs"
        body = {"content": base64.b64encode(content_bytes).decode("ascii"), "encoding": "base64"}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_blobs_parallel(self, token: str, jobs: list[FileJob]) -> dict[str, str]:
        out: dict[str, str] = {}
        lock = threading.Lock()

        def worker(job: FileJob) -> None:
            data = job.local_path.read_bytes()
            sha = self._create_blob(token, data)
            with lock:
                out[job.repo_path] = sha
            if self.verbose:
                self._log(f"    [blob] {job.repo_path}")

        with ThreadPoolExecutor(max_workers=self.workers) as ex:
            futures = [ex.submit(worker, j) for j in jobs]
            for fut in as_completed(futures):
                fut.result()

        return out

    def _create_tree(self, token: str, base_tree_sha: str, path_to_blob_sha: dict[str, str]) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/trees"
        tree_entries = [
            {"path": path, "mode": "100644", "type": "blob", "sha": blob_sha}
            for path, blob_sha in path_to_blob_sha.items()
        ]
        body = {"base_tree": base_tree_sha, "tree": tree_entries}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _create_commit(self, token: str, tree_sha: str, parent_commit_sha: str) -> str:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/commits"
        body = {"message": self.message, "tree": tree_sha, "parents": [parent_commit_sha]}
        j = self._api_request("POST", url, token, body=body)
        return j["sha"]

    def _update_branch_ref(self, token: str, new_commit_sha: str) -> None:
        url = f"https://api.github.com/repos/{self.owner}/{self.repo}/git/refs/heads/{self.branch}"
        body = {"sha": new_commit_sha, "force": False}
        self._api_request("PATCH", url, token, body=body)

    def _log(self, msg: str) -> None:
        with self.lock:
            print(msg)


################################################################################
# FILE 5/22: bundle/github.py (END)
################################################################################


################################################################################
# FILE 6/22: credentials/__init__.py (START)
################################################################################

from .environ import Environ

__all__ = [
    "Environ"
]   

################################################################################
# FILE 6/22: credentials/__init__.py (END)
################################################################################


################################################################################
# FILE 7/22: credentials/environ.py (START)
################################################################################




import os



class Environ:
    githublogin = os.getenv("GITHUB_LOGIN")
    githubtoken = os.getenv("GITHUB_TOKEN")
    mailadress  = os.getenv("MAIL_ADRESS")
    phonenumber = os.getenv("PHONE_NUMBER")
    ippublic    = os.getenv("IP_PUBLIC")
    ipprivate   = os.getenv("IP_PRIVATE")
    sshkey      = os.getenv("SSH_KEY")


################################################################################
# FILE 7/22: credentials/environ.py (END)
################################################################################


################################################################################
# FILE 8/22: main.py (START)
################################################################################


from utils import *
from world import *
from bundle import *





def main() -> None:
    rows = ROWS()
    row = rows.array[ MATERIALS.IDX["STONE"] ][0]
    rows.remove(row=row)

    cell = 20          # cube edge length
    nx = 40            # number of cells in X  -> world X size = nx*cell
    ny = 40            # number of cells in Y
    nz = 40            # number of cells in Z
    n = nx * ny * nz  # total number of cells

    timer.lap()
    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.insert(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg="STEP 1 :  3D grid partition built")

    max_x = nx * cell - 1
    max_y = ny * cell - 1
    max_z = nz * cell - 1

    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (
                random.randint(0, max_x),
                random.randint(0, max_y),
                random.randint(0, max_z),
            )
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Random CONTAINS checks completed in")

    print(" - Now deleting all rows...")
    for i in range(10000):
        row = rows.array[ MATERIALS.IDX["STONE"] ][n-1-i]
        rows.remove(row=row)
    timer.print(msg=" - All 10000 rows deleted in")
    # and now test wiht a new set adn see if it still works
    print("STEP 2 : Rebuilding rows after deletion...")
    cell = 40          # double size
    nx = 20            # half number of cells in X  -> world X size = nx*cell
    ny = 20            # half number of cells in Y
    nz = 20            # half number of cells in Z
    n = nx * ny * nz   # total number of cells (1/8th number of previous)

    for ix in range(nx):
        x0 = ix * cell
        x1 = x0 + cell
        for iy in range(ny):
            y0 = iy * cell
            y1 = y0 + cell
            for iz in range(nz):
                z0 = iz * cell
                z1 = z0 + cell
                rows.insert(p0=(x0, y0, z0), p1=(x1, y1, z1), mat="STONE")
                

    timer.print(msg=" - second time 3D grid partition built")
    succes = 0
    fails = 0
    for _ in range(1000):
        try:
            pos = (
                random.randint(0, max_x),
                random.randint(0, max_y),
                random.randint(0, max_z),
            )
            mat, rid, row = rows.find(pos=pos)
            assert ROW.CONTAINS(row=row, pos=pos), f"pos={pos} not contained by found row (mat={mat}, rid={rid})"
            succes += 1
        except:
            fails += 1
            pass

    print(" - All random CONTAINS checks passed.", f"Successes: {succes}, Fails: {fails} is a succes percentage of {100-fails/(succes+fails)*100:.2f}% adn per lookup {(succes+fails)/timer.delta[-1]:.2f} lookups/second")
    timer.print(msg=" - Second random CONTAINS checks completed in")

    if succes == 1000 and fails == 0:
        print("FINALLY: TESTS PASSED SUCCESSFULLY!")

    print("STEP 3 : Now testing SPLIT functionality...")
    rows = ROWS() # it has by default a large enough array to hold 10000 rows per material
    print("WORLD VOLUME BEFORE: ", rows.volume())
    print(rows.size)
    # 1 row exists normally at tis point -> its created at init with STONE material
    for i in range(1000):
        x = random.randint(a=1000, b=999000)
        y = random.randint(a=1000, b=999000)
        z = random.randint(a=1000, b=64000)
        rows.split(pos=(x, y, z), mat="AIR")  # should raise error since no rows exist yet
        print(f" - SPLIT test {i+1}/10 passed.")

    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SPLIT tests.")
    
    print("WORLD VOLUME AFTER: ", rows.volume())

    timer.print(msg="STARTING STEP 4 : Now testing SWEEP functionality...")
    rows.sweep()
    timer.print(msg=" - SWEEP completed in")
    rows.sweep()
    timer.print(msg=" - Second SWEEP completed in")

    print("WORLD VOLUME AFTER SWEEP: ", rows.volume())

    for i in range(len(rows.array)):
        n = rows.nrows(mat=Materials.idx2name[i])
        print(f"Material {Materials.idx2name[i]} has {n} rows after SWEEP tests.")







if __name__ == "__main__":
    timer.lap()
    with Bundle():
        try:
            main()
            timer.print(msg="main.py: executed in")
        except Exception:
            traceback.print_exc()
        finally:    
            pass



################################################################################
# FILE 8/22: main.py (END)
################################################################################


################################################################################
# FILE 9/22: TODO.md (START)
################################################################################




# ! ROWS
# TODO: ROWS.SPLIT(pos:POS=None)
# TODO: ROWS.MERGE(row0:NDARRAY=None, row1:NDARRAY=None)
# TODO: 

# ! UTILS
# TODO: 

# ! BUNDLE
# TODO: CLEANUP!!!

################################################################################
# FILE 9/22: TODO.md (END)
################################################################################


################################################################################
# FILE 10/22: utils/__init__.py (START)
################################################################################

from .request import Request
from .includes import *
from .includes import __all__ as inc
__all__ = [
    "Request",
] + inc

################################################################################
# FILE 10/22: utils/__init__.py (END)
################################################################################


################################################################################
# FILE 11/22: utils/bvh.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from numpy.typing import NDArray
    from world.rows import ROWS
    from utils.types import POS

from world.row import ROW





class BVH:
    __slots__ = (
        "rows",
        "root",
        "left",
        "right",
        "parent",
        # AABB as 6 parallel lists (SoA)
        "xmin",
        "ymin",
        "zmin",
        "xmax",
        "ymax",
        "zmax",
        # leaf as 2 parallel lists
        "leaf_mid",
        "leaf_rid",
        # fast delete index
        "leaf_index",
    )

    def __init__(self, rows: ROWS) -> None:
        self.rows = rows
        self.root: int = -1

        self.left: list[int] = []
        self.right: list[int] = []
        self.parent: list[int] = []

        self.xmin: list[int] = []
        self.ymin: list[int] = []
        self.zmin: list[int] = []
        self.xmax: list[int] = []
        self.ymax: list[int] = []
        self.zmax: list[int] = []

        self.leaf_mid: list[int] = []
        self.leaf_rid: list[int] = []

        # (mid, rid) -> node index
        self.leaf_index: dict[tuple[int, int], int] = {}

    # ------------------------------------------------------------------
    # node alloc
    # ------------------------------------------------------------------

    def _new_node(
        self,
        xmin: int,
        ymin: int,
        zmin: int,
        xmax: int,
        ymax: int,
        zmax: int,
        leaf_mid: int = -1,
        leaf_rid: int = -1,
        left: int = -1,
        right: int = -1,
        parent: int = -1,
    ) -> int:
        i = len(self.left)

        self.left.append(left)
        self.right.append(right)
        self.parent.append(parent)

        self.xmin.append(xmin)
        self.ymin.append(ymin)
        self.zmin.append(zmin)
        self.xmax.append(xmax)
        self.ymax.append(ymax)
        self.zmax.append(zmax)

        self.leaf_mid.append(leaf_mid)
        self.leaf_rid.append(leaf_rid)
        return i

    # ------------------------------------------------------------------
    # helpers
    # ------------------------------------------------------------------

    @staticmethod
    def _volume(xmin: int, ymin: int, zmin: int, xmax: int, ymax: int, zmax: int) -> int:
        return (xmax - xmin) * (ymax - ymin) * (zmax - zmin)

    def _merged_volume_with_node(
        self,
        node: int,
        bxmin: int,
        bymin: int,
        bzmin: int,
        bxmax: int,
        bymax: int,
        bzmax: int,
    ) -> int:
        axmin = self.xmin[node]
        aymin = self.ymin[node]
        azmin = self.zmin[node]
        axmax = self.xmax[node]
        aymax = self.ymax[node]
        azmax = self.zmax[node]

        mxmin = axmin if axmin < bxmin else bxmin
        mymin = aymin if aymin < bymin else bymin
        mzmin = azmin if azmin < bzmin else bzmin
        mxmax = axmax if axmax > bxmax else bxmax
        mymax = aymax if aymax > bymax else bymax
        mzmax = azmax if azmax > bzmax else bzmax

        return self._volume(mxmin, mymin, mzmin, mxmax, mymax, mzmax)

    def _fix_upwards(self, node:int=None) -> None:
        while node != -1:
            l = self.left[node]
            r = self.right[node]

            self.xmin[node] = self.xmin[l] if self.xmin[l] < self.xmin[r] else self.xmin[r]
            self.ymin[node] = self.ymin[l] if self.ymin[l] < self.ymin[r] else self.ymin[r]
            self.zmin[node] = self.zmin[l] if self.zmin[l] < self.zmin[r] else self.zmin[r]
            self.xmax[node] = self.xmax[l] if self.xmax[l] > self.xmax[r] else self.xmax[r]
            self.ymax[node] = self.ymax[l] if self.ymax[l] > self.ymax[r] else self.ymax[r]
            self.zmax[node] = self.zmax[l] if self.zmax[l] > self.zmax[r] else self.zmax[r]

            node = self.parent[node]

    # ------------------------------------------------------------------
    # insertion
    # ------------------------------------------------------------------

    def insert(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is None:
            mid = self.rows.mats.name2idx[mat]
            row = self.rows.array[mid][rid]
        else:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])

        xmin, ymin, zmin = ROW.P0(row)
        xmax, ymax, zmax = ROW.P1(row)

        leaf_node = self._new_node(
            xmin, ymin, zmin,
            xmax, ymax, zmax,
            leaf_mid=mid,
            leaf_rid=rid,
        )

        self.leaf_index[(mid, rid)] = leaf_node

        if self.root == -1:
            self.root = leaf_node
            return

        self.root = self._insert_node(self.root, leaf_node)

    def _insert_node(self, root: int, leaf_node: int) -> int:
        bxmin = self.xmin[leaf_node]; bymin = self.ymin[leaf_node]; bzmin = self.zmin[leaf_node]
        bxmax = self.xmax[leaf_node]; bymax = self.ymax[leaf_node]; bzmax = self.zmax[leaf_node]

        node = root
        while self.leaf_mid[node] == -1:
            l = self.left[node]
            r = self.right[node]
            node = (
                l if self._merged_volume_with_node(l, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                < self._merged_volume_with_node(r, bxmin, bymin, bzmin, bxmax, bymax, bzmax)
                else r
            )

        old_leaf = node
        parent = self.parent[old_leaf]

        axmin = self.xmin[old_leaf]; aymin = self.ymin[old_leaf]; azmin = self.zmin[old_leaf]
        axmax = self.xmax[old_leaf]; aymax = self.ymax[old_leaf]; azmax = self.zmax[old_leaf]

        new_parent = self._new_node(
            axmin if axmin < bxmin else bxmin,
            aymin if aymin < bymin else bymin,
            azmin if azmin < bzmin else bzmin,
            axmax if axmax > bxmax else bxmax,
            aymax if aymax > bymax else bymax,
            azmax if azmax > bzmax else bzmax,
        )

        self.left[new_parent] = old_leaf
        self.right[new_parent] = leaf_node
        self.parent[old_leaf] = new_parent
        self.parent[leaf_node] = new_parent

        if parent == -1:
            return new_parent

        if self.left[parent] == old_leaf:
            self.left[parent] = new_parent
        else:
            self.right[parent] = new_parent

        self.parent[new_parent] = parent
        self._fix_upwards(parent)
        return root

    # ------------------------------------------------------------------
    # removal (FAST)
    # ------------------------------------------------------------------

    def remove(self, mat:str=None, rid:int=None, row:NDArray[ROW.DTYPE]=None) -> None:
        if row is not None:
            mat_id = int(row[*ROW.IDS_MAT])
            mid = self.rows.mats.id2idx[mat_id]
            rid = int(row[*ROW.IDS_ID])
        else:
            mid = self.rows.mats.name2idx[mat]

        try:
            found = self.leaf_index.pop((mid, rid))
        except KeyError:
            raise KeyError("[ERROR] BVH.remove() failed: row not found in BVH")

        parent = self.parent[found]
        if parent == -1:
            self.root = -1
            return

        sibling = self.right[parent] if self.left[parent] == found else self.left[parent]
        grand = self.parent[parent]

        if grand == -1:
            self.root = sibling
            self.parent[sibling] = -1
        else:
            if self.left[grand] == parent:
                self.left[grand] = sibling
            else:
                self.right[grand] = sibling
            self.parent[sibling] = grand
            self._fix_upwards(grand)

    # ------------------------------------------------------------------
    # find
    # ------------------------------------------------------------------

    def find(self, pos:POS=None) -> tuple[str, int, "NDArray[ROW.DTYPE]"]:
        if self.root == -1:
            raise LookupError("[ERROR] BVH.find() failed: empty BVH")

        x, y, z = pos
        stack = [self.root]

        xminL = self.xmin; yminL = self.ymin; zminL = self.zmin
        xmaxL = self.xmax; ymaxL = self.ymax; zmaxL = self.zmax
        leftL = self.left; rightL = self.right
        leaf_midL = self.leaf_mid; leaf_ridL = self.leaf_rid
        rows_arr = self.rows.array
        idx2name = self.rows.mats.idx2name

        while stack:
            n = stack.pop()
            if n == -1:
                continue

            if not (xminL[n] <= x < xmaxL[n] and yminL[n] <= y < ymaxL[n] and zminL[n] <= z < zmaxL[n]):
                continue

            mid = leaf_midL[n]
            if mid != -1:
                rid = leaf_ridL[n]
                row = rows_arr[mid][rid]
                if ROW.CONTAINS(row=row, pos=pos):
                    return idx2name[mid], rid, row
                continue

            l = leftL[n]
            r = rightL[n]

            if l != -1 and (xminL[l] <= x < xmaxL[l] and yminL[l] <= y < ymaxL[l] and zminL[l] <= z < zmaxL[l]):
                stack.append(l)
            if r != -1 and (xminL[r] <= x < xmaxL[r] and yminL[r] <= y < ymaxL[r] and zminL[r] <= z < zmaxL[r]):
                stack.append(r)

        raise LookupError("[ERROR] BVH.find() failed: point not found (partition invariant violated or BVH not updated)")
















################################################################################
# FILE 11/22: utils/bvh.py (END)
################################################################################


################################################################################
# FILE 12/22: utils/event.py (START)
################################################################################

from __future__ import annotations
from typing import Any, Callable
from dataclasses import dataclass, field
from .event import Event
from .schedule import Schedule



@dataclass(order=True)
class Event:
    due_ns: int
    seq: int
    callback: Callable[..., Any] = field(compare=False)
    args: tuple[Any, ...] = field(default_factory=tuple, compare=False)
    kwargs: dict[str, Any] = field(default_factory=dict, compare=False)
    cancelled: bool = field(default=False, compare=False)


class Handler:
    __slots__ = ("_scheduler", "_event")

    def __init__(self, scheduler: "Schedule", event: Event) -> None:
        self._scheduler = scheduler
        self._event = event

    def cancel(self) -> bool:
        return self._scheduler.cancel(self)


################################################################################
# FILE 12/22: utils/event.py (END)
################################################################################


################################################################################
# FILE 13/22: utils/includes.py (START)
################################################################################

from __future__ import annotations  # MUST BE FIRST

# EXCEPTION IMPORTS
from .timer import Timer, time      # NON SORTED -> HERE BECAUSE Timer IS USED IMMEDIATELY
timer = Timer()

# IMPORTS FROM STANDARD LIBRARY AND THIRD-PARTY LIBRARIES
from typing import TYPE_CHECKING, Any, Iterator, TypeVar, Generic, Union, Tuple, List, Dict, Callable, Optional
from pathlib import Path
from numpy.typing import NDArray
from PIL import Image, ImageDraw, ImageFont


# SIMPLE IMPORTS
import math
import numpy as np
import torch 
import heapq
import threading
import json
import time
import pathlib
import sys
import os
import random
import shutil
import datetime
import bisect
import pygame
import moderngl
import traceback
import stat



# my own modules (utils)
from .types import POS, SIZE


# Exports
__all__ = [
    "math",
    "time",
    "np",
    "NDArray",
    "torch",
    "TYPE_CHECKING",
    "annotations",
    "Any",
    "Iterator",
    "TypeVar",
    "Generic",
    "Union",
    "Tuple",
    "List",
    "Dict",
    "Callable",
    "Optional",
    "Image",
    "ImageDraw",
    "ImageFont",
    "Timer",
    "heapq",
    "threading",
    "json",
    "Path",
    "POS",
    "SIZE",
    "pathlib",
    "sys",
    "os",
    "random",
    "shutil",
    "datetime",
    "bisect",
    "pygame",
    "moderngl",
    "timer", # include the instance timer -> can be used as utils.timer
    "traceback",
    "stat",
]


timer.print(msg=f"utils/includes.py: {len(__all__)} modules loaded in")
timer.reset()

################################################################################
# FILE 13/22: utils/includes.py (END)
################################################################################


################################################################################
# FILE 14/22: utils/mdx.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from world.rows import ROWS



from collections import defaultdict
from dataclasses import dataclass
from typing import DefaultDict, Dict, Optional, Set, Tuple

from world.row import ROW

# rid locator
Loc = Tuple[int, int]  # (mid, rid)

# Face keys:
# We include mid (material index) so we can merge per-material quickly.
# The spans must match exactly on the other two axes.
FaceKey = Tuple[int, int, int, int, int, int]  # (mid, a0, a1, b0, b1, face_coord)


@dataclass
class _RowFaces:
    # store the 6 keys so we can unregister quickly without recomputing
    x0: FaceKey
    x1: FaceKey
    y0: FaceKey
    y1: FaceKey
    z0: FaceKey
    z1: FaceKey


class MDX:
    """
    Tracks adjacency candidates for merges using face hashing.

    For each axis we maintain:
      neg[axis][key] -> set of (mid,rid) with face at MIN along that axis
      pos[axis][key] -> set of (mid,rid) with face at MAX along that axis

    A merge along X exists when:
      pos[X][(mid, y0,y1,z0,z1, x)] intersects neg[X][(mid, y0,y1,z0,z1, x)]
    """

    AX_X = 0
    AX_Y = 1
    AX_Z = 2

    def __init__(self, rows:ROWS=None) -> None:
        self.rows = rows
        # axis -> key -> set(loc)
        self.neg: Tuple[DefaultDict[FaceKey, Set[Loc]], ...] = (
            defaultdict(set), defaultdict(set), defaultdict(set)
        )
        self.pos: Tuple[DefaultDict[FaceKey, Set[Loc]], ...] = (
            defaultdict(set), defaultdict(set), defaultdict(set)
        )

        # (mid,rid) -> stored face keys (for O(1) unregister)
        self._faces: Dict[Loc, _RowFaces] = {}

    # ---------------------------
    # key construction
    # ---------------------------
    @staticmethod
    def _faces_for(mid: int, row) -> _RowFaces:
        x0, y0, z0 = ROW.P0(row=row)
        x1, y1, z1 = ROW.P1(row=row)
        # axis X: spans are (y0,y1,z0,z1), face coord is x0 or x1
        kx0: FaceKey = (mid, y0, y1, z0, z1, x0)
        kx1: FaceKey = (mid, y0, y1, z0, z1, x1)
        # axis Y: spans are (x0,x1,z0,z1), face coord is y0 or y1
        ky0: FaceKey = (mid, x0, x1, z0, z1, y0)
        ky1: FaceKey = (mid, x0, x1, z0, z1, y1)
        # axis Z: spans are (x0,x1,y0,y1), face coord is z0 or z1
        kz0: FaceKey = (mid, x0, x1, y0, y1, z0)
        kz1: FaceKey = (mid, x0, x1, y0, y1, z1)
        return _RowFaces(x0=kx0, x1=kx1, y0=ky0, y1=ky1, z0=kz0, z1=kz1)

    # ---------------------------
    # register / unregister
    # ---------------------------
    def insert(self, row=None) -> None:
        mid = self.rows.mats.name2idx[ROW.MAT(row=row)]
        rid = ROW.RID(row=row)
        loc = (mid, rid)
        faces = self._faces_for(mid, row)
        self._faces[loc] = faces

        self.neg[self.AX_X][faces.x0].add(loc)
        self.pos[self.AX_X][faces.x1].add(loc)

        self.neg[self.AX_Y][faces.y0].add(loc)
        self.pos[self.AX_Y][faces.y1].add(loc)

        self.neg[self.AX_Z][faces.z0].add(loc)
        self.pos[self.AX_Z][faces.z1].add(loc)

    def remove(self, mat:str=None, rid:int=None) -> None:
        mid = self.rows.mats.name2idx[mat]
        loc = (mid, rid)
        faces = self._faces.pop(loc, None)
        if faces is None:
            return

        self._discard(self.neg[self.AX_X], faces.x0, loc)
        self._discard(self.pos[self.AX_X], faces.x1, loc)

        self._discard(self.neg[self.AX_Y], faces.y0, loc)
        self._discard(self.pos[self.AX_Y], faces.y1, loc)

        self._discard(self.neg[self.AX_Z], faces.z0, loc)
        self._discard(self.pos[self.AX_Z], faces.z1, loc)

    @staticmethod
    def _discard(m: DefaultDict[FaceKey, Set[Loc]], key: FaceKey, loc: Loc) -> None:
        s = m.get(key)
        if not s:
            return
        s.discard(loc)
        if not s:
            # keep dict small
            del m[key]

    # ---------------------------
    # rid move helper (swap-delete)
    # ---------------------------
    def move_rid(self, mid: int, old_rid: int, new_rid: int, row) -> None:
        self.remove(mat=self.rows.mats.idx2name[mid], rid=old_rid)
        self.insert(row=row)

    # ---------------------------
    # partner query
    # ---------------------------
    def find_partner(self, mid: int, rid: int, axis: int) -> Optional[Loc]:
        """
        Finds any merge partner for (mid,rid) along given axis.
        Returns (mid, rid2) or None.
        """
        loc = (mid, rid)
        faces = self._faces.get(loc)
        if faces is None:
            return None

        if axis == self.AX_X:
            # partner has x0 == our x1, same yz span
            key = faces.x1
            candidates = self.neg[self.AX_X].get(key)
        elif axis == self.AX_Y:
            key = faces.y1
            candidates = self.neg[self.AX_Y].get(key)
        elif axis == self.AX_Z:
            key = faces.z1
            candidates = self.neg[self.AX_Z].get(key)
        else:
            raise ValueError("axis must be 0,1,2")

        if not candidates:
            return None

        # return any candidate that isn't self
        for c in candidates:
            if c != loc:
                return c
        return None

################################################################################
# FILE 14/22: utils/mdx.py (END)
################################################################################


################################################################################
# FILE 15/22: utils/request.py (START)
################################################################################

import time
import urllib.request
import urllib.error
import json


class Request:
    def __init__(self, url: str = None, timeout: int = 600, retries: int = 3, data=None, method: str = None) -> None:
        self.timeout = timeout
        self.retries = retries
        self._retries = retries
        self.url = url
        self.data = data
        self.method = method

        self.init()

    def init(self) -> None:
        self.request = urllib.request.Request(url=self.url, data=self.data, method=self.method)

    def header(self, key: str = None, value: str = None) -> None:
        self.request.add_header(key, value)

    def open(self) -> dict:
        try:
            with urllib.request.urlopen(self.request, timeout=self.timeout) as response:
                raw = response.read().decode("utf-8", errors="replace")
                try:
                    return json.loads(raw) if raw else {}
                
                except json.JSONDecodeError as e:
                    raise RuntimeError(f"[ERROR] invalid JSON response for {self.url}\n{e!r}\n---\n{raw[:200]}") from e

        except urllib.error.HTTPError as e:
            raw = e.read().decode("utf-8", errors="replace")
            retryable = (e.code == 429) or (500 <= e.code <= 599)

            if retryable and self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] {e.code} for {self.url}\n{raw}") from e

        except (urllib.error.URLError, TimeoutError, OSError) as e:
            if self.retries > 0:
                self.retries -= 1
                time.sleep(0.5 * (2 ** (self._retries - self.retries)))
                return self.open()
            raise RuntimeError(f"[ERROR] request failed for {self.url}\n{e!r}") from e
        
        except Exception as e:
            raise RuntimeError(f"[ERROR] unexpected error for {self.url}\n{e!r}") from e

################################################################################
# FILE 15/22: utils/request.py (END)
################################################################################


################################################################################
# FILE 16/22: utils/schedule.py (START)
################################################################################

import threading
from typing import Any, Callable, Optional
import heapq
from .timer import Timer, now
from .event import Event, Handler



class Schedule:
    def __init__(self) -> None:
        self._timer = Timer()

        self._lock = threading.Lock()
        self._cv = threading.Condition(self._lock)
        self._pq: list[Event] = []
        self._seq = 0

        self._worker: Optional[threading.Thread] = None
        self._stop = False
        self._running = False

        self.start()

    def start(self) -> None:
        with self._lock:
            if self._running:
                return
            self._stop = False
            self._worker = threading.Thread(target=self._run, name="SchedulerWorker", daemon=True)
            self._running = True
            self._worker.start()

    def stop(self) -> None:
        with self._lock:
            if not self._running:
                return
            self._stop = True
            self._cv.notify_all()

        if self._worker:
            self._worker.join(timeout=2.0)

        with self._lock:
            self._running = False
            self._worker = None

    def schedule(self, ns: int=None, fn: Callable[..., Any]=None, *args: Any, **kwargs: Any) -> Handler:
        with self._lock:
            self._seq += 1
            ev = Event(due_ns=ns, seq=self._seq, callback=fn, args=args, kwargs=kwargs)
            heapq.heappush(self._pq, ev)
            self._cv.notify_all()
            return Handler(self, ev)

    def new(self, seconds:float=None, fn:Callable[..., Any]=None, delay=False, *args: Any, **kwargs: Any) -> Handler:
        if delay==True:
            ns = now() + int(seconds * 1e9)
        if delay==False:
            ns = int(seconds * 1e9)
        return self.schedule(ns=ns, fn=fn, *args, **kwargs)
    

    def cancel(self, handle: Handler) -> bool:
        with self._lock:
            if handle._event.cancelled:
                return False
            handle._event.cancelled = True
            self._cv.notify_all()
            return True

    def _run(self) -> None:
        while True:
            with self._lock:
                # Wait until there is work or stop requested
                while not self._pq and not self._stop:
                    self._cv.wait()

                if self._stop:
                    return

                # Drop cancelled events at head
                while self._pq and self._pq[0].cancelled:
                    heapq.heappop(self._pq)

                if not self._pq:
                    continue

                ev = self._pq[0]
                due = ev.due_ns

            # 2) Wait until deadline (no lock held)
            self._timer.waitns(due)

            # 3) Pop-and-execute if still valid
            with self._lock:
                if self._stop:
                    return

                if not self._pq:
                    continue
                if self._pq[0] is not ev:
                    continue

                heapq.heappop(self._pq)
                if ev.cancelled:
                    continue

            try:
                ev.callback(*ev.args, **ev.kwargs)
            except Exception as e:
                # Keep scheduler alive; replace with logging if desired
                print(f"[Schedule] callback error: {e!r}")






















# ============================================================
# Example usage
# ============================================================

if __name__ == "__main__":
    import time

    sched = Schedule()
    def hello(who:str=None, n:int=1) -> None:
        print(f"{time.perf_counter():.3f} hello {who} x{n}")
    def test(who:str=None,  n:int=1) -> None:
        print(who, n*n)

    h1 = sched.new(seconds=0.050, fn=test, who="A", n=2, delay=True)
    h2 = sched.new(seconds=0.120, fn=hello, who="B", n=3, delay=True)
    h3 = sched.new(seconds=0.080, fn=test, who="C", n=1, delay=True)
    h2.cancel()
    futuretime = time.perf_counter() + 0.100
    h4 = sched.new(seconds=futuretime, fn=hello, who="D", n=4, delay=False)
    h5 = sched.new(seconds=futuretime, fn=test, who="E", n=5, delay=False)
    h6 = sched.new(seconds=futuretime, fn=hello, who="F", n=6, delay=False)


    time.sleep(0.2)
    sched.stop()

################################################################################
# FILE 16/22: utils/schedule.py (END)
################################################################################


################################################################################
# FILE 17/22: utils/timer.py (START)
################################################################################

from __future__ import annotations
import time



class Timer:
    def __init__(self) -> None:
        self.coarse_ns = 2_000_000
        self.spin_ns = 1_000_000

        self.start()

    def nowns(self) -> int:  # can be used as Timer().nowns()
        return time.perf_counter_ns()
    
    @staticmethod   # can be used as Timer.now()
    def now() -> float:
        return time.perf_counter_ns()

    def start(self) -> int:
        self.started = self.nowns()
        self.t0 = self.started
        self.delta = []
        self.times = []
        return self.t0
    
    def lap(self) -> int:
        t1 = self.nowns()
        t0 = self.t0
        self.t0 = t1
        dt = round((t1 - t0) / 1e9, 6) # seconds
        self.delta.append(dt)
        self.times.append(t1)
        return dt       # time since last lap in seconds
    
    def stop(self) -> int:
        self.lap()
        first = self.started
        last = self.times[-1]
        t = round((last - first) / 1e9, 6) # seconds with 6 decimal places (microseconds) 
        return t        # total since started
    
    def print(self, msg:str=None) -> None:
        self.lap()
        txt = f"lap {len(self.delta)}: {self.delta[-1]} seconds, total {round((self.times[-1] - self.started) / 1e9, 6)} seconds"
        if msg is not None:
            txt = f"{msg}: {txt}"
        print(txt)

    def waitns(self, deadline_ns: int) -> None:
        coarse_ns = self.coarse_ns
        spin_ns = self.spin_ns

        while True:
            n = self.nowns()
            remaining = deadline_ns - n
            if remaining <= 0:
                return

            # FAR: sleep until within coarse_ns
            if remaining > coarse_ns:
                time.sleep((remaining - coarse_ns) / 1e9)
                continue

            # NEAR: yield until within spin_ns
            if remaining > spin_ns:
                time.sleep(0)
                continue

            # FINAL: busy-spin
            while self.nowns() < deadline_ns:
                pass
            return

    def wait(self, seconds: float) -> None:
        if seconds <= 0:
            return
        self.waitns(self.nowns() + int(seconds * 1e9))

    def reset(self) -> int:
        t = self.stop()
        self.start()
        return t  # total since started before reset


now = Timer.now # now: now() returns the current time in nanoseconds

################################################################################
# FILE 17/22: utils/timer.py (END)
################################################################################


################################################################################
# FILE 18/22: utils/types.py (START)
################################################################################

from typing import TypeAlias
POS: TypeAlias = tuple[int, int, int]
SIZE: TypeAlias = tuple[int, int, int]

__all__ = [
    "POS",
    "SIZE",
]

################################################################################
# FILE 18/22: utils/types.py (END)
################################################################################


################################################################################
# FILE 19/22: world/__init__.py (START)
################################################################################

from .rows import ROWS, rows
from .row import ROW
from .materials import MATERIALS, Materials, Material

from utils import *
from world import *
from bundle import *

__all__ = [
    "MATERIALS",
    "Materials",
    "Material",
    "ROW",
    "ROWS",
    "rows",
]

################################################################################
# FILE 19/22: world/__init__.py (END)
################################################################################


################################################################################
# FILE 20/22: world/materials.py (START)
################################################################################
















class MATERIALS:
    TYPES = {
        "INVIS": 0,     # start at 16384                # invisible
        "TRANS": 1,     # start at 32768                # transparent
        "SOLID": 2,     # start at 65536                # solid
        "ROCKS": 3,     # start at 4294967296           # indestructible
    }

    DATA  = {
        "AIR":      (16384+0,     TYPES["INVIS"]),

        "WATER":    (32768+0,     TYPES["TRANS"]), 
        "LAVA":     (32768+1,     TYPES["TRANS"]),
        "GLASS":    (32768+2,     TYPES["TRANS"]),

        "STONE":    (65536+0,     TYPES["SOLID"]),
        "OBSIDIAN": (65536+1,     TYPES["SOLID"]),

        "BEDROCK":  (4294967296+0,TYPES["ROCKS"]),
    }

    IDX = {name: i for i, name in enumerate(DATA.keys())}

    NUM = len(DATA)

class Material:
    def __init__(self, name:str=None) -> None:
        self.id, self.type = MATERIALS.DATA.get(name, (None, None)) 
        self.idx = MATERIALS.IDX.get(name, None) 
        if self.id is None or self.type is None or self.idx is None:
            raise ValueError(f"Invalid material name: {name}")

    def isrocks(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

    def issolid(self) -> bool:
        return self.type == MATERIALS.TYPES["SOLID"]
    
    def istrans(self) -> bool:
        return self.type == MATERIALS.TYPES["TRANS"]
    
    def isinvisible(self) -> bool:
        return self.type == MATERIALS.TYPES["INVIS"]
    
    def isindestructible(self) -> bool:
        return self.type == MATERIALS.TYPES["ROCKS"]

class Materials:
    idx2name = {idx: name for name, idx in MATERIALS.IDX.items()}
    name2idx = MATERIALS.IDX

    name2id  = {name: pair[0] for name, pair in MATERIALS.DATA.items()}
    id2name  = {pair[0]: name for name, pair in MATERIALS.DATA.items()}

    # the one you actually need:
    id2idx   = {pair[0]: MATERIALS.IDX[name] for name, pair in MATERIALS.DATA.items()}
    idx2id   = {MATERIALS.IDX[name]: pair[0] for name, pair in MATERIALS.DATA.items()}


    def __init__(self) -> None:
        for name in MATERIALS.DATA.keys():
            setattr(self, name.lower(), Material(name=name))

    def idx(self, name: str = None, id: int = None) -> int:
        if (name is None) == (id is None):
            raise ValueError("Provide exactly one of name or id")
        return self.name2idx[name] if name is not None else self.id2idx[id]

    def id(self, name: str = None, idx: int = None) -> int:
        if (name is None) == (idx is None):
            raise ValueError("Provide exactly one of name or idx")
        return self.name2id[name] if name is not None else self.idx2id[idx]

    def name(self, id: int = None, idx: int = None) -> str:
        if (id is None) == (idx is None):
            raise ValueError("Provide exactly one of id or idx")
        return self.id2name[id] if id is not None else self.idx2name[idx]


################################################################################
# FILE 20/22: world/materials.py (END)
################################################################################


################################################################################
# FILE 21/22: world/row.py (START)
################################################################################

from __future__ import annotations
import stat
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass



import numpy as np
from numpy.typing import NDArray


from utils.types import SIZE, POS
from world.materials import Material, Materials





class ROW:
    DTYPE = np.uint64
    SHAPE = (4, 4)
    NBITS = DTYPE(0).nbytes * 8                      # -> 64 bits

    XBITS = 20
    YBITS = 20
    ZBITS = 16
    if XBITS + YBITS + ZBITS + 1 > NBITS:
        raise ValueError("bit allocation error")

    XMIN = 0
    YMIN = 0
    ZMIN = 0
    XMAX = 2**XBITS
    YMAX = 2**YBITS
    ZMAX = 2**ZBITS
    NMAX = XMAX * YMAX * ZMAX
    

    # POSITIONS (MIN)  stored in row 0
    IDS_X0 = (0, 0)
    IDS_Y0 = (0, 1)
    IDS_Z0 = (0, 2)

    # POSITIONS (MAX)  stored in row 1
    IDS_X1 = (1, 0)
    IDS_Y1 = (1, 1)
    IDS_Z1 = (1, 2)

    # DIMENSIONS  stored in row 2
    IDS_DX = (2, 0)
    IDS_DY = (2, 1)
    IDS_DZ = (2, 2)

    # METADATA  stored in row 3
    IDS_ID    = (3, 0)
    IDS_MAT   = (3, 1)
    IDS_FLAGS = (3, 2)

    ENCODE_DIRTY        = DTYPE(1 << 0)
    ENCODE_ALIVE        = DTYPE(1 << 1)
    ENCODE_SOLID        = DTYPE(1 << 2)
    ENCODE_DESTRUCTABLE = DTYPE(1 << 3)
    ENCODE_VISIBLE      = DTYPE(1 << 4)

    SENTINEL = np.iinfo(DTYPE).max
    ARRAY: NDArray[DTYPE] = np.zeros(SHAPE, dtype=DTYPE)
    for i in range(4):
        for j in range(4):
            ARRAY[i, j] = SENTINEL  # initialize all to -1 -> invalid
    _ID = 0
    
    @staticmethod # get min position (x0, y0, z0)   
    def P0(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X0]), int(row[*ROW.IDS_Y0]), int(row[*ROW.IDS_Z0]))
    
    @staticmethod # get max position (x1, y1, z1)
    def P1(row:NDArray[DTYPE]=None) -> POS:
        return (int(row[*ROW.IDS_X1]), int(row[*ROW.IDS_Y1]), int(row[*ROW.IDS_Z1]))
    
    @staticmethod # get size (dx, dy, dz)
    def SIZE(row:NDArray[DTYPE]=None) -> SIZE:
        return (int(row[*ROW.IDS_DX]), int(row[*ROW.IDS_DY]), int(row[*ROW.IDS_DZ]))
    
    @staticmethod # get material id
    def MID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_MAT])
    
    @staticmethod # get meterial string name
    def MAT(row:NDArray[DTYPE]=None) -> str:
        return Materials.id2name[ROW.MID(row=row)]
    
    @staticmethod # get row id
    def RID(row:NDArray[DTYPE]=None) -> int:
        return int(row[*ROW.IDS_ID])
    
    @staticmethod # get flags
    def FLAGS(row:NDArray[DTYPE]=None) -> tuple[bool, bool, bool, bool, bool]:
        flags: int = int(row[*ROW.IDS_FLAGS])
        dirty, alive, solid, destr, visib = ROW.DECODE(flags=flags)
        return (dirty, alive, solid, destr, visib)
    
    @staticmethod # get volume (dx * dy * dz)
    def VOLUME(row:NDArray[DTYPE]=None) -> int:
        dx, dy, dz = ROW.SIZE(row=row)
        return dx * dy * dz

    @staticmethod # make a copy of the template array
    def COPY() -> NDArray[DTYPE]:
        return np.copy(ROW.ARRAY)
    
    @staticmethod
    def CLIP(pos:POS=None) -> POS:
        x, y, z = pos
        cx = min(max(x, ROW.XMIN), ROW.XMAX - 1)
        cy = min(max(y, ROW.YMIN), ROW.YMAX - 1)
        cz = min(max(z, ROW.ZMIN), ROW.ZMAX - 1)
        pos: POS = (cx, cy, cz)
        return pos
    
    @staticmethod
    def SORT(p0:POS=None, p1:POS=None) -> tuple[POS, POS]:
        x0, y0, z0 = p0
        x1, y1, z1 = p1
        sx0, sx1 = (min(x0, x1), max(x0, x1))
        sy0, sy1 = (min(y0, y1), max(y0, y1))
        sz0, sz1 = (min(z0, z1), max(z0, z1))
        p0: POS = (sx0, sy0, sz0)
        p1: POS = (sx1, sy1, sz1)
        return (p0, p1)
    
    @staticmethod
    def CONTAINS(row: NDArray[DTYPE], pos: POS) -> bool:
        x, y, z = pos
        x0, y0, z0 = ROW.P0(row=row)
        x1, y1, z1 = ROW.P1(row=row)
        return (
            (x0 <= x < x1) and
            (y0 <= y < y1) and
            (z0 <= z < z1)
        )
    
    @staticmethod
    def MERGE(row0: NDArray[DTYPE]=None, row1: NDArray[DTYPE]=None) -> tuple[bool, bool, bool]:
        if row0[*ROW.IDS_MAT] != row1[*ROW.IDS_MAT]:
            return (False, False, False)

        x0a, y0a, z0a = ROW.P0(row=row0)
        x1a, y1a, z1a = ROW.P1(row=row0)
        x0b, y0b, z0b = ROW.P0(row=row1)
        x1b, y1b, z1b = ROW.P1(row=row1)
        p00 = (x0a, y0a, z0a)
        p01 = (x1a, y1a, z1a)
        p10 = (x0b, y0b, z0b)
        p11 = (x1b, y1b, z1b)

        def overlap(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a0 < b1 and b0 < a1
        def touches(a0:int=None, a1:int=None, b0:int=None, b1:int=None) -> bool: return a1 == b0 or b1 == a0

        touching = [False, False, False]
        overlaps = [False, False, False]

        for i in range(3):
            if overlap(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                overlaps[i] = True
            elif touches(a0=p00[i], a1=p01[i], b0=p10[i], b1=p11[i]):
                touching[i] = True
            else:
                return (False, False, False)  # separated on this axis
            
        if sum(touching) == 1 and sum(overlaps) == 2:
            return tuple(touching)  # (x_touch, y_touch, z_touch)

        return (False, False, False)
    

    @staticmethod
    def ENCODE(dirty:bool=None, alive:bool=None, solid:bool=None, destructable:bool=None, visible:bool=None) -> int:
        f: int = 0
        if dirty:
            f |= int(ROW.ENCODE_DIRTY)
        if alive:
            f |= int(ROW.ENCODE_ALIVE)
        if solid:
            f |= int(ROW.ENCODE_SOLID)
        if destructable:
            f |= int(ROW.ENCODE_DESTRUCTABLE)
        if visible:
            f |= int(ROW.ENCODE_VISIBLE)
        return f
    
    @staticmethod
    def DECODE(flags) -> tuple[bool, bool, bool, bool, bool]:
        f: int = int(flags)

        dirty = (f & int(ROW.ENCODE_DIRTY)) != 0
        alive = (f & int(ROW.ENCODE_ALIVE)) != 0
        solid = (f & int(ROW.ENCODE_SOLID)) != 0
        destr = (f & int(ROW.ENCODE_DESTRUCTABLE)) != 0
        visib = (f & int(ROW.ENCODE_VISIBLE)) != 0
        return dirty, alive, solid, destr, visib








                

    @staticmethod
    def new(p0:POS=None, p1:POS=None, mat:str=None, rid:int=None, dirty:bool=True, alive:bool=True) -> NDArray[DTYPE]:
        p0, p1 = ROW.SORT(p0=ROW.CLIP(pos=p0), p1=ROW.CLIP(pos=p1))
        mat: Material = Material(name=mat)
        flags: int = ROW.ENCODE(dirty=dirty, alive=alive, solid=mat.issolid(), destructable=not mat.isindestructible(), visible=not mat.isinvisible())
        
        copy: NDArray[ROW.DTYPE] = ROW.COPY()

        # POS0
        copy[*ROW.IDS_X0]    = np.uint64(p0[0])
        copy[*ROW.IDS_Y0]    = np.uint64(p0[1])
        copy[*ROW.IDS_Z0]    = np.uint64(p0[2])
        # POS1
        copy[*ROW.IDS_X1]    = np.uint64(p1[0])
        copy[*ROW.IDS_Y1]    = np.uint64(p1[1])
        copy[*ROW.IDS_Z1]    = np.uint64(p1[2])
        # SIZE
        copy[*ROW.IDS_DX]    = np.uint64(p1[0] - p0[0])
        copy[*ROW.IDS_DY]    = np.uint64(p1[1] - p0[1])
        copy[*ROW.IDS_DZ]    = np.uint64(p1[2] - p0[2])
        # METADATA
        copy[*ROW.IDS_ID]    = np.uint64(rid)       # stores now the row index within material array instead of global unique id
        copy[*ROW.IDS_MAT]   = np.uint64(mat.id)
        copy[*ROW.IDS_FLAGS] = np.uint64(flags)

        if any(v < 0 for v in (copy[*ROW.IDS_DX], copy[*ROW.IDS_DY], copy[*ROW.IDS_DZ])):
            raise ValueError("p1 must be greater than or equal to p0 on all axes")
        if any(v < 0 for v in (copy[*ROW.IDS_X0], copy[*ROW.IDS_Y0], copy[*ROW.IDS_Z0])):
            raise ValueError("positions must be non-negative")
        return copy
    
    

################################################################################
# FILE 21/22: world/row.py (END)
################################################################################


################################################################################
# FILE 22/22: world/rows.py (START)
################################################################################

from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    pass


import numpy as np
from numpy.typing import NDArray

from world.row import ROW
from utils.bvh import BVH
from world.materials import Materials, MATERIALS
from utils.types import POS, SIZE
from utils.mdx import MDX




class ROWS:
    SIZE = 65536
    def __init__(self) -> None:
        self.mats = Materials()
        self.bvh = BVH(rows=self)
        self.mdx = MDX(rows=self)
        self.n:dict[int, int] = {mid: 0 for mid in range(MATERIALS.NUM)}  # number of valid rows per material
        self.m = 0  # for the total number of rows used

        self.array: NDArray[ROW.DTYPE] = np.full((MATERIALS.NUM, ROWS.SIZE, *ROW.SHAPE), fill_value=ROW.SENTINEL, dtype=ROW.DTYPE)
        self.shape = self.array.shape
        self.nbytes = self.array.nbytes
        self.gbytes = self.nbytes / (1024**3)

        mat = "STONE"
        self.insert(p0=(ROW.XMIN, ROW.YMIN, ROW.ZMIN), p1=(ROW.XMAX, ROW.YMAX, ROW.ZMAX), mat=mat)  # alive and dirty by default are true so no need to specify : easier to use now!!!
        self.size = ROW.XMAX - ROW.XMIN, ROW.YMAX - ROW.YMIN, ROW.ZMAX - ROW.ZMIN

        self._merge = 16
        self.__merge = 0

    def newn(self, mat:str=None) -> int:
        mid: int = Materials.name2idx[mat]
        n: int = self.n[mid]
        self.n[mid] += 1
        self.m += 1
        return n
    
    def deln(self, mat: str=None) -> int:
        if mat is None:
            raise ValueError("material must be specified")
        mid = Materials.name2idx[mat]
        if self.n[mid] <= 0:
            raise ValueError("no rows to free")
        self.n[mid] -= 1
        self.m -= 1
        return self.n[mid]
            
    def insert(self, p0:POS=None, p1:POS=None, mat:str=None, dirty:bool=True, alive:bool=True) -> ROWS:
        mid: int = Materials.name2idx[mat]
        rid: int = self.newn(mat=mat)
        row = ROW.new(p0=p0, p1=p1, mat=mat, rid=rid, dirty=dirty, alive=alive)
        self.array[mid][rid] = row  # added rid=n so that bvh can use it when i provide a row as argument
        self.bvh.insert(row=row)  # insert into bvh index
        self.mdx.insert(row=row)
        return self
    
    def remove(self, index:int=None, mat:str=None, row:NDArray[ROW.DTYPE]=None) -> ROWS:
        if row is not None and index is None and mat is None:
            mat = ROW.MAT(row=row)
            index = ROW.RID(row=row)
        mid = Materials.name2idx[mat]
        n = self.n[mid]
        if index < 0 or index >= n:
            raise IndexError("index out of range")
        last = n - 1
        self.bvh.remove(mat=mat, rid=index)
        self.mdx.remove(mat=mat, rid=index)

        if index != last:
            self.bvh.remove(mat=mat, rid=last)
            self.mdx.remove(mat=mat, rid=last)
            self.array[mid][index] = self.array[mid][last]
            self.array[mid][index][*ROW.IDS_ID] = np.uint64(index)
            self.bvh.insert(row=self.array[mid][index])
            self.mdx.insert(row=self.array[mid][index])

        self.array[mid][last] = ROW.ARRAY
        self.deln(mat=mat)
        return self
    
    def volume(self) -> int:
        total = 0
        for mid in range(MATERIALS.NUM):
            n = self.n[mid]
            for rid in range(n):
                row = self.array[mid][rid]
                total += ROW.VOLUME(row=row)
        return total

    def find(self, pos:POS=None) -> tuple[str, int, NDArray[ROW.DTYPE]]:
        mat, rid, row = self.bvh.find(pos=pos)
        return (mat, rid, row)
    
    def get(self, mat:str=None, rid:int=None) -> NDArray[ROW.DTYPE]:
        return self.array[Materials.name2idx[mat]][rid]

    def nrows(self, mat:str=None) -> int:
        return self.n[Materials.name2idx[mat]]
    
    def split(self, pos:POS=None, mat:str=None) -> tuple[int, int]:
        mat0, rid, row = self.find(pos=pos)
        p0 = ROW.P0(row=row)
        p1 = ROW.P1(row=row)
        
        x0, y0, z0 = p0
        x1, y1, z1 = pos
        x2, y2, z2 =x1+1, y1+1, z1+1
        x3, y3, z3 = p1

        xs = [[x0, x1], [x1, x2], [x2, x3]]
        ys = [[y0, y1], [y1, y2], [y2, y3]]
        zs = [[z0, z1], [z1, z2], [z2, z3]]

        for i, (X0, X1) in enumerate(xs):
            for j, (Y0, Y1) in enumerate(ys):
                for k, (Z0, Z1) in enumerate(zs):
                    size = (X1 - X0) * (Y1 - Y0) * (Z1 - Z0)
                    if size > 0:
                        if i == 1 and j == 1 and k == 1:    # the center cube should get the new material (its the one containing pos)
                            self.insert(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat) # use new the material given for the new row
                        else:
                            self.insert(p0=(X0, Y0, Z0), p1=(X1, Y1, Z1), mat=mat0) # use the old material for the other rows

        self.remove(row=row)  # remove the original row
        if self.__merge % self._merge == 0:
            self.sweep()
            self.__merge = 0
        self.__merge += 1



    def merge_pair(self, mat: str, rid_a: int, rid_b: int) -> bool:
        mid = Materials.name2idx[mat]
        n = self.n[mid]
        if rid_a < 0 or rid_a >= n or rid_b < 0 or rid_b >= n or rid_a == rid_b:
            return False

        row_a = self.array[mid][rid_a]
        row_b = self.array[mid][rid_b]

        touch = ROW.MERGE(row0=row_a, row1=row_b)
        if touch == (False, False, False):
            return False

        # merged bounds
        p0 = ROW.SORT(p0=ROW.P0(row=row_a), p1=ROW.P0(row=row_b))[0]
        p1 = ROW.SORT(p0=ROW.P1(row=row_a), p1=ROW.P1(row=row_b))[1]

        # remove higher rid first (because remove() swap-deletes)
        hi = rid_a if rid_a > rid_b else rid_b
        lo = rid_b if hi == rid_a else rid_a
        self.remove(mat=mat, index=hi)
        self.remove(mat=mat, index=lo)

        self.insert(p0=p0, p1=p1, mat=mat)
        return True

    def merge_pass(self, mat: str, axis: int) -> int:
        mid = Materials.name2idx[mat]
        merges = 0

        rid = 0
        while rid < self.n[mid]:
            partner = self.mdx.find_partner(mid=mid, rid=rid, axis=axis)
            if partner is None:
                rid += 1
                continue

            _, rid2 = partner
            if self.merge_pair(mat=mat, rid_a=rid, rid_b=rid2):
                merges += 1
                # don't increment rid: slot now contains swapped-in row
            else:
                rid += 1

        return merges
    
    def merge(self, mat:str=None) -> int:
        total = 0
        while True:
            m = (
                self.merge_pass(mat, axis=self.mdx.AX_X) +
                self.merge_pass(mat, axis=self.mdx.AX_Y) +
                self.merge_pass(mat, axis=self.mdx.AX_Z)
            )
            total += m
            if m == 0:
                return total
            
    def sweep(self) -> int:
        for mat in self.mats.name2idx.keys():
            self.merge(mat=mat)


    def __repr__(self) -> str:
        return self.__str__()

    def __str__(self) -> str:
        n = self.nrows(mat="STONE")
        return f"ROWS(shape={self.shape}, nbytes={self.nbytes}, gbytes={self.gbytes:.3f} with {n} valid rows)"





rows = ROWS()

################################################################################
# FILE 22/22: world/rows.py (END)
################################################################################


################################################################################
### CAPTURED OUTPUT (STDOUT/STDERR) ###
################################################################################

STEP 1 :  3D grid partition built: lap 3: 5.88354 seconds, total 5.923666 seconds
 - All random CONTAINS checks passed. Successes: 1000, Fails: 0 is a succes percentage of 100.00% adn per lookup 169.97 lookups/second
 - Random CONTAINS checks completed in: lap 4: 0.49684 seconds, total 6.420506 seconds
 - Now deleting all rows...
 - All 10000 rows deleted in: lap 5: 0.429121 seconds, total 6.849627 seconds
STEP 2 : Rebuilding rows after deletion...
 - second time 3D grid partition built: lap 6: 0.65111 seconds, total 7.500737 seconds
 - All random CONTAINS checks passed. Successes: 1000, Fails: 0 is a succes percentage of 100.00% adn per lookup 1535.84 lookups/second
 - Second random CONTAINS checks completed in: lap 7: 0.177705 seconds, total 7.678441 seconds
FINALLY: TESTS PASSED SUCCESSFULLY!
STEP 3 : Now testing SPLIT functionality...
WORLD VOLUME BEFORE:  72056357089509375
(1048576, 1048576, 65536)
 - SPLIT test 1/10 passed.
 - SPLIT test 2/10 passed.
 - SPLIT test 3/10 passed.
 - SPLIT test 4/10 passed.
 - SPLIT test 5/10 passed.
 - SPLIT test 6/10 passed.
 - SPLIT test 7/10 passed.
 - SPLIT test 8/10 passed.
 - SPLIT test 9/10 passed.
 - SPLIT test 10/10 passed.
 - SPLIT test 11/10 passed.
 - SPLIT test 12/10 passed.
 - SPLIT test 13/10 passed.
 - SPLIT test 14/10 passed.
 - SPLIT test 15/10 passed.
 - SPLIT test 16/10 passed.
 - SPLIT test 17/10 passed.
 - SPLIT test 18/10 passed.
 - SPLIT test 19/10 passed.
 - SPLIT test 20/10 passed.
 - SPLIT test 21/10 passed.
 - SPLIT test 22/10 passed.
 - SPLIT test 23/10 passed.
 - SPLIT test 24/10 passed.
 - SPLIT test 25/10 passed.
 - SPLIT test 26/10 passed.
 - SPLIT test 27/10 passed.
 - SPLIT test 28/10 passed.
 - SPLIT test 29/10 passed.
 - SPLIT test 30/10 passed.
 - SPLIT test 31/10 passed.
 - SPLIT test 32/10 passed.
 - SPLIT test 33/10 passed.
 - SPLIT test 34/10 passed.
 - SPLIT test 35/10 passed.
 - SPLIT test 36/10 passed.
 - SPLIT test 37/10 passed.
 - SPLIT test 38/10 passed.
 - SPLIT test 39/10 passed.
 - SPLIT test 40/10 passed.
 - SPLIT test 41/10 passed.
 - SPLIT test 42/10 passed.
 - SPLIT test 43/10 passed.
 - SPLIT test 44/10 passed.
 - SPLIT test 45/10 passed.
 - SPLIT test 46/10 passed.
 - SPLIT test 47/10 passed.
 - SPLIT test 48/10 passed.
 - SPLIT test 49/10 passed.
 - SPLIT test 50/10 passed.
 - SPLIT test 51/10 passed.
 - SPLIT test 52/10 passed.
 - SPLIT test 53/10 passed.
 - SPLIT test 54/10 passed.
 - SPLIT test 55/10 passed.
 - SPLIT test 56/10 passed.
 - SPLIT test 57/10 passed.
 - SPLIT test 58/10 passed.
 - SPLIT test 59/10 passed.
 - SPLIT test 60/10 passed.
 - SPLIT test 61/10 passed.
 - SPLIT test 62/10 passed.
 - SPLIT test 63/10 passed.
 - SPLIT test 64/10 passed.
 - SPLIT test 65/10 passed.
 - SPLIT test 66/10 passed.
 - SPLIT test 67/10 passed.
 - SPLIT test 68/10 passed.
 - SPLIT test 69/10 passed.
 - SPLIT test 70/10 passed.
 - SPLIT test 71/10 passed.
 - SPLIT test 72/10 passed.
 - SPLIT test 73/10 passed.
 - SPLIT test 74/10 passed.
 - SPLIT test 75/10 passed.
 - SPLIT test 76/10 passed.
 - SPLIT test 77/10 passed.
 - SPLIT test 78/10 passed.
 - SPLIT test 79/10 passed.
 - SPLIT test 80/10 passed.
 - SPLIT test 81/10 passed.
 - SPLIT test 82/10 passed.
 - SPLIT test 83/10 passed.
 - SPLIT test 84/10 passed.
 - SPLIT test 85/10 passed.
 - SPLIT test 86/10 passed.
 - SPLIT test 87/10 passed.
 - SPLIT test 88/10 passed.
 - SPLIT test 89/10 passed.
 - SPLIT test 90/10 passed.
 - SPLIT test 91/10 passed.
 - SPLIT test 92/10 passed.
 - SPLIT test 93/10 passed.
 - SPLIT test 94/10 passed.
 - SPLIT test 95/10 passed.
 - SPLIT test 96/10 passed.
 - SPLIT test 97/10 passed.
 - SPLIT test 98/10 passed.
 - SPLIT test 99/10 passed.
 - SPLIT test 100/10 passed.
 - SPLIT test 101/10 passed.
 - SPLIT test 102/10 passed.
 - SPLIT test 103/10 passed.
 - SPLIT test 104/10 passed.
 - SPLIT test 105/10 passed.
 - SPLIT test 106/10 passed.
 - SPLIT test 107/10 passed.
 - SPLIT test 108/10 passed.
 - SPLIT test 109/10 passed.
 - SPLIT test 110/10 passed.
 - SPLIT test 111/10 passed.
 - SPLIT test 112/10 passed.
 - SPLIT test 113/10 passed.
 - SPLIT test 114/10 passed.
 - SPLIT test 115/10 passed.
 - SPLIT test 116/10 passed.
 - SPLIT test 117/10 passed.
 - SPLIT test 118/10 passed.
 - SPLIT test 119/10 passed.
 - SPLIT test 120/10 passed.
 - SPLIT test 121/10 passed.
 - SPLIT test 122/10 passed.
 - SPLIT test 123/10 passed.
 - SPLIT test 124/10 passed.
 - SPLIT test 125/10 passed.
 - SPLIT test 126/10 passed.
 - SPLIT test 127/10 passed.
 - SPLIT test 128/10 passed.
 - SPLIT test 129/10 passed.
 - SPLIT test 130/10 passed.
 - SPLIT test 131/10 passed.
 - SPLIT test 132/10 passed.
 - SPLIT test 133/10 passed.
 - SPLIT test 134/10 passed.
 - SPLIT test 135/10 passed.
 - SPLIT test 136/10 passed.
 - SPLIT test 137/10 passed.
 - SPLIT test 138/10 passed.
 - SPLIT test 139/10 passed.
 - SPLIT test 140/10 passed.
 - SPLIT test 141/10 passed.
 - SPLIT test 142/10 passed.
 - SPLIT test 143/10 passed.
 - SPLIT test 144/10 passed.
 - SPLIT test 145/10 passed.
 - SPLIT test 146/10 passed.
 - SPLIT test 147/10 passed.
 - SPLIT test 148/10 passed.
 - SPLIT test 149/10 passed.
 - SPLIT test 150/10 passed.
 - SPLIT test 151/10 passed.
 - SPLIT test 152/10 passed.
 - SPLIT test 153/10 passed.
 - SPLIT test 154/10 passed.
 - SPLIT test 155/10 passed.
 - SPLIT test 156/10 passed.
 - SPLIT test 157/10 passed.
 - SPLIT test 158/10 passed.
 - SPLIT test 159/10 passed.
 - SPLIT test 160/10 passed.
 - SPLIT test 161/10 passed.
 - SPLIT test 162/10 passed.
 - SPLIT test 163/10 passed.
 - SPLIT test 164/10 passed.
 - SPLIT test 165/10 passed.
 - SPLIT test 166/10 passed.
 - SPLIT test 167/10 passed.
 - SPLIT test 168/10 passed.
 - SPLIT test 169/10 passed.
 - SPLIT test 170/10 passed.
 - SPLIT test 171/10 passed.
 - SPLIT test 172/10 passed.
 - SPLIT test 173/10 passed.
 - SPLIT test 174/10 passed.
 - SPLIT test 175/10 passed.
 - SPLIT test 176/10 passed.
 - SPLIT test 177/10 passed.
 - SPLIT test 178/10 passed.
 - SPLIT test 179/10 passed.
 - SPLIT test 180/10 passed.
 - SPLIT test 181/10 passed.
 - SPLIT test 182/10 passed.
 - SPLIT test 183/10 passed.
 - SPLIT test 184/10 passed.
 - SPLIT test 185/10 passed.
 - SPLIT test 186/10 passed.
 - SPLIT test 187/10 passed.
 - SPLIT test 188/10 passed.
 - SPLIT test 189/10 passed.
 - SPLIT test 190/10 passed.
 - SPLIT test 191/10 passed.
 - SPLIT test 192/10 passed.
 - SPLIT test 193/10 passed.
 - SPLIT test 194/10 passed.
 - SPLIT test 195/10 passed.
 - SPLIT test 196/10 passed.
 - SPLIT test 197/10 passed.
 - SPLIT test 198/10 passed.
 - SPLIT test 199/10 passed.
 - SPLIT test 200/10 passed.
 - SPLIT test 201/10 passed.
 - SPLIT test 202/10 passed.
 - SPLIT test 203/10 passed.
 - SPLIT test 204/10 passed.
 - SPLIT test 205/10 passed.
 - SPLIT test 206/10 passed.
 - SPLIT test 207/10 passed.
 - SPLIT test 208/10 passed.
 - SPLIT test 209/10 passed.
 - SPLIT test 210/10 passed.
 - SPLIT test 211/10 passed.
 - SPLIT test 212/10 passed.
 - SPLIT test 213/10 passed.
 - SPLIT test 214/10 passed.
 - SPLIT test 215/10 passed.
 - SPLIT test 216/10 passed.
 - SPLIT test 217/10 passed.
 - SPLIT test 218/10 passed.
 - SPLIT test 219/10 passed.
 - SPLIT test 220/10 passed.
 - SPLIT test 221/10 passed.
 - SPLIT test 222/10 passed.
 - SPLIT test 223/10 passed.
 - SPLIT test 224/10 passed.
 - SPLIT test 225/10 passed.
 - SPLIT test 226/10 passed.
 - SPLIT test 227/10 passed.
 - SPLIT test 228/10 passed.
 - SPLIT test 229/10 passed.
 - SPLIT test 230/10 passed.
 - SPLIT test 231/10 passed.
 - SPLIT test 232/10 passed.
 - SPLIT test 233/10 passed.
 - SPLIT test 234/10 passed.
 - SPLIT test 235/10 passed.
 - SPLIT test 236/10 passed.
 - SPLIT test 237/10 passed.
 - SPLIT test 238/10 passed.
 - SPLIT test 239/10 passed.
 - SPLIT test 240/10 passed.
 - SPLIT test 241/10 passed.
 - SPLIT test 242/10 passed.
 - SPLIT test 243/10 passed.
 - SPLIT test 244/10 passed.
 - SPLIT test 245/10 passed.
 - SPLIT test 246/10 passed.
 - SPLIT test 247/10 passed.
 - SPLIT test 248/10 passed.
 - SPLIT test 249/10 passed.
 - SPLIT test 250/10 passed.
 - SPLIT test 251/10 passed.
 - SPLIT test 252/10 passed.
 - SPLIT test 253/10 passed.
 - SPLIT test 254/10 passed.
 - SPLIT test 255/10 passed.
 - SPLIT test 256/10 passed.
 - SPLIT test 257/10 passed.
 - SPLIT test 258/10 passed.
 - SPLIT test 259/10 passed.
 - SPLIT test 260/10 passed.
 - SPLIT test 261/10 passed.
 - SPLIT test 262/10 passed.
 - SPLIT test 263/10 passed.
 - SPLIT test 264/10 passed.
 - SPLIT test 265/10 passed.
 - SPLIT test 266/10 passed.
 - SPLIT test 267/10 passed.
 - SPLIT test 268/10 passed.
 - SPLIT test 269/10 passed.
 - SPLIT test 270/10 passed.
 - SPLIT test 271/10 passed.
 - SPLIT test 272/10 passed.
 - SPLIT test 273/10 passed.
 - SPLIT test 274/10 passed.
 - SPLIT test 275/10 passed.
 - SPLIT test 276/10 passed.
 - SPLIT test 277/10 passed.
 - SPLIT test 278/10 passed.
 - SPLIT test 279/10 passed.
 - SPLIT test 280/10 passed.
 - SPLIT test 281/10 passed.
 - SPLIT test 282/10 passed.
 - SPLIT test 283/10 passed.
 - SPLIT test 284/10 passed.
 - SPLIT test 285/10 passed.
 - SPLIT test 286/10 passed.
 - SPLIT test 287/10 passed.
 - SPLIT test 288/10 passed.
 - SPLIT test 289/10 passed.
 - SPLIT test 290/10 passed.
 - SPLIT test 291/10 passed.
 - SPLIT test 292/10 passed.
 - SPLIT test 293/10 passed.
 - SPLIT test 294/10 passed.
 - SPLIT test 295/10 passed.
 - SPLIT test 296/10 passed.
 - SPLIT test 297/10 passed.
 - SPLIT test 298/10 passed.
 - SPLIT test 299/10 passed.
 - SPLIT test 300/10 passed.
 - SPLIT test 301/10 passed.
 - SPLIT test 302/10 passed.
 - SPLIT test 303/10 passed.
 - SPLIT test 304/10 passed.
 - SPLIT test 305/10 passed.
 - SPLIT test 306/10 passed.
 - SPLIT test 307/10 passed.
 - SPLIT test 308/10 passed.
 - SPLIT test 309/10 passed.
 - SPLIT test 310/10 passed.
 - SPLIT test 311/10 passed.
 - SPLIT test 312/10 passed.
 - SPLIT test 313/10 passed.
 - SPLIT test 314/10 passed.
 - SPLIT test 315/10 passed.
 - SPLIT test 316/10 passed.
 - SPLIT test 317/10 passed.
 - SPLIT test 318/10 passed.
 - SPLIT test 319/10 passed.
 - SPLIT test 320/10 passed.
 - SPLIT test 321/10 passed.
 - SPLIT test 322/10 passed.
 - SPLIT test 323/10 passed.
 - SPLIT test 324/10 passed.
 - SPLIT test 325/10 passed.
 - SPLIT test 326/10 passed.
 - SPLIT test 327/10 passed.
 - SPLIT test 328/10 passed.
 - SPLIT test 329/10 passed.
 - SPLIT test 330/10 passed.
 - SPLIT test 331/10 passed.
 - SPLIT test 332/10 passed.
 - SPLIT test 333/10 passed.
 - SPLIT test 334/10 passed.
 - SPLIT test 335/10 passed.
 - SPLIT test 336/10 passed.
 - SPLIT test 337/10 passed.
 - SPLIT test 338/10 passed.
 - SPLIT test 339/10 passed.
 - SPLIT test 340/10 passed.
 - SPLIT test 341/10 passed.
 - SPLIT test 342/10 passed.
 - SPLIT test 343/10 passed.
 - SPLIT test 344/10 passed.
 - SPLIT test 345/10 passed.
 - SPLIT test 346/10 passed.
 - SPLIT test 347/10 passed.
 - SPLIT test 348/10 passed.
 - SPLIT test 349/10 passed.
 - SPLIT test 350/10 passed.
 - SPLIT test 351/10 passed.
 - SPLIT test 352/10 passed.
 - SPLIT test 353/10 passed.
 - SPLIT test 354/10 passed.
 - SPLIT test 355/10 passed.
 - SPLIT test 356/10 passed.
 - SPLIT test 357/10 passed.
 - SPLIT test 358/10 passed.
 - SPLIT test 359/10 passed.
 - SPLIT test 360/10 passed.
 - SPLIT test 361/10 passed.
 - SPLIT test 362/10 passed.
 - SPLIT test 363/10 passed.
 - SPLIT test 364/10 passed.
 - SPLIT test 365/10 passed.
 - SPLIT test 366/10 passed.
 - SPLIT test 367/10 passed.
 - SPLIT test 368/10 passed.
 - SPLIT test 369/10 passed.
 - SPLIT test 370/10 passed.
 - SPLIT test 371/10 passed.
 - SPLIT test 372/10 passed.
 - SPLIT test 373/10 passed.
 - SPLIT test 374/10 passed.
 - SPLIT test 375/10 passed.
 - SPLIT test 376/10 passed.
 - SPLIT test 377/10 passed.
 - SPLIT test 378/10 passed.
 - SPLIT test 379/10 passed.
 - SPLIT test 380/10 passed.
 - SPLIT test 381/10 passed.
 - SPLIT test 382/10 passed.
 - SPLIT test 383/10 passed.
 - SPLIT test 384/10 passed.
 - SPLIT test 385/10 passed.
 - SPLIT test 386/10 passed.
 - SPLIT test 387/10 passed.
 - SPLIT test 388/10 passed.
 - SPLIT test 389/10 passed.
 - SPLIT test 390/10 passed.
 - SPLIT test 391/10 passed.
 - SPLIT test 392/10 passed.
 - SPLIT test 393/10 passed.
 - SPLIT test 394/10 passed.
 - SPLIT test 395/10 passed.
 - SPLIT test 396/10 passed.
 - SPLIT test 397/10 passed.
 - SPLIT test 398/10 passed.
 - SPLIT test 399/10 passed.
 - SPLIT test 400/10 passed.
 - SPLIT test 401/10 passed.
 - SPLIT test 402/10 passed.
 - SPLIT test 403/10 passed.
 - SPLIT test 404/10 passed.
 - SPLIT test 405/10 passed.
 - SPLIT test 406/10 passed.
 - SPLIT test 407/10 passed.
 - SPLIT test 408/10 passed.
 - SPLIT test 409/10 passed.
 - SPLIT test 410/10 passed.
 - SPLIT test 411/10 passed.
 - SPLIT test 412/10 passed.
 - SPLIT test 413/10 passed.
 - SPLIT test 414/10 passed.
 - SPLIT test 415/10 passed.
 - SPLIT test 416/10 passed.
 - SPLIT test 417/10 passed.
 - SPLIT test 418/10 passed.
 - SPLIT test 419/10 passed.
 - SPLIT test 420/10 passed.
 - SPLIT test 421/10 passed.
 - SPLIT test 422/10 passed.
 - SPLIT test 423/10 passed.
 - SPLIT test 424/10 passed.
 - SPLIT test 425/10 passed.
 - SPLIT test 426/10 passed.
 - SPLIT test 427/10 passed.
 - SPLIT test 428/10 passed.
 - SPLIT test 429/10 passed.
 - SPLIT test 430/10 passed.
 - SPLIT test 431/10 passed.
 - SPLIT test 432/10 passed.
 - SPLIT test 433/10 passed.
 - SPLIT test 434/10 passed.
 - SPLIT test 435/10 passed.
 - SPLIT test 436/10 passed.
 - SPLIT test 437/10 passed.
 - SPLIT test 438/10 passed.
 - SPLIT test 439/10 passed.
 - SPLIT test 440/10 passed.
 - SPLIT test 441/10 passed.
 - SPLIT test 442/10 passed.
 - SPLIT test 443/10 passed.
 - SPLIT test 444/10 passed.
 - SPLIT test 445/10 passed.
 - SPLIT test 446/10 passed.
 - SPLIT test 447/10 passed.
 - SPLIT test 448/10 passed.
 - SPLIT test 449/10 passed.
 - SPLIT test 450/10 passed.
 - SPLIT test 451/10 passed.
 - SPLIT test 452/10 passed.
 - SPLIT test 453/10 passed.
 - SPLIT test 454/10 passed.
 - SPLIT test 455/10 passed.
 - SPLIT test 456/10 passed.
 - SPLIT test 457/10 passed.
 - SPLIT test 458/10 passed.
 - SPLIT test 459/10 passed.
 - SPLIT test 460/10 passed.
 - SPLIT test 461/10 passed.
 - SPLIT test 462/10 passed.
 - SPLIT test 463/10 passed.
 - SPLIT test 464/10 passed.
 - SPLIT test 465/10 passed.
 - SPLIT test 466/10 passed.
 - SPLIT test 467/10 passed.
 - SPLIT test 468/10 passed.
 - SPLIT test 469/10 passed.
 - SPLIT test 470/10 passed.
 - SPLIT test 471/10 passed.
 - SPLIT test 472/10 passed.
 - SPLIT test 473/10 passed.
 - SPLIT test 474/10 passed.
 - SPLIT test 475/10 passed.
 - SPLIT test 476/10 passed.
 - SPLIT test 477/10 passed.
 - SPLIT test 478/10 passed.
 - SPLIT test 479/10 passed.
 - SPLIT test 480/10 passed.
 - SPLIT test 481/10 passed.
 - SPLIT test 482/10 passed.
 - SPLIT test 483/10 passed.
 - SPLIT test 484/10 passed.
 - SPLIT test 485/10 passed.
 - SPLIT test 486/10 passed.
 - SPLIT test 487/10 passed.
 - SPLIT test 488/10 passed.
 - SPLIT test 489/10 passed.
 - SPLIT test 490/10 passed.
 - SPLIT test 491/10 passed.
 - SPLIT test 492/10 passed.
 - SPLIT test 493/10 passed.
 - SPLIT test 494/10 passed.
 - SPLIT test 495/10 passed.
 - SPLIT test 496/10 passed.
 - SPLIT test 497/10 passed.
 - SPLIT test 498/10 passed.
 - SPLIT test 499/10 passed.
 - SPLIT test 500/10 passed.
 - SPLIT test 501/10 passed.
 - SPLIT test 502/10 passed.
 - SPLIT test 503/10 passed.
 - SPLIT test 504/10 passed.
 - SPLIT test 505/10 passed.
 - SPLIT test 506/10 passed.
 - SPLIT test 507/10 passed.
 - SPLIT test 508/10 passed.
 - SPLIT test 509/10 passed.
 - SPLIT test 510/10 passed.
 - SPLIT test 511/10 passed.
 - SPLIT test 512/10 passed.
 - SPLIT test 513/10 passed.
 - SPLIT test 514/10 passed.
 - SPLIT test 515/10 passed.
 - SPLIT test 516/10 passed.
 - SPLIT test 517/10 passed.
 - SPLIT test 518/10 passed.
 - SPLIT test 519/10 passed.
 - SPLIT test 520/10 passed.
 - SPLIT test 521/10 passed.
 - SPLIT test 522/10 passed.
 - SPLIT test 523/10 passed.
 - SPLIT test 524/10 passed.
 - SPLIT test 525/10 passed.
 - SPLIT test 526/10 passed.
 - SPLIT test 527/10 passed.
 - SPLIT test 528/10 passed.
 - SPLIT test 529/10 passed.
 - SPLIT test 530/10 passed.
 - SPLIT test 531/10 passed.
 - SPLIT test 532/10 passed.
 - SPLIT test 533/10 passed.
 - SPLIT test 534/10 passed.
 - SPLIT test 535/10 passed.
 - SPLIT test 536/10 passed.
 - SPLIT test 537/10 passed.
 - SPLIT test 538/10 passed.
 - SPLIT test 539/10 passed.
 - SPLIT test 540/10 passed.
 - SPLIT test 541/10 passed.
 - SPLIT test 542/10 passed.
 - SPLIT test 543/10 passed.
 - SPLIT test 544/10 passed.
 - SPLIT test 545/10 passed.
 - SPLIT test 546/10 passed.
 - SPLIT test 547/10 passed.
 - SPLIT test 548/10 passed.
 - SPLIT test 549/10 passed.
 - SPLIT test 550/10 passed.
 - SPLIT test 551/10 passed.
 - SPLIT test 552/10 passed.
 - SPLIT test 553/10 passed.
 - SPLIT test 554/10 passed.
 - SPLIT test 555/10 passed.
 - SPLIT test 556/10 passed.
 - SPLIT test 557/10 passed.
 - SPLIT test 558/10 passed.
 - SPLIT test 559/10 passed.
 - SPLIT test 560/10 passed.
 - SPLIT test 561/10 passed.
 - SPLIT test 562/10 passed.
 - SPLIT test 563/10 passed.
 - SPLIT test 564/10 passed.
 - SPLIT test 565/10 passed.
 - SPLIT test 566/10 passed.
 - SPLIT test 567/10 passed.
 - SPLIT test 568/10 passed.
 - SPLIT test 569/10 passed.
 - SPLIT test 570/10 passed.
 - SPLIT test 571/10 passed.
 - SPLIT test 572/10 passed.
 - SPLIT test 573/10 passed.
 - SPLIT test 574/10 passed.
 - SPLIT test 575/10 passed.
 - SPLIT test 576/10 passed.
 - SPLIT test 577/10 passed.
 - SPLIT test 578/10 passed.
 - SPLIT test 579/10 passed.
 - SPLIT test 580/10 passed.
 - SPLIT test 581/10 passed.
 - SPLIT test 582/10 passed.
 - SPLIT test 583/10 passed.
 - SPLIT test 584/10 passed.
 - SPLIT test 585/10 passed.
 - SPLIT test 586/10 passed.
 - SPLIT test 587/10 passed.
 - SPLIT test 588/10 passed.
 - SPLIT test 589/10 passed.
 - SPLIT test 590/10 passed.
 - SPLIT test 591/10 passed.
 - SPLIT test 592/10 passed.
 - SPLIT test 593/10 passed.
 - SPLIT test 594/10 passed.
 - SPLIT test 595/10 passed.
 - SPLIT test 596/10 passed.
 - SPLIT test 597/10 passed.
 - SPLIT test 598/10 passed.
 - SPLIT test 599/10 passed.
 - SPLIT test 600/10 passed.
 - SPLIT test 601/10 passed.
 - SPLIT test 602/10 passed.
 - SPLIT test 603/10 passed.
 - SPLIT test 604/10 passed.
 - SPLIT test 605/10 passed.
 - SPLIT test 606/10 passed.
 - SPLIT test 607/10 passed.
 - SPLIT test 608/10 passed.
 - SPLIT test 609/10 passed.
 - SPLIT test 610/10 passed.
 - SPLIT test 611/10 passed.
 - SPLIT test 612/10 passed.
 - SPLIT test 613/10 passed.
 - SPLIT test 614/10 passed.
 - SPLIT test 615/10 passed.
 - SPLIT test 616/10 passed.
 - SPLIT test 617/10 passed.
 - SPLIT test 618/10 passed.
 - SPLIT test 619/10 passed.
 - SPLIT test 620/10 passed.
 - SPLIT test 621/10 passed.
 - SPLIT test 622/10 passed.
 - SPLIT test 623/10 passed.
 - SPLIT test 624/10 passed.
 - SPLIT test 625/10 passed.
 - SPLIT test 626/10 passed.
 - SPLIT test 627/10 passed.
 - SPLIT test 628/10 passed.
 - SPLIT test 629/10 passed.
 - SPLIT test 630/10 passed.
 - SPLIT test 631/10 passed.
 - SPLIT test 632/10 passed.
 - SPLIT test 633/10 passed.
 - SPLIT test 634/10 passed.
 - SPLIT test 635/10 passed.
 - SPLIT test 636/10 passed.
 - SPLIT test 637/10 passed.
 - SPLIT test 638/10 passed.
 - SPLIT test 639/10 passed.
 - SPLIT test 640/10 passed.
 - SPLIT test 641/10 passed.
 - SPLIT test 642/10 passed.
 - SPLIT test 643/10 passed.
 - SPLIT test 644/10 passed.
 - SPLIT test 645/10 passed.
 - SPLIT test 646/10 passed.
 - SPLIT test 647/10 passed.
 - SPLIT test 648/10 passed.
 - SPLIT test 649/10 passed.
 - SPLIT test 650/10 passed.
 - SPLIT test 651/10 passed.
 - SPLIT test 652/10 passed.
 - SPLIT test 653/10 passed.
 - SPLIT test 654/10 passed.
 - SPLIT test 655/10 passed.
 - SPLIT test 656/10 passed.
 - SPLIT test 657/10 passed.
 - SPLIT test 658/10 passed.
 - SPLIT test 659/10 passed.
 - SPLIT test 660/10 passed.
 - SPLIT test 661/10 passed.
 - SPLIT test 662/10 passed.
 - SPLIT test 663/10 passed.
 - SPLIT test 664/10 passed.
 - SPLIT test 665/10 passed.
 - SPLIT test 666/10 passed.
 - SPLIT test 667/10 passed.
 - SPLIT test 668/10 passed.
 - SPLIT test 669/10 passed.
 - SPLIT test 670/10 passed.
 - SPLIT test 671/10 passed.
 - SPLIT test 672/10 passed.
 - SPLIT test 673/10 passed.
 - SPLIT test 674/10 passed.
 - SPLIT test 675/10 passed.
 - SPLIT test 676/10 passed.
 - SPLIT test 677/10 passed.
 - SPLIT test 678/10 passed.
 - SPLIT test 679/10 passed.
 - SPLIT test 680/10 passed.
 - SPLIT test 681/10 passed.
 - SPLIT test 682/10 passed.
 - SPLIT test 683/10 passed.
 - SPLIT test 684/10 passed.
 - SPLIT test 685/10 passed.
 - SPLIT test 686/10 passed.
 - SPLIT test 687/10 passed.
 - SPLIT test 688/10 passed.
 - SPLIT test 689/10 passed.
 - SPLIT test 690/10 passed.
 - SPLIT test 691/10 passed.
 - SPLIT test 692/10 passed.
 - SPLIT test 693/10 passed.
 - SPLIT test 694/10 passed.
 - SPLIT test 695/10 passed.
 - SPLIT test 696/10 passed.
 - SPLIT test 697/10 passed.
 - SPLIT test 698/10 passed.
 - SPLIT test 699/10 passed.
 - SPLIT test 700/10 passed.
 - SPLIT test 701/10 passed.
 - SPLIT test 702/10 passed.
 - SPLIT test 703/10 passed.
 - SPLIT test 704/10 passed.
 - SPLIT test 705/10 passed.
 - SPLIT test 706/10 passed.
 - SPLIT test 707/10 passed.
 - SPLIT test 708/10 passed.
 - SPLIT test 709/10 passed.
 - SPLIT test 710/10 passed.
 - SPLIT test 711/10 passed.
 - SPLIT test 712/10 passed.
 - SPLIT test 713/10 passed.
 - SPLIT test 714/10 passed.
 - SPLIT test 715/10 passed.
 - SPLIT test 716/10 passed.
 - SPLIT test 717/10 passed.
 - SPLIT test 718/10 passed.
 - SPLIT test 719/10 passed.
 - SPLIT test 720/10 passed.
 - SPLIT test 721/10 passed.
 - SPLIT test 722/10 passed.
 - SPLIT test 723/10 passed.
 - SPLIT test 724/10 passed.
 - SPLIT test 725/10 passed.
 - SPLIT test 726/10 passed.
 - SPLIT test 727/10 passed.
 - SPLIT test 728/10 passed.
 - SPLIT test 729/10 passed.
 - SPLIT test 730/10 passed.
 - SPLIT test 731/10 passed.
 - SPLIT test 732/10 passed.
 - SPLIT test 733/10 passed.
 - SPLIT test 734/10 passed.
 - SPLIT test 735/10 passed.
 - SPLIT test 736/10 passed.
 - SPLIT test 737/10 passed.
 - SPLIT test 738/10 passed.
 - SPLIT test 739/10 passed.
 - SPLIT test 740/10 passed.
 - SPLIT test 741/10 passed.
 - SPLIT test 742/10 passed.
 - SPLIT test 743/10 passed.
 - SPLIT test 744/10 passed.
 - SPLIT test 745/10 passed.
 - SPLIT test 746/10 passed.
 - SPLIT test 747/10 passed.
 - SPLIT test 748/10 passed.
 - SPLIT test 749/10 passed.
 - SPLIT test 750/10 passed.
 - SPLIT test 751/10 passed.
 - SPLIT test 752/10 passed.
 - SPLIT test 753/10 passed.
 - SPLIT test 754/10 passed.
 - SPLIT test 755/10 passed.
 - SPLIT test 756/10 passed.
 - SPLIT test 757/10 passed.
 - SPLIT test 758/10 passed.
 - SPLIT test 759/10 passed.
 - SPLIT test 760/10 passed.
 - SPLIT test 761/10 passed.
 - SPLIT test 762/10 passed.
 - SPLIT test 763/10 passed.
 - SPLIT test 764/10 passed.
 - SPLIT test 765/10 passed.
 - SPLIT test 766/10 passed.
 - SPLIT test 767/10 passed.
 - SPLIT test 768/10 passed.
 - SPLIT test 769/10 passed.
 - SPLIT test 770/10 passed.
 - SPLIT test 771/10 passed.
 - SPLIT test 772/10 passed.
 - SPLIT test 773/10 passed.
 - SPLIT test 774/10 passed.
 - SPLIT test 775/10 passed.
 - SPLIT test 776/10 passed.
 - SPLIT test 777/10 passed.
 - SPLIT test 778/10 passed.
 - SPLIT test 779/10 passed.
 - SPLIT test 780/10 passed.
 - SPLIT test 781/10 passed.
 - SPLIT test 782/10 passed.
 - SPLIT test 783/10 passed.
 - SPLIT test 784/10 passed.
 - SPLIT test 785/10 passed.
 - SPLIT test 786/10 passed.
 - SPLIT test 787/10 passed.
 - SPLIT test 788/10 passed.
 - SPLIT test 789/10 passed.
 - SPLIT test 790/10 passed.
 - SPLIT test 791/10 passed.
 - SPLIT test 792/10 passed.
 - SPLIT test 793/10 passed.
 - SPLIT test 794/10 passed.
 - SPLIT test 795/10 passed.
 - SPLIT test 796/10 passed.
 - SPLIT test 797/10 passed.
 - SPLIT test 798/10 passed.
 - SPLIT test 799/10 passed.
 - SPLIT test 800/10 passed.
 - SPLIT test 801/10 passed.
 - SPLIT test 802/10 passed.
 - SPLIT test 803/10 passed.
 - SPLIT test 804/10 passed.
 - SPLIT test 805/10 passed.
 - SPLIT test 806/10 passed.
 - SPLIT test 807/10 passed.
 - SPLIT test 808/10 passed.
 - SPLIT test 809/10 passed.
 - SPLIT test 810/10 passed.
 - SPLIT test 811/10 passed.
 - SPLIT test 812/10 passed.
 - SPLIT test 813/10 passed.
 - SPLIT test 814/10 passed.
 - SPLIT test 815/10 passed.
 - SPLIT test 816/10 passed.
 - SPLIT test 817/10 passed.
 - SPLIT test 818/10 passed.
 - SPLIT test 819/10 passed.
 - SPLIT test 820/10 passed.
 - SPLIT test 821/10 passed.
 - SPLIT test 822/10 passed.
 - SPLIT test 823/10 passed.
 - SPLIT test 824/10 passed.
 - SPLIT test 825/10 passed.
 - SPLIT test 826/10 passed.
 - SPLIT test 827/10 passed.
 - SPLIT test 828/10 passed.
 - SPLIT test 829/10 passed.
 - SPLIT test 830/10 passed.
 - SPLIT test 831/10 passed.
 - SPLIT test 832/10 passed.
 - SPLIT test 833/10 passed.
 - SPLIT test 834/10 passed.
 - SPLIT test 835/10 passed.
 - SPLIT test 836/10 passed.
 - SPLIT test 837/10 passed.
 - SPLIT test 838/10 passed.
 - SPLIT test 839/10 passed.
 - SPLIT test 840/10 passed.
 - SPLIT test 841/10 passed.
 - SPLIT test 842/10 passed.
 - SPLIT test 843/10 passed.
 - SPLIT test 844/10 passed.
 - SPLIT test 845/10 passed.
 - SPLIT test 846/10 passed.
 - SPLIT test 847/10 passed.
 - SPLIT test 848/10 passed.
 - SPLIT test 849/10 passed.
 - SPLIT test 850/10 passed.
 - SPLIT test 851/10 passed.
 - SPLIT test 852/10 passed.
 - SPLIT test 853/10 passed.
 - SPLIT test 854/10 passed.
 - SPLIT test 855/10 passed.
 - SPLIT test 856/10 passed.
 - SPLIT test 857/10 passed.
 - SPLIT test 858/10 passed.
 - SPLIT test 859/10 passed.
 - SPLIT test 860/10 passed.
 - SPLIT test 861/10 passed.
 - SPLIT test 862/10 passed.
 - SPLIT test 863/10 passed.
 - SPLIT test 864/10 passed.
 - SPLIT test 865/10 passed.
 - SPLIT test 866/10 passed.
 - SPLIT test 867/10 passed.
 - SPLIT test 868/10 passed.
 - SPLIT test 869/10 passed.
 - SPLIT test 870/10 passed.
 - SPLIT test 871/10 passed.
 - SPLIT test 872/10 passed.
 - SPLIT test 873/10 passed.
 - SPLIT test 874/10 passed.
 - SPLIT test 875/10 passed.
 - SPLIT test 876/10 passed.
 - SPLIT test 877/10 passed.
 - SPLIT test 878/10 passed.
 - SPLIT test 879/10 passed.
 - SPLIT test 880/10 passed.
 - SPLIT test 881/10 passed.
 - SPLIT test 882/10 passed.
 - SPLIT test 883/10 passed.
 - SPLIT test 884/10 passed.
 - SPLIT test 885/10 passed.
 - SPLIT test 886/10 passed.
 - SPLIT test 887/10 passed.
 - SPLIT test 888/10 passed.
 - SPLIT test 889/10 passed.
 - SPLIT test 890/10 passed.
 - SPLIT test 891/10 passed.
 - SPLIT test 892/10 passed.
 - SPLIT test 893/10 passed.
 - SPLIT test 894/10 passed.
 - SPLIT test 895/10 passed.
 - SPLIT test 896/10 passed.
 - SPLIT test 897/10 passed.
 - SPLIT test 898/10 passed.
 - SPLIT test 899/10 passed.
 - SPLIT test 900/10 passed.
 - SPLIT test 901/10 passed.
 - SPLIT test 902/10 passed.
 - SPLIT test 903/10 passed.
 - SPLIT test 904/10 passed.
 - SPLIT test 905/10 passed.
 - SPLIT test 906/10 passed.
 - SPLIT test 907/10 passed.
 - SPLIT test 908/10 passed.
 - SPLIT test 909/10 passed.
 - SPLIT test 910/10 passed.
 - SPLIT test 911/10 passed.
 - SPLIT test 912/10 passed.
 - SPLIT test 913/10 passed.
 - SPLIT test 914/10 passed.
 - SPLIT test 915/10 passed.
 - SPLIT test 916/10 passed.
 - SPLIT test 917/10 passed.
 - SPLIT test 918/10 passed.
 - SPLIT test 919/10 passed.
 - SPLIT test 920/10 passed.
 - SPLIT test 921/10 passed.
 - SPLIT test 922/10 passed.
 - SPLIT test 923/10 passed.
 - SPLIT test 924/10 passed.
 - SPLIT test 925/10 passed.
 - SPLIT test 926/10 passed.
 - SPLIT test 927/10 passed.
 - SPLIT test 928/10 passed.
 - SPLIT test 929/10 passed.
 - SPLIT test 930/10 passed.
 - SPLIT test 931/10 passed.
 - SPLIT test 932/10 passed.
 - SPLIT test 933/10 passed.
 - SPLIT test 934/10 passed.
 - SPLIT test 935/10 passed.
 - SPLIT test 936/10 passed.
 - SPLIT test 937/10 passed.
 - SPLIT test 938/10 passed.
 - SPLIT test 939/10 passed.
 - SPLIT test 940/10 passed.
 - SPLIT test 941/10 passed.
 - SPLIT test 942/10 passed.
 - SPLIT test 943/10 passed.
 - SPLIT test 944/10 passed.
 - SPLIT test 945/10 passed.
 - SPLIT test 946/10 passed.
 - SPLIT test 947/10 passed.
 - SPLIT test 948/10 passed.
 - SPLIT test 949/10 passed.
 - SPLIT test 950/10 passed.
 - SPLIT test 951/10 passed.
 - SPLIT test 952/10 passed.
 - SPLIT test 953/10 passed.
 - SPLIT test 954/10 passed.
 - SPLIT test 955/10 passed.
 - SPLIT test 956/10 passed.
 - SPLIT test 957/10 passed.
 - SPLIT test 958/10 passed.
 - SPLIT test 959/10 passed.
 - SPLIT test 960/10 passed.
 - SPLIT test 961/10 passed.
 - SPLIT test 962/10 passed.
 - SPLIT test 963/10 passed.
 - SPLIT test 964/10 passed.
 - SPLIT test 965/10 passed.
 - SPLIT test 966/10 passed.
 - SPLIT test 967/10 passed.
 - SPLIT test 968/10 passed.
 - SPLIT test 969/10 passed.
 - SPLIT test 970/10 passed.
 - SPLIT test 971/10 passed.
 - SPLIT test 972/10 passed.
 - SPLIT test 973/10 passed.
 - SPLIT test 974/10 passed.
 - SPLIT test 975/10 passed.
 - SPLIT test 976/10 passed.
 - SPLIT test 977/10 passed.
 - SPLIT test 978/10 passed.
 - SPLIT test 979/10 passed.
 - SPLIT test 980/10 passed.
 - SPLIT test 981/10 passed.
 - SPLIT test 982/10 passed.
 - SPLIT test 983/10 passed.
 - SPLIT test 984/10 passed.
 - SPLIT test 985/10 passed.
 - SPLIT test 986/10 passed.
 - SPLIT test 987/10 passed.
 - SPLIT test 988/10 passed.
 - SPLIT test 989/10 passed.
 - SPLIT test 990/10 passed.
 - SPLIT test 991/10 passed.
 - SPLIT test 992/10 passed.
 - SPLIT test 993/10 passed.
 - SPLIT test 994/10 passed.
 - SPLIT test 995/10 passed.
 - SPLIT test 996/10 passed.
 - SPLIT test 997/10 passed.
 - SPLIT test 998/10 passed.
 - SPLIT test 999/10 passed.
 - SPLIT test 1000/10 passed.
Material AIR has 1000 rows after SPLIT tests.
Material WATER has 0 rows after SPLIT tests.
Material LAVA has 0 rows after SPLIT tests.
Material GLASS has 0 rows after SPLIT tests.
Material STONE has 5324 rows after SPLIT tests.
Material OBSIDIAN has 0 rows after SPLIT tests.
Material BEDROCK has 0 rows after SPLIT tests.
WORLD VOLUME AFTER:  72056357089509375
STARTING STEP 4 : Now testing SWEEP functionality...: lap 8: 7.33504 seconds, total 15.013481 seconds
 - SWEEP completed in: lap 9: 0.052953 seconds, total 15.066434 seconds
 - Second SWEEP completed in: lap 10: 0.008626 seconds, total 15.07506 seconds
WORLD VOLUME AFTER SWEEP:  72056357089509375
Material AIR has 1000 rows after SWEEP tests.
Material WATER has 0 rows after SWEEP tests.
Material LAVA has 0 rows after SWEEP tests.
Material GLASS has 0 rows after SWEEP tests.
Material STONE has 5188 rows after SWEEP tests.
Material OBSIDIAN has 0 rows after SWEEP tests.
Material BEDROCK has 0 rows after SWEEP tests.
main.py: executed in: lap 11: 0.006631 seconds, total 15.081691 seconds

################################################################################
### END OF CAPTURED OUTPUT ###
################################################################################
# Total lines in bundle: 3406
# Total files in bundle: 22
# Generated at the time: 2026-01-29T15:17:06
--- END OF FILE ---
